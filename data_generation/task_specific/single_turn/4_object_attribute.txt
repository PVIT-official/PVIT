{"img_id": 3396, "query": " a window on a building : [0.27, 0.142, 0.297, 0.225]\na black aroow on sign: [0.115, 0.602, 0.158, 0.662]\n a window on a building : [0.168, 0.133, 0.217, 0.213]\npants are brown : [0.28, 0.703, 0.311, 0.773]\na window in the building : [0.329, 0.308, 0.399, 0.437]\na window on a building: [0.343, 0.135, 0.385, 0.208]\n a window on a building : [0.421, 0.168, 0.448, 0.25]\nbuilding has red bricks: [0.549, 0.17, 0.82, 0.46]\nit is a red car : [0.719, 0.657, 0.936, 0.79]\na window on a building: [0.258, 0.14, 0.304, 0.227]\n\n<shirt: [0.261, 0.632, 0.326, 0.708]> <blue>\n<tire: [0.886, 0.718, 0.932, 0.777]> <back>\n<car: [0.734, 0.655, 0.956, 0.802]> <red>\n<coat: [0.695, 0.647, 0.769, 0.733]> <yellow, blue>\n<pants: [0.035, 0.732, 0.091, 0.822]> <white>\n<building: [0.004, 0.0, 0.574, 0.533]> <white>\n<sign: [0.848, 0.362, 0.949, 0.465]> <white>\n", "response": "Task: What can you say about the color of the bricks in the <Region>[0.549, 0.17, 0.82, 0.46]</Region> of the building?\nOutput: The bricks in that region of the building are red in color.", "instruction": "What can you say about the color of the bricks in the <Region>[0.549, 0.17, 0.82, 0.46]</Region> of the building?", "input": "", "output": "The bricks in that region of the building are red in color.", "is_classification": false, "dataset": "VG", "img_info": "3396.jpg"}
{"img_id": 498034, "query": "Empty wine glass on the table: [0.47, 0.859, 0.527, 0.996]\nCurtain rod above the window: [0.279, 0.0, 0.87, 0.059]\nthis is a wine glass: [0.52, 0.744, 0.645, 0.911]\nEmpty wine glass on the table: [0.541, 0.857, 0.599, 0.996]\nEmpty wine glass on the table: [0.486, 0.647, 0.525, 0.782]\nBlack curtain rod above the window: [0.273, 0.0, 0.879, 0.057]\nGreen bottle on the table: [0.534, 0.533, 0.584, 0.783]\nthis is a wine glass: [0.52, 0.744, 0.645, 0.911]\nTan curtain over the window: [0.699, 0.037, 0.806, 0.372]\nEmpty wine glass on the table: [0.539, 0.861, 0.592, 0.996]\n\n<curtain: [0.707, 0.054, 0.809, 0.369]> <tan>\n<window: [0.396, 0.016, 0.795, 0.41]> <curtain>\n<rod: [0.298, 0.016, 0.863, 0.048]> <black>\n<rod: [0.292, 0.007, 0.862, 0.069]> <curtain>\n<glass: [0.463, 0.852, 0.535, 0.98]> <empty, wine>\n<glass: [0.541, 0.861, 0.597, 0.966]> <wine, empty>\n<glass: [0.485, 0.63, 0.524, 0.785]> <empty, wine>\n<bottle: [0.532, 0.526, 0.592, 0.773]> <green>\n", "response": "Task: Is there any wine in the Green bottle on the table in <Region>[0.532, 0.526, 0.592, 0.773]</Region>?\nOutput: There is no information about whether there is wine in the green bottle or not, as it has not been mentioned.", "instruction": "Is there any wine in the Green bottle on the table in <Region>[0.532, 0.526, 0.592, 0.773]</Region>?", "input": "", "output": "There is no information about whether there is wine in the green bottle or not, as it has not been mentioned.", "is_classification": false, "dataset": "VG", "img_info": "498034.jpg"}
{"img_id": 713780, "query": "person eating at a restuarant: [0.788, 0.262, 0.882, 0.501]\n a person is sitting down : [0.661, 0.26, 0.822, 0.516]\nperson eating at a restuarant: [0.247, 0.212, 0.758, 0.992]\na person is sitting: [0.017, 0.281, 0.125, 0.461]\nperson eating at a restuarant: [0.915, 0.25, 0.997, 0.469]\nperson eating at a restuarant: [0.011, 0.285, 0.116, 0.447]\nperson eating at a restuarant: [0.247, 0.212, 0.758, 0.992]\n a person is sitting down : [0.019, 0.284, 0.116, 0.471]\n a chair that you sit in : [0.003, 0.387, 0.065, 0.766]\nA person is sitting down: [0.204, 0.27, 0.76, 0.991]\n\n<person: [0.258, 0.223, 0.76, 0.997]> <sitting down>\n<person: [0.682, 0.257, 0.825, 0.5]> <sitting down>\n<person: [0.635, 0.268, 0.717, 0.517]> <sitting down>\n<person: [0.611, 0.268, 0.646, 0.365]> <sitting down>\n<person: [0.929, 0.257, 0.997, 0.44]> <sitting down>\n<hair: [0.37, 0.227, 0.646, 0.611]> <blonde>\n<person: [0.015, 0.28, 0.123, 0.379]> <sitting>\n<head: [0.747, 0.249, 0.813, 0.326]> <billed, cotton>\n<sticker: [0.318, 0.026, 0.366, 0.082]> <red, square>\n<restaurant: [0.0, 0.0, 0.985, 0.997]> <casual, family, fast food, large>\n<person: [0.204, 0.216, 0.757, 0.988]> <young, female>\n", "response": "Task: What type of restaurant is depicted in <Region>[0.0, 0.0, 0.985, 0.997]</Region>?\nOutput: The restaurant depicted in that region is casual, family-friendly, and serves fast food. It also seems to be relatively large.", "instruction": "What type of restaurant is depicted in <Region>[0.0, 0.0, 0.985, 0.997]</Region>?", "input": "", "output": "The restaurant depicted in that region is casual, family-friendly, and serves fast food. It also seems to be relatively large.", "is_classification": false, "dataset": "VG", "img_info": "713780.jpg"}
{"img_id": 1126, "query": "metal gurney railing: [0.042, 0.67, 0.492, 0.997]\nGloves on the man's hands: [0.54, 0.652, 0.67, 0.78]\nMan wearing a set of scrubs: [0.456, 0.167, 0.6, 0.688]\nblack hair on man: [0.536, 0.182, 0.606, 0.324]\nblack hair on man: [0.536, 0.182, 0.606, 0.324]\nwhite hospital mask : [0.25, 0.292, 0.34, 0.568]\nGlove on a persons hand: [0.756, 0.568, 0.862, 0.699]\nMan wearing a set of scrubs: [0.284, 0.167, 0.558, 0.783]\nMustard colored shirt on the man: [0.738, 0.363, 0.974, 0.619]\nMan wearing a blue shirt : [0.284, 0.289, 0.494, 0.711]\n\n<scrubs: [0.206, 0.339, 0.33, 0.607]> <set>\n<scrubs: [0.252, 0.28, 0.468, 0.807]> <set>\n<scrubs: [0.46, 0.357, 0.608, 0.586]> <set>\n<scrubs: [0.568, 0.369, 0.65, 0.47]> <set>\n<scrubs: [0.764, 0.336, 0.968, 0.991]> <set>\n<hand: [0.26, 0.696, 0.338, 0.807]> <person's>\n<hand: [0.55, 0.661, 0.636, 0.747]> <person's>\n<hand: [0.768, 0.577, 0.844, 0.676]> <person's>\n<hand: [0.726, 0.699, 0.784, 0.789]> <person's>\n<mask: [0.24, 0.321, 0.328, 0.554]> <hospital, white>\n<shirt: [0.256, 0.283, 0.47, 0.723]> <hospital, blue>\n<glove: [0.23, 0.682, 0.39, 0.83]> <white, plastic>\n<barrette: [0.018, 0.318, 0.134, 0.494]> <grey>\n<chart: [0.83, 0.113, 0.972, 0.363]> <black, white>\n<railing: [0.074, 0.673, 0.474, 0.991]> <metal>\n<sheet: [0.296, 0.821, 0.514, 0.991]> <white>\n<device: [0.676, 0.696, 0.768, 0.875]> <blue, medical>\n<shirt: [0.248, 0.348, 0.528, 0.753]> <blue>\n<shirt: [0.232, 0.375, 0.408, 0.688]> <blue>\n<shirt: [0.57, 0.42, 0.796, 0.649]> <blue>\n<man: [0.398, 0.173, 0.53, 0.342]> <blackhaired>\n<man: [0.238, 0.137, 0.366, 0.378]> <blackhaired>\n<black hair: [0.65, 0.449, 0.726, 0.554]> <on man>\n<lights: [0.764, 0.0, 0.962, 0.06]> <flourescent>\n<shirt: [0.742, 0.351, 0.972, 0.634]> <mustard>\n<shirt: [0.756, 0.336, 0.964, 0.693]> <brown>\n", "response": "Task: What color is the shirt worn by the man in <Region>[0.232, 0.375, 0.408, 0.688]</Region>?\nOutput: The color of the shirt worn by the man is blue.", "instruction": "What color is the shirt worn by the man in <Region>[0.232, 0.375, 0.408, 0.688]</Region>?", "input": "", "output": "The color of the shirt worn by the man is blue.", "is_classification": false, "dataset": "VG", "img_info": "1126.jpg"}
{"img_id": 3285, "query": " a stone in a wall : [0.615, 0.493, 0.635, 0.525]\nGarbage receptacle is red: [0.603, 0.65, 0.685, 0.837]\nthe person has a backpack: [0.705, 0.36, 0.905, 0.877]\n a person walking on a sidewalk : [0.212, 0.59, 0.258, 0.78]\nthe person has a backpack: [0.705, 0.36, 0.905, 0.877]\nthe person is walking: [0.307, 0.563, 0.351, 0.73]\nthe trash can is red: [0.565, 0.603, 0.79, 0.95]\nthe wall is gray and white: [0.403, 0.502, 0.794, 0.795]\n a stone in a wall : [0.689, 0.542, 0.715, 0.592]\n a stone in a wall : [0.708, 0.588, 0.735, 0.618]\n\n<receptacle: [0.599, 0.593, 0.711, 0.86]> <red>\n<flowers: [0.323, 0.647, 0.429, 0.74]> <pink>\n<bush: [0.191, 0.625, 0.616, 1.0]> <green>\n<wall: [0.064, 0.445, 0.833, 0.82]> <concrete>\n<towel: [0.711, 0.435, 0.925, 0.687]> <blue>\n<boy: [0.726, 0.333, 0.927, 0.99]> <walking>\n<person: [0.752, 0.37, 0.938, 0.995]> <walking>\n<person: [0.725, 0.347, 0.945, 0.995]> <walking>\n<person: [0.738, 0.353, 0.915, 0.993]> <walking>\n<person: [0.754, 0.377, 0.92, 0.98]> <walking>\n<person: [0.31, 0.557, 0.35, 0.718]> <walking>\n<person: [0.209, 0.587, 0.251, 0.76]> <walking>\n<person: [0.736, 0.37, 0.954, 0.927]> <walking>\n<shirt: [0.725, 0.457, 0.938, 0.628]> <blue>\n<trash can: [0.59, 0.615, 0.686, 0.825]> <red>\n<sign: [0.203, 0.013, 0.409, 0.238]> <blue, white>\n<wall: [0.414, 0.483, 0.74, 0.747]> <stone>\n<wall: [0.416, 0.502, 0.781, 0.797]> <gray, white>\n<trash can: [0.584, 0.613, 0.713, 0.872]> <red>\n<boy: [0.751, 0.382, 0.924, 0.995]> <with a blue towel over his shoulders>\n<flowers: [0.149, 0.64, 0.615, 0.95]> <pink>\n<top: [0.307, 0.592, 0.35, 0.688]> <white>\n", "response": "Task: Is the wall in <Region>[0.064, 0.445, 0.833, 0.82]</Region> made of concrete, and what are its colors?\nOutput: The wall in this region is made of concrete, and its colors are gray and white.", "instruction": "Is the wall in <Region>[0.064, 0.445, 0.833, 0.82]</Region> made of concrete, and what are its colors?", "input": "", "output": "The wall in this region is made of concrete, and its colors are gray and white.", "is_classification": false, "dataset": "VG", "img_info": "3285.jpg"}
{"img_id": 1671, "query": "letter on the mug: [0.393, 0.572, 0.482, 0.658]\nThe edge of a computer keyboard: [0.89, 0.722, 0.998, 0.995]\nThe year 2002 printed on a CD ROM disk.: [0.099, 0.725, 0.185, 0.808]\nBlack letters on a cup: [0.416, 0.572, 0.484, 0.657]\nBeige cord from the keyboard connected to the computer : [0.054, 0.565, 0.971, 0.773]\nA white handle on a cup: [0.547, 0.47, 0.637, 0.702]\nkeyboard on the desk: [0.853, 0.732, 0.998, 0.98]\nD on the side of the coffee mug : [0.391, 0.458, 0.507, 0.678]\nthe CD has black letters and numbers: [0.003, 0.722, 0.226, 0.98]\nCD on the white counter next to the coffee mug : [0.0, 0.615, 0.282, 0.98]\n\n<monitor: [0.644, 0.002, 0.998, 0.41]> <large, white>\n<ream: [0.725, 0.305, 0.998, 0.655]> <paper>\n<white counter: [0.209, 0.487, 0.894, 0.99]> <white>\n<paper: [0.729, 0.322, 0.998, 0.665]> <packaged>\n<d: [0.416, 0.465, 0.458, 0.573]> <old english>\n<letters: [0.416, 0.573, 0.481, 0.653]> <black>\n<envelope sleeve: [0.004, 0.663, 0.309, 0.995]> <white>\n<cup: [0.406, 0.332, 0.64, 0.712]> <dirty, white>\n<handle: [0.545, 0.462, 0.637, 0.693]> <white>\n<logo: [0.406, 0.45, 0.464, 0.595]> <black>\n<case: [0.01, 0.647, 0.302, 0.995]> <white>\n<cord: [0.421, 0.773, 0.914, 0.935]> <black>\n<paper: [0.711, 0.315, 0.993, 0.675]> <package>\n<numbers: [0.098, 0.727, 0.199, 0.798]> <black>\n<lettering: [0.417, 0.572, 0.49, 0.67]> <black>\n<mug: [0.414, 0.323, 0.635, 0.735]> <dirty>\n<logo: [0.403, 0.448, 0.471, 0.603]> <black, white>\n<keyboard: [0.87, 0.717, 0.996, 0.99]> <white>\n", "response": "Task: What is the text written on the CD in <Region>[0.003, 0.722, 0.226, 0.98]</Region>, and what color is the text?\nOutput: The text written on the CD in that region is \"2002,\" and the color of the text is black.", "instruction": "What is the text written on the CD in <Region>[0.003, 0.722, 0.226, 0.98]</Region>, and what color is the text?", "input": "", "output": "The text written on the CD in that region is \"2002,\" and the color of the text is black.", "is_classification": false, "dataset": "VG", "img_info": "1671.jpg"}
{"img_id": 713906, "query": "Windshield wiper on the train. : [0.442, 0.364, 0.557, 0.451]\nthe headlight on the train: [0.401, 0.593, 0.433, 0.637]\nglass window on train: [0.937, 0.436, 0.959, 0.497]\nwindshield wiper on train: [0.44, 0.341, 0.577, 0.483]\na bridge above the train: [0.01, 0.067, 0.378, 0.435]\ntrain on the tracks: [0.15, 0.177, 0.81, 0.849]\nthe bright round reddish light on the train: [0.392, 0.587, 0.436, 0.64]\nthe black and yellow train: [0.188, 0.172, 0.759, 0.903]\nthe door of a train: [0.246, 0.349, 0.284, 0.577]\nThe windshield wiper: [0.445, 0.363, 0.563, 0.461]\n\n<front: [0.354, 0.299, 0.742, 0.604]> <yellow>\n<patch: [0.108, 0.397, 0.322, 0.996]> <dark, gray>\n<wiper: [0.44, 0.356, 0.574, 0.476]> <windshield>\n<train: [0.67, 0.331, 0.996, 0.572]> <side>\n<tracks: [0.746, 0.631, 0.993, 0.809]> <set>\n<train: [0.228, 0.137, 0.847, 0.88]> <blue, yellow, silver>\n<bumper: [0.542, 0.86, 0.996, 0.984]> <orange>\n<headlight: [0.382, 0.561, 0.476, 0.665]> <train front>\n<headlight: [0.376, 0.569, 0.467, 0.673]> <train front>\n<windshield: [0.389, 0.281, 0.727, 0.468]> <train front>\n<windshield: [0.397, 0.3, 0.691, 0.465]> <train front>\n<staircase: [0.111, 0.372, 0.155, 0.503]> <distance>\n<ticketing machine: [0.823, 0.388, 0.929, 0.584]> <electronic ticketing>\n<train: [0.283, 0.196, 0.788, 0.863]> <black, yellow>\n", "response": "Task: What color is the object indicated by <Region>[0.542, 0.86, 0.996, 0.984]</Region>?\nOutput: The object indicated by the given region is orange.", "instruction": "What color is the object indicated by <Region>[0.542, 0.86, 0.996, 0.984]</Region>?", "input": "", "output": "The object indicated by the given region is orange.", "is_classification": false, "dataset": "VG", "img_info": "713906.jpg"}
{"img_id": 1670, "query": "key on the keyboard: [0.35, 0.465, 0.404, 0.515]\nbeige and brown keyboard: [0.068, 0.352, 0.649, 0.677]\nDell 101-key computer keyboard: [0.08, 0.34, 0.645, 0.687]\nArrow keys on an older model keyboard.: [0.448, 0.515, 0.52, 0.598]\nA piece of paper sitting near a computer monitor.: [0.531, 0.043, 0.772, 0.29]\na pink mouse pad: [0.615, 0.355, 0.912, 0.628]\nkey on the keyboard: [0.092, 0.61, 0.12, 0.628]\nDell compute keyboard on desk: [0.075, 0.35, 0.715, 0.672]\nkey on the keyboard: [0.092, 0.61, 0.12, 0.628]\nhandle on the cup : [0.005, 0.343, 0.058, 0.398]\n\n<keyboard: [0.084, 0.372, 0.64, 0.668]> <white, computer, older-model>\n<computer mouse: [0.674, 0.43, 0.746, 0.58]> <black, computer>\n<mouse pad: [0.625, 0.367, 0.906, 0.61]> <mouse>\n<key: [0.101, 0.458, 0.13, 0.485]> <dark>\n<key: [0.101, 0.517, 0.13, 0.543]> <dark>\n<key: [0.101, 0.552, 0.135, 0.57]> <dark>\n<key: [0.145, 0.447, 0.17, 0.477]> <light>\n<key: [0.15, 0.493, 0.17, 0.512]> <light>\n<pad: [0.625, 0.362, 0.906, 0.608]> <mouse>\n<key: [0.47, 0.527, 0.504, 0.56]> <arrow>\n<key: [0.45, 0.56, 0.475, 0.59]> <arrow>\n<key: [0.47, 0.553, 0.499, 0.583]> <arrow>\n<key: [0.494, 0.56, 0.522, 0.583]> <arrow>\n<button: [0.2, 0.25, 0.217, 0.268]> <monitor, adjustment>\n<button: [0.287, 0.243, 0.305, 0.262]> <monitor, adjustment>\n<button: [0.31, 0.243, 0.324, 0.262]> <monitor, adjustment>\n<button: [0.33, 0.243, 0.347, 0.255]> <monitor, adjustment>\n<button: [0.364, 0.237, 0.374, 0.25]> <monitor, adjustment>\n<monitor: [0.004, 0.003, 0.565, 0.367]> <old-style, computer>\n<speaker: [0.805, 0.107, 0.941, 0.3]> <computer, laying on it's back, white>\n<paper: [0.52, 0.062, 0.776, 0.288]> <one piece>\n<key: [0.389, 0.507, 0.441, 0.54]> <grey>\n<key: [0.374, 0.533, 0.44, 0.572]> <grey>\n<key: [0.354, 0.58, 0.383, 0.603]> <grey>\n<key: [0.384, 0.565, 0.412, 0.598]> <grey>\n<key: [0.412, 0.565, 0.441, 0.598]> <grey>\n<dell computer: [0.005, 0.0, 0.639, 0.67]> <DELL>\n<cord: [0.81, 0.533, 0.993, 0.622]> <black>\n<cup: [0.0, 0.205, 0.062, 0.387]> <white, coffee cup>\n<desk: [0.004, 0.003, 0.998, 0.992]> <white>\n<mouse: [0.67, 0.427, 0.744, 0.577]> <pink>\n<mousepad: [0.627, 0.36, 0.907, 0.603]> <pink>\n<cup: [0.889, 0.288, 0.989, 0.455]> <paper>\n<computer desk: [0.0, 0.003, 0.998, 0.992]> <curved, beige>\n<paper: [0.71, 0.438, 0.996, 0.937]> <white, sheet>\n", "response": "Task: What is the make of the computer keyboard in the <Region>[0.084, 0.372, 0.64, 0.668]</Region>?\nOutput: The make of the computer keyboard is Dell.", "instruction": "What is the make of the computer keyboard in the <Region>[0.084, 0.372, 0.64, 0.668]</Region>?", "input": "", "output": "The make of the computer keyboard is Dell.", "is_classification": false, "dataset": "VG", "img_info": "1670.jpg"}
{"img_id": 285785, "query": "Brown wallet next to computer: [0.229, 0.547, 0.858, 0.915]\nBrown wallet next to computer: [0.229, 0.547, 0.858, 0.915]\nFace of a silver watch: [0.776, 0.607, 0.97, 0.762]\na cord for a laptop computer: [0.725, 0.117, 0.979, 0.604]\nSilver watch on top of wallet: [0.715, 0.566, 0.981, 0.956]\nFace of a watch: [0.778, 0.613, 0.974, 0.767]\nUSB port in the laptop: [0.214, 0.528, 0.277, 0.614]\nthe laptop is black : [0.1, 0.487, 0.175, 0.55]\na keyboard for a laptop computer: [0.053, 0.047, 0.931, 0.529]\na view of lights: [0.389, 0.098, 0.64, 0.257]\n\n<watch: [0.646, 0.559, 0.963, 0.994]> <silver>\n<band: [0.709, 0.73, 0.921, 0.991]> <thick>\n<light: [0.42, 0.081, 0.512, 0.189]> <blue, bright>\n<laptop: [0.111, 0.245, 0.22, 0.433]> <black>\n<watch: [0.822, 0.632, 0.941, 0.718]> <Face>\n<watch: [0.7, 0.581, 0.989, 0.99]> <silver>\n<picture: [0.01, 0.021, 0.998, 0.969]> <indoors>\n<wallet: [0.251, 0.537, 0.827, 0.946]> <brown>\n<computer: [0.051, 0.1, 0.817, 0.516]> <silver, Wallet>\n<computer: [0.015, 0.022, 0.938, 0.682]> <silver>\n", "response": "Task: What color is the laptop indicated by <Region>[0.051, 0.1, 0.817, 0.516]</Region>? \nOutput: The laptop in the region is silver in color.", "instruction": "What color is the laptop indicated by <Region>[0.051, 0.1, 0.817, 0.516]</Region>?", "input": "", "output": "The laptop in the region is silver in color.", "is_classification": false, "dataset": "VG", "img_info": "285785.jpg"}
{"img_id": 498060, "query": "a bottle on the shelf: [0.604, 0.081, 0.664, 0.214]\na bottle on the shelf: [0.602, 0.086, 0.652, 0.206]\na bathroom toilet: [0.272, 0.745, 0.402, 0.982]\nbottles on hanging shelf: [0.546, 0.072, 0.686, 0.266]\nA white toilet bowl.: [0.312, 0.812, 0.519, 0.995]\nthe toilet is white: [0.313, 0.585, 0.696, 0.997]\nthe pump bottle is white: [0.579, 0.073, 0.621, 0.228]\na white bathroom toilet: [0.304, 0.789, 0.497, 0.996]\nA white toilet. : [0.251, 0.556, 0.657, 0.995]\na toilet is white: [0.344, 0.747, 0.58, 1.0]\n\n<bottle: [0.609, 0.065, 0.657, 0.238]> <green>\n<toilet: [0.288, 0.797, 0.506, 0.997]> <white>\n<toilet: [0.278, 0.736, 0.512, 0.973]> <white>\n<toilet: [0.325, 0.742, 0.536, 0.945]> <white>\n<towels: [0.002, 0.24, 0.08, 0.924]> <white>\n", "response": "Task: Are there any objects with a color other than white on the toilet bowl indicated by <Region>[0.312, 0.812, 0.519, 0.995]</Region>?\nOutput: No, there are no objects with a color other than white on the toilet bowl.", "instruction": "Are there any objects with a color other than white on the toilet bowl indicated by <Region>[0.312, 0.812, 0.519, 0.995]</Region>?", "input": "", "output": "No, there are no objects with a color other than white on the toilet bowl.", "is_classification": false, "dataset": "VG", "img_info": "498060.jpg"}
{"img_id": 1159420, "query": "sideview mirror is black: [0.733, 0.332, 0.826, 0.499]\nman wearing a brown business suit: [0.0, 0.499, 0.281, 0.996]\nblack door handle on the door: [0.589, 0.556, 0.626, 0.679]\nthis is an outdoors scene: [0.366, 0.802, 0.404, 0.804]\nside view mirror on the truck: [0.712, 0.328, 0.932, 0.698]\nthis is an outdoors scene: [0.366, 0.802, 0.404, 0.804]\nman wearing gray suit: [0.216, 0.492, 0.403, 0.987]\nside view mirror on the truck: [0.712, 0.328, 0.932, 0.698]\nblack mirrors on door: [0.694, 0.1, 0.827, 0.489]\nthis is an outdoors scene: [0.366, 0.802, 0.404, 0.804]\n\n<mirror: [0.738, 0.338, 0.82, 0.496]> <black>\n<mirror: [0.717, 0.075, 0.814, 0.335]> <black>\n<window: [0.598, 0.102, 0.903, 0.536]> <door window>\n<handle: [0.587, 0.561, 0.624, 0.684]> <black>\n<suit: [0.002, 0.496, 0.352, 0.988]> <brown>\n<suit: [0.218, 0.493, 0.4, 0.977]> <gray>\n<scene: [0.365, 0.789, 0.407, 0.817]> <outdoors>\n", "response": "Task: What is the color of the side view mirror on the truck, located at <Region>[0.712, 0.328, 0.932, 0.698]</Region>?\nOutput: The side view mirror on the truck in this region is black.", "instruction": "What is the color of the side view mirror on the truck, located at <Region>[0.712, 0.328, 0.932, 0.698]</Region>?", "input": "", "output": "The side view mirror on the truck in this region is black.", "is_classification": false, "dataset": "VG", "img_info": "1159420.jpg"}
{"img_id": 285707, "query": "man wearing a yellow shirt: [0.243, 0.296, 0.461, 0.727]\nman wearing a yellow shirt: [0.243, 0.296, 0.461, 0.727]\na person wearin ga shirt: [0.263, 0.337, 0.566, 0.768]\nthe chest of the dog is white: [0.594, 0.419, 0.662, 0.581]\na person wearing a red hat: [0.332, 0.181, 0.469, 0.575]\nthe dog is wearing a collar: [0.599, 0.432, 0.654, 0.489]\na person wearing a hat: [0.319, 0.286, 0.398, 0.448]\nthe man's shirt is yellow: [0.252, 0.416, 0.444, 0.597]\nA man wearing a yellow shirt. : [0.263, 0.416, 0.434, 0.584]\na person wearin ga shirt: [0.263, 0.337, 0.566, 0.768]\n\n<chest: [0.604, 0.498, 0.652, 0.575]> <white>\n<shirt: [0.257, 0.41, 0.438, 0.616]> <yellow>\n<collar: [0.565, 0.381, 0.665, 0.498]> <blue>\n<shirt: [0.244, 0.439, 0.504, 0.651]> <yellow>\n<hat: [0.306, 0.293, 0.443, 0.423]> <red>\n", "response": "Task: What color is the collar on the dog indicated by <Region>[0.599, 0.432, 0.654, 0.489]</Region>?\nOutput: The collar on the dog is blue.", "instruction": "What color is the collar on the dog indicated by <Region>[0.599, 0.432, 0.654, 0.489]</Region>?", "input": "", "output": "The collar on the dog is blue.", "is_classification": false, "dataset": "VG", "img_info": "285707.jpg"}
{"img_id": 4079, "query": "pillow sits on bed: [0.479, 0.365, 0.682, 0.486]\npillow sits on bed: [0.322, 0.34, 0.637, 0.475]\nfluffy pillow is on a bed: [0.331, 0.34, 0.672, 0.477]\nside table is wooden: [0.0, 0.484, 0.299, 0.742]\nblue and black rug on floor: [0.019, 0.693, 0.749, 0.994]\ntable has a brown drawer: [0.129, 0.557, 0.264, 0.713]\npillow on the bed: [0.691, 0.354, 0.855, 0.465]\nfluffy pillow is on a bed: [0.637, 0.328, 0.942, 0.445]\nA grey and white pillow behind the green one. : [0.63, 0.328, 0.961, 0.447]\ntwo pictures hanging on the wall: [0.45, 0.143, 0.775, 0.303]\n\n<pillows: [0.338, 0.334, 0.965, 0.473]> <matching>\n<pillow: [0.502, 0.338, 0.952, 0.539]> <green, beige>\n<comforter: [0.408, 0.492, 0.987, 0.9]> <white, swirled>\n<phone: [0.148, 0.449, 0.257, 0.547]> <small, white>\n<pictures: [0.373, 0.127, 0.817, 0.324]> <hanging>\n<pictures: [0.415, 0.139, 0.659, 0.35]> <hanging, brown>\n<pictures: [0.624, 0.146, 0.846, 0.361]> <brown, hanging>\n<pillow: [0.305, 0.338, 0.682, 0.5]> <white>\n<pillow: [0.669, 0.311, 0.904, 0.482]> <white>\n<lamp shade: [0.013, 0.328, 0.199, 0.418]> <white>\n<drawer: [0.096, 0.537, 0.35, 0.723]> <brown>\n<handle: [0.106, 0.621, 0.206, 0.676]> <black>\n<handle: [0.106, 0.629, 0.19, 0.66]> <black>\n<phone: [0.154, 0.447, 0.286, 0.533]> <old, white>\n<pillow: [0.28, 0.324, 0.662, 0.465]> <fluffy>\n<pillow: [0.524, 0.328, 0.984, 0.459]> <fluffy>\n<pillow: [0.653, 0.363, 0.794, 0.445]> <fluffy>\n<pillow: [0.588, 0.328, 0.958, 0.49]> <fluffy>\n<table: [0.0, 0.488, 0.325, 0.703]> <brown>\n<table: [0.006, 0.51, 0.379, 0.73]> <brown>\n<table: [0.029, 0.453, 0.392, 0.725]> <side, wooden>\n<lamp shade: [0.0, 0.314, 0.219, 0.465]> <white>\n<rug: [0.1, 0.742, 0.579, 0.996]> <black, patterned>\n<cover: [0.466, 0.396, 0.846, 0.641]> <white>\n<nightstand door: [0.138, 0.547, 0.28, 0.705]> <closed>\n<nightstand door: [0.013, 0.574, 0.141, 0.75]> <closed>\n", "response": "Task: What color are the handles of the brown drawer in <Region>[0.096, 0.537, 0.35, 0.723]</Region>?\nOutput: The handles of the brown drawer in that region are black.", "instruction": "What color are the handles of the brown drawer in <Region>[0.096, 0.537, 0.35, 0.723]</Region>?", "input": "", "output": "The handles of the brown drawer in that region are black.", "is_classification": false, "dataset": "VG", "img_info": "4079.jpg"}
{"img_id": 285624, "query": "a teddy bear in a stroller: [0.278, 0.393, 0.785, 0.993]\nPink teddy bear strapped into stroller: [0.277, 0.466, 0.761, 0.905]\nPink plastic clamp on stroller: [0.193, 0.558, 0.294, 0.655]\nPink threaded nose: [0.425, 0.613, 0.462, 0.646]\npink nose on bear: [0.371, 0.596, 0.527, 0.681]\nthe bear is strapped in: [0.291, 0.44, 0.718, 0.973]\nthe bear is strapped in: [0.291, 0.44, 0.718, 0.973]\na bear with pink nose: [0.424, 0.426, 0.635, 0.76]\nPink bow with black dots.: [0.394, 0.64, 0.571, 0.762]\nBlack handles on stroller: [0.035, 0.041, 0.611, 0.323]\n\n<crown pattern: [0.313, 0.344, 0.444, 0.49]> <orange>\n<stroller: [0.05, 0.04, 0.942, 0.998]> <FOR SMALL CHILD>\n<bear: [0.278, 0.462, 0.752, 0.935]> <pink>\n<strap: [0.277, 0.555, 0.54, 0.853]> <pink>\n<buckle: [0.444, 0.76, 0.533, 0.851]> <plastic>\n<nose: [0.424, 0.613, 0.467, 0.646]> <pink, threaded>\n<clamp: [0.208, 0.555, 0.304, 0.669]> <pink, plastic>\n<ribbon: [0.398, 0.626, 0.58, 0.771]> <pink>\n<cloth: [0.186, 0.298, 0.909, 0.997]> <pink>\n<foot: [0.392, 0.81, 0.531, 0.916]> <pink>\n<bear: [0.312, 0.456, 0.739, 0.919]> <TEDDY>\n<crown: [0.304, 0.344, 0.439, 0.485]> <gold>\n<fabric: [0.179, 0.295, 0.918, 0.998]> <pink>\n<straps: [0.579, 0.498, 0.635, 0.836]> <SAFETY>\n<straps: [0.311, 0.604, 0.539, 0.846]> <SAFETY>\n<handle: [0.479, 0.038, 0.596, 0.271]> <BLACK, PINK, STROLLER>\n<handle: [0.014, 0.065, 0.16, 0.314]> <BLACK, PINK, STROLLER>\n<teddy bear: [0.302, 0.441, 0.739, 0.912]> <SHAGGY, PINK, WOOLY>\n<bow: [0.403, 0.631, 0.598, 0.758]> <PINK>\n<dots: [0.514, 0.665, 0.524, 0.678]> <BLACK>\n<nose: [0.423, 0.606, 0.47, 0.645]> <PINK>\n<feet: [0.391, 0.785, 0.746, 0.912]> <BEAR'S>\n<bars: [0.114, 0.33, 0.347, 0.784]> <GREEN>\n<bars: [0.576, 0.289, 0.798, 0.684]> <GREEN>\n<seat: [0.1, 0.252, 0.919, 0.982]> <PINK>\n<straps: [0.294, 0.494, 0.639, 0.868]> <PINK>\n<design: [0.307, 0.34, 0.461, 0.486]> <PINK, ORANGISH, CROWN>\n<handle: [0.478, 0.032, 0.604, 0.269]> <BLACK>\n<handle: [0.021, 0.06, 0.159, 0.305]> <BLACK>\n<bow: [0.403, 0.612, 0.594, 0.771]> <LITTLE, PINK>\n<nose: [0.423, 0.604, 0.472, 0.645]> <BRIGHT PINK>\n<nose: [0.418, 0.608, 0.479, 0.649]> <PINK>\n<ribbon: [0.399, 0.627, 0.592, 0.775]> <PINK>\n<neck: [0.405, 0.632, 0.558, 0.721]> <BEAR'S>\n<chain: [0.237, 0.736, 0.328, 0.981]> <PINK, FUZZY, KEY>\n<squares: [0.034, 0.73, 0.188, 0.837]> <GREEN>\n<button: [0.445, 0.566, 0.484, 0.599]> <BLACK>\n", "response": "Task: What is the object indicated in <Region>[0.193, 0.558, 0.294, 0.655]</Region>, and what is its color?\nOutput: The object in the indicated region is a pink plastic clamp that may fasten the stroller's belt or canopy. Its color is pink.", "instruction": "What is the object indicated in <Region>[0.193, 0.558, 0.294, 0.655]</Region>, and what is its color?", "input": "", "output": "The object in the indicated region is a pink plastic clamp that may fasten the stroller's belt or canopy. Its color is pink.", "is_classification": false, "dataset": "VG", "img_info": "285624.jpg"}
{"img_id": 498107, "query": "A gray shirt on a tennis player: [0.162, 0.27, 0.395, 0.823]\nman wearing green shirt and blue cap: [0.481, 0.721, 0.751, 0.997]\nMan in green shirt with blue hat.: [0.492, 0.726, 0.742, 0.997]\nteenis player wearing gray shirt: [0.155, 0.037, 0.597, 0.994]\nwoman sitting behind a fence wearing yellow shirt: [0.051, 0.295, 0.197, 0.62]\na light grey colored tshirt: [0.15, 0.258, 0.373, 0.839]\nman wearing gray shirt: [0.148, 0.243, 0.382, 0.884]\nman wearing green shirt and blue cap: [0.481, 0.721, 0.751, 0.997]\nman dressed in a lime green shirt : [0.489, 0.718, 0.734, 0.994]\nA blue hat on a man's head: [0.569, 0.721, 0.651, 0.802]\n\n<shirt: [0.551, 0.837, 0.739, 0.991]> <green>\n<boy: [0.34, 0.545, 0.48, 0.963]> <little>\n<shirt: [0.336, 0.663, 0.482, 0.933]> <blue>\n<green shirt: [0.495, 0.834, 0.733, 0.997]> <green>\n<blue hat: [0.557, 0.695, 0.669, 0.818]> <blue>\n", "response": "Task: What color is the shirt worn by the person in <Region>[0.148, 0.243, 0.382, 0.884]</Region>?\nOutput: The person in that region is wearing a gray shirt.", "instruction": "What color is the shirt worn by the person in <Region>[0.148, 0.243, 0.382, 0.884]</Region>?", "input": "", "output": "The person in that region is wearing a gray shirt.", "is_classification": false, "dataset": "VG", "img_info": "498107.jpg"}
{"img_id": 1159929, "query": " food is in a display: [0.404, 0.76, 0.544, 0.824]\nfood is in a display: [0.788, 0.737, 0.856, 0.792]\nBasket sitting on top of display case: [0.794, 0.528, 0.995, 0.609]\n food is in a display: [0.404, 0.76, 0.544, 0.824]\nfood is in a glass display: [0.219, 0.765, 0.315, 0.83]\nfood is in a glass display: [0.139, 0.784, 0.216, 0.832]\nfood is in a glass display: [0.575, 0.918, 0.631, 0.972]\nfood is in a display: [0.425, 0.742, 0.528, 0.775]\nfood is in a display: [0.784, 0.739, 0.851, 0.789]\na red basket: [0.204, 0.562, 0.381, 0.623]\n\n<basket: [0.788, 0.523, 0.995, 0.634]> <wire>\n<basket: [0.188, 0.551, 0.402, 0.636]> <red>\n<donut: [0.299, 0.93, 0.402, 0.99]> <brown>\n<display: [0.005, 0.652, 0.949, 0.997]> <glass>\n<display: [0.02, 0.639, 0.959, 0.966]> <glass>\n<display: [0.005, 0.629, 0.949, 0.85]> <glass>\n", "response": "Task: Can you specify the type of material used to make the basket in <Region>[0.788, 0.523, 0.995, 0.634]</Region>?\nOutput: The basket in that region is made of wire.", "instruction": "Can you specify the type of material used to make the basket in <Region>[0.788, 0.523, 0.995, 0.634]</Region>?", "input": "", "output": "The basket in that region is made of wire.", "is_classification": false, "dataset": "VG", "img_info": "1159929.jpg"}
{"img_id": 1592861, "query": "the bus is red and white: [0.627, 0.606, 0.76, 0.824]\nwhite framed door on side of bus: [0.051, 0.634, 0.169, 0.9]\nthe bus is red and white: [0.627, 0.606, 0.76, 0.824]\nThe buildings in the background : [0.526, 0.498, 0.706, 0.583]\nred electric bus is parked: [0.383, 0.627, 0.446, 0.802]\nelectric sign on the bus: [0.67, 0.614, 0.707, 0.654]\nred electric bus is parked: [0.245, 0.602, 0.29, 0.866]\nThe front tire of the bus: [0.56, 0.741, 0.599, 0.796]\nthe doors on the bus: [0.049, 0.631, 0.17, 0.878]\nthe doors on the bus: [0.049, 0.631, 0.17, 0.878]\n\n<bus: [0.622, 0.62, 0.762, 0.835]> <parked, red>\n<bus: [0.0, 0.563, 0.218, 0.931]> <parked, red, white>\n<bus: [0.196, 0.594, 0.25, 0.872]> <red, parked>\n<bus: [0.272, 0.605, 0.354, 0.846]> <red, parked>\n<display: [0.671, 0.62, 0.73, 0.662]> <digital>\n<buildings: [0.52, 0.508, 0.71, 0.602]> <in the background>\n<mountains: [0.001, 0.427, 0.679, 0.656]> <in the background>\n<bus: [0.381, 0.617, 0.447, 0.806]> <parked, red, electric>\n<bus: [0.33, 0.602, 0.386, 0.83]> <electric, red, parked>\n<bus: [0.281, 0.602, 0.345, 0.849]> <parked, red, electric>\n<bus: [0.239, 0.608, 0.286, 0.846]> <electric, red, parked>\n<bus: [0.206, 0.594, 0.247, 0.886]> <parked, red, electric>\n<bus: [0.0, 0.591, 0.21, 0.915]> <electric, red, parked>\n<bus: [0.233, 0.597, 0.285, 0.844]> <parked, red, electric>\n<buses: [0.006, 0.526, 0.456, 0.944]> <parked>\n<parking lot: [0.282, 0.802, 0.576, 0.986]> <paved>\n<street lamp: [0.125, 0.164, 0.177, 0.485]> <tall>\n<bus: [0.628, 0.591, 0.814, 0.826]> <parked>\n<bus: [0.368, 0.622, 0.46, 0.843]> <parked>\n", "response": "Task: What is the color of the electric sign on the <Region>[0.628, 0.591, 0.814, 0.826]</Region>?\nOutput: There is no electric sign in that region. However, the region does contain a parked bus that is red and white in color.", "instruction": "What is the color of the electric sign on the <Region>[0.628, 0.591, 0.814, 0.826]</Region>?", "input": "", "output": "There is no electric sign in that region. However, the region does contain a parked bus that is red and white in color.", "is_classification": false, "dataset": "VG", "img_info": "1592861.jpg"}
{"img_id": 4632, "query": "A gold framed picture.: [0.791, 0.068, 0.998, 0.403]\npicture frame beside the lamp: [0.203, 0.459, 0.264, 0.609]\ndoor has a window panel: [0.684, 0.174, 0.711, 0.253]\ndoor has a window panel: [0.684, 0.174, 0.711, 0.253]\ndoor has a window panel: [0.711, 0.171, 0.74, 0.25]\ndoor has a window panel: [0.0, 0.212, 0.047, 0.321]\ndoor has a window panel: [0.008, 0.309, 0.051, 0.403]\npicture frame on the table: [0.203, 0.456, 0.256, 0.591]\ndoor has a window panel: [0.055, 0.397, 0.102, 0.491]\ndoor has a window panel: [0.0, 0.212, 0.047, 0.321]\n\n<lamp: [0.24, 0.374, 0.305, 0.565]> <table, off>\n<door: [0.004, 0.165, 0.139, 0.824]> <white>\n<panes: [0.0, 0.209, 0.109, 0.494]> <glass>\n<loveseat: [0.297, 0.512, 0.719, 0.824]> <low>\n<window: [0.678, 0.179, 0.762, 0.515]> <closed>\n<floor: [0.023, 0.732, 0.861, 0.985]> <wooden>\n<pillow: [0.381, 0.544, 0.479, 0.679]> <throw>\n<seat: [0.336, 0.535, 0.703, 0.809]> <love>\n<chair: [0.002, 0.497, 0.209, 0.991]> <brown>\n<sconce: [0.334, 0.25, 0.367, 0.371]> <candle>\n<rocking chair: [0.0, 0.526, 0.199, 0.985]> <wooden>\n<picture: [0.787, 0.106, 0.967, 0.379]> <framed>\n<frame: [0.207, 0.456, 0.252, 0.597]> <picture>\n<frame: [0.793, 0.047, 0.969, 0.403]> <gold>\n<picture: [0.822, 0.147, 0.953, 0.347]> <framed>\n<chair: [0.002, 0.529, 0.191, 0.979]> <rocking, wood>\n<rug: [0.5, 0.812, 0.623, 0.956]> <area, dark colors>\n<table: [0.172, 0.597, 0.32, 0.8]> <end, wood>\n<lamp: [0.242, 0.459, 0.301, 0.585]> <white>\n<shade: [0.229, 0.371, 0.301, 0.479]> <lamp>\n<blinds: [0.668, 0.171, 0.746, 0.479]> <white, horizontal>\n<panel: [0.045, 0.209, 0.094, 0.309]> <window>\n<panel: [0.049, 0.312, 0.096, 0.409]> <window>\n<panel: [0.053, 0.394, 0.1, 0.491]> <window>\n<panel: [0.014, 0.4, 0.059, 0.479]> <window>\n<panel: [0.0, 0.4, 0.018, 0.503]> <window>\n<panel: [0.008, 0.306, 0.057, 0.403]> <window>\n<panel: [0.688, 0.179, 0.713, 0.256]> <window>\n<panel: [0.719, 0.168, 0.744, 0.256]> <window>\n<table lamp: [0.232, 0.379, 0.297, 0.594]> <black>\n<shade: [0.232, 0.376, 0.295, 0.459]> <white>\n<chair: [0.0, 0.503, 0.236, 0.994]> <wooden>\n", "response": "Task: Is there a candle in the <Region>[0.334, 0.25, 0.367, 0.371]</Region>? \nOutput: Yes, there is a candle in that region.", "instruction": "Is there a candle in the <Region>[0.334, 0.25, 0.367, 0.371]</Region>?", "input": "", "output": "Yes, there is a candle in that region.", "is_classification": false, "dataset": "VG", "img_info": "4632.jpg"}
{"img_id": 3237, "query": " a car in a parking lot : [0.586, 0.873, 0.63, 0.91]\nwhite cloud in the sky: [0.259, 0.122, 0.334, 0.212]\nWhite truck on the other side of fence.: [0.448, 0.85, 0.631, 0.895]\nwhite cloud in the sky: [0.751, 0.602, 0.812, 0.688]\nA cloud in the sky.: [0.175, 0.322, 0.395, 0.508]\nrow of street lights : [0.026, 0.443, 0.994, 0.953]\n a car in a parking lot : [0.273, 0.855, 0.354, 0.897]\nWhite clouds in the sky: [0.0, 0.01, 0.996, 0.815]\nthe street lights are metal: [0.515, 0.557, 0.639, 0.87]\nConcrete next to a black fence.: [0.391, 0.752, 0.441, 0.918]\n\n<petals: [0.271, 0.867, 0.32, 0.933]> <purple>\n<fern: [0.752, 0.742, 0.974, 0.988]> <green>\n<fence: [0.065, 0.778, 0.818, 0.927]> <black>\n<sky: [0.004, 0.005, 0.998, 0.837]> <white>\n<truck: [0.524, 0.853, 0.631, 0.89]> <white>\n<concrete: [0.454, 0.967, 0.71, 0.993]> <black>\n<street light: [0.499, 0.617, 0.565, 0.892]> <row>\n<flowers: [0.188, 0.857, 0.321, 0.938]> <purple>\n<sidewalk: [0.314, 0.923, 0.759, 0.993]> <grey>\n<car: [0.006, 0.827, 0.343, 0.993]> <white>\n", "response": "Task: What is the color of the truck indicated by <Region>[0.524, 0.853, 0.631, 0.89]</Region>?\nOutput: The color of the truck in the indicated region is white.", "instruction": "What is the color of the truck indicated by <Region>[0.524, 0.853, 0.631, 0.89]</Region>?", "input": "", "output": "The color of the truck in the indicated region is white.", "is_classification": false, "dataset": "VG", "img_info": "3237.jpg"}
{"img_id": 3089, "query": "A silver car in front of the house.: [0.59, 0.543, 0.996, 0.812]\nthe suv is parked: [0.585, 0.537, 0.999, 0.818]\ngray car parked in the street: [0.585, 0.537, 0.998, 0.81]\ncar parked in a driveway: [0.01, 0.448, 0.255, 0.768]\na metal black fence: [0.256, 0.61, 0.59, 0.758]\nA silver car parked behind the fence.: [0.041, 0.522, 0.199, 0.673]\nA brown car parked behind the fence.: [0.391, 0.575, 0.451, 0.683]\nA silver car in front of the house.: [0.59, 0.543, 0.996, 0.812]\nthe cone is orange: [0.221, 0.563, 0.246, 0.622]\nA silver car parked behind the fence.: [0.041, 0.522, 0.199, 0.673]\n\n<cone: [0.226, 0.56, 0.269, 0.62]> <orange>\n<car: [0.606, 0.555, 0.998, 0.787]> <silver>\n<car: [0.048, 0.505, 0.21, 0.638]> <silver>\n<car: [0.051, 0.5, 0.247, 0.715]> <brown>\n<suv: [0.591, 0.543, 0.996, 0.823]> <silver>\n<fence: [0.285, 0.632, 0.495, 0.772]> <metal>\n", "response": "Task: What color is the fence in the <Region>[0.285, 0.632, 0.495, 0.772]</Region>?\nOutput: The color of the fence in the mentioned region is not specified, but it is described as being made of metal.", "instruction": "What color is the fence in the <Region>[0.285, 0.632, 0.495, 0.772]</Region>?", "input": "", "output": "The color of the fence in the mentioned region is not specified, but it is described as being made of metal.", "is_classification": false, "dataset": "VG", "img_info": "3089.jpg"}
{"img_id": 712969, "query": "small orange boat in water: [0.681, 0.804, 0.839, 0.873]\nLarge white boat base next to an orange boat.: [0.183, 0.695, 0.74, 0.887]\na white rope attached to a boat: [0.563, 0.775, 0.76, 0.882]\nbow of white boat: [0.174, 0.699, 0.731, 0.889]\na small orange boat: [0.69, 0.775, 0.813, 0.869]\nwhite boat in the dock : [0.696, 0.704, 0.84, 0.815]\nOrange and black boat with white top.: [0.674, 0.804, 0.831, 0.865]\nOrange boat next to white boat : [0.683, 0.779, 0.85, 0.875]\nreflection of boat in water: [0.213, 0.872, 0.638, 0.998]\nwindshield on the boat: [0.709, 0.817, 0.773, 0.839]\n\n<sky: [0.052, 0.046, 0.96, 0.692]> <daytime, blue, clear>\n<tree: [0.034, 0.474, 0.16, 0.649]> <palm>\n<boat: [0.164, 0.008, 0.769, 0.896]> <white, in water>\n<dock: [0.019, 0.783, 0.276, 0.889]> <cement>\n<flags: [0.159, 0.113, 0.413, 0.671]> <assorted>\n<boat: [0.292, 0.717, 0.801, 0.895]> <white>\n<surface: [0.273, 0.883, 0.784, 0.958]> <water>\n<boat: [0.668, 0.786, 0.844, 0.865]> <orange>\n<boat: [0.256, 0.01, 0.753, 0.897]> <white>\n<water body: [0.018, 0.77, 0.969, 0.99]> <large>\n<boat: [0.674, 0.778, 0.832, 0.864]> <small, orange>\n<ship: [0.167, 0.014, 0.739, 0.892]> <large, white>\n<palm tree: [0.032, 0.48, 0.154, 0.603]> <standing, large>\n<flags: [0.149, 0.044, 0.351, 0.612]> <flying in air>\n<lamp post: [0.047, 0.599, 0.115, 0.82]> <large, white>\n<boat: [0.669, 0.794, 0.837, 0.872]> <orange>\n", "response": "Task: What is the object in <Region>[0.292, 0.717, 0.801, 0.895]</Region> and what is its color? Is the boat in the water or on the dock?\nOutput: The object in the region is a white boat. The boat is in the water.", "instruction": "What is the object in <Region>[0.292, 0.717, 0.801, 0.895]</Region> and what is its color? Is the boat in the water or on the dock?", "input": "", "output": "The object in the region is a white boat. The boat is in the water.", "is_classification": false, "dataset": "VG", "img_info": "712969.jpg"}
{"img_id": 231, "query": "light on the car: [0.584, 0.723, 0.625, 0.743]\nRose bushes behind a fence at a house: [0.526, 0.423, 0.894, 0.668]\nlittle silver car driving down the street: [0.568, 0.552, 0.871, 0.84]\na stone retaining wall in front of the house: [0.055, 0.64, 0.5, 0.845]\nRose bushes behind a fence at a house: [0.526, 0.423, 0.894, 0.668]\ncar has four doors: [0.539, 0.648, 0.871, 0.828]\nwheel of the car: [0.814, 0.775, 0.85, 0.838]\nblack wires over car: [0.247, 0.107, 0.688, 0.342]\nblack wires over car: [0.247, 0.107, 0.688, 0.342]\nRose bushes behind a fence at a house: [0.526, 0.423, 0.894, 0.668]\n\n<house: [0.164, 0.207, 0.729, 0.585]> <adobe colored>\n<fence: [0.0, 0.517, 0.994, 0.735]> <white>\n<car: [0.535, 0.647, 0.871, 0.823]> <little, silver>\n<house: [0.15, 0.227, 0.74, 0.568]> <metal>\n<retaining wall: [0.0, 0.657, 0.998, 0.835]> <stone>\n<yield sign: [0.823, 0.215, 0.93, 0.848]> <yield>\n<sign: [0.177, 0.683, 0.223, 0.755]> <small>\n<wires: [0.003, 0.047, 0.996, 0.31]> <electrical>\n<sky: [0.0, 0.005, 0.998, 0.44]> <clear, blue>\n", "response": "Task: Is the object in <Region>[0.535, 0.647, 0.871, 0.823]</Region> large or small? What is the color of the fence behind the car?\nOutput: The object in that region is a little silver car, so it is a small object. The fence behind the car is white in color.", "instruction": "Is the object in <Region>[0.535, 0.647, 0.871, 0.823]</Region> large or small? What is the color of the fence behind the car?", "input": "", "output": "The object in that region is a little silver car, so it is a small object. The fence behind the car is white in color.", "is_classification": false, "dataset": "VG", "img_info": "231.jpg"}
{"img_id": 1088, "query": "a blue and red baseball shirt: [0.815, 0.279, 0.953, 0.415]\nthe man wearing black shoes: [0.775, 0.249, 0.96, 0.526]\na tan catchers mitt: [0.325, 0.588, 0.425, 0.659]\nleft shoe of player pitching ball: [0.26, 0.743, 0.345, 0.802]\nwhite line on the ground: [0.638, 0.603, 0.752, 0.719]\nshoe on man's foot: [0.22, 0.74, 0.363, 0.818]\nshirt has a red logo on front: [0.363, 0.569, 0.595, 0.701]\nhand holding a glove: [0.328, 0.593, 0.425, 0.645]\nbaseball glove in players hand: [0.32, 0.598, 0.418, 0.644]\n blue and red baseball cap: [0.358, 0.179, 0.422, 0.211]\n\n<cap: [0.358, 0.179, 0.42, 0.209]> <blue, red>\n<glove: [0.338, 0.604, 0.412, 0.636]> <leather>\n<shoe: [0.64, 0.667, 0.692, 0.704]> <black>\n<dhl: [0.793, 0.104, 0.997, 0.477]> <yellow>\n<pipes: [0.008, 0.005, 0.79, 0.136]> <green>\n<shirt: [0.817, 0.281, 0.948, 0.415]> <blue, red>\n<hat: [0.44, 0.52, 0.535, 0.594]> <red, blue>\n<mitt: [0.322, 0.589, 0.422, 0.657]> <tan>\n<jacket: [0.792, 0.261, 0.982, 0.439]> <blue, red>\n<white line: [0.642, 0.6, 0.752, 0.713]> <white>\n<player: [0.268, 0.156, 0.597, 0.426]> <bent over>\n<catcher's mitt: [0.253, 0.247, 0.328, 0.296]> <black>\n<red number: [0.433, 0.228, 0.49, 0.269]> <red>\n<sign: [0.763, 0.11, 0.988, 0.461]> <red, yellow>\n", "response": "Task: What is the color of the shoelaces on the shoe indicated by <Region>[0.22, 0.74, 0.363, 0.818]</Region>? \nOutput: The image does not provide any information regarding the color of the shoelaces of the shoe indicated by the given region.", "instruction": "What is the color of the shoelaces on the shoe indicated by <Region>[0.22, 0.74, 0.363, 0.818]</Region>?", "input": "", "output": "The image does not provide any information regarding the color of the shoelaces of the shoe indicated by the given region.", "is_classification": false, "dataset": "VG", "img_info": "1088.jpg"}
{"img_id": 32, "query": "plates  inside cabinets : [0.389, 0.425, 0.554, 0.502]\nwooden cabinets with silver handles: [0.269, 0.808, 0.425, 0.998]\nmetal door handle: [0.791, 0.875, 0.844, 0.902]\nThe cabinets are wooden: [0.514, 0.187, 0.877, 0.55]\nutensils hanging on wall rack under cabinets: [0.584, 0.522, 0.917, 0.743]\nelectrical outlet and switch: [0.35, 0.565, 0.384, 0.627]\nutensils are present: [0.003, 0.338, 0.983, 0.978]\nmetal cabinet door handle: [0.61, 0.44, 0.63, 0.507]\nReflections on the countertop: [0.599, 0.727, 0.892, 0.907]\nutensils made from steel: [0.735, 0.537, 0.943, 0.743]\n\n<sink: [0.331, 0.692, 0.54, 0.763]> <steel, empty, stainless, silver>\n<faucet: [0.448, 0.6, 0.568, 0.765]> <silver, single handled>\n<dishwasher: [0.448, 0.795, 0.704, 1.0]> <white, automatic>\n<counter: [0.051, 0.61, 0.956, 0.873]> <black, granite, clean, marbled>\n<refrigerator: [0.0, 0.343, 0.07, 1.0]> <refrigerator, white, big>\n<door: [0.318, 0.0, 0.529, 0.525]> <glass>\n<cabinet: [0.0, 0.002, 0.943, 0.547]> <wood>\n<wall: [0.048, 0.525, 0.95, 0.72]> <tiled>\n<cabinet: [0.055, 0.73, 0.938, 0.997]> <wooden>\n<outlet: [0.16, 0.567, 0.379, 0.625]> <wall>\n<potato masher: [0.8, 0.54, 0.839, 0.7]> <potato masher>\n<handle: [0.134, 0.455, 0.815, 0.513]> <metal>\n<books: [0.357, 0.038, 0.524, 0.183]> <colored>\n<mugs: [0.46, 0.328, 0.511, 0.382]> <white>\n<utensils: [0.579, 0.525, 0.939, 0.75]> <steel, a group>\n<plate: [0.46, 0.443, 0.52, 0.498]> <together>\n<cabinets: [0.0, 0.002, 0.943, 0.547]> <wooden>\n<cups: [0.46, 0.328, 0.511, 0.382]> <white>\n<wear: [0.25, 0.503, 0.932, 0.752]> <hanging>\n<handles: [0.134, 0.455, 0.815, 0.513]> <silver>\n<cups: [0.38, 0.328, 0.41, 0.383]> <stacked>\n<cookbooks: [0.335, 0.043, 0.529, 0.172]> <collection>\n<backsplash: [0.394, 0.525, 0.596, 0.657]> <beige>\n<handles: [0.611, 0.453, 0.655, 0.512]> <metallic, silver>\n", "response": "Task: What material is used to make the utensils found in the <Region>[0.579, 0.525, 0.939, 0.75]</Region>?\nOutput: The utensils found in the region are made from steel.", "instruction": "What material is used to make the utensils found in the <Region>[0.579, 0.525, 0.939, 0.75]</Region>?", "input": "", "output": "The utensils found in the region are made from steel.", "is_classification": false, "dataset": "VG", "img_info": "32.jpg"}
{"img_id": 753, "query": "black sign on the brick building: [0.591, 0.545, 0.619, 0.643]\nsign for business: [0.206, 0.388, 0.394, 0.5]\nsmall blue sign with yellow letters: [0.091, 0.575, 0.129, 0.608]\nstore sign with white letters: [0.691, 0.527, 0.752, 0.573]\nsmall blue sign with yellow letters: [0.091, 0.575, 0.129, 0.608]\nseveral brick buildings with stores and residences: [0.003, 0.0, 0.998, 0.757]\nparking space line: [0.636, 0.905, 0.782, 0.968]\nsign for business: [0.206, 0.388, 0.394, 0.5]\nblack sign that says Optica: [0.703, 0.528, 0.752, 0.578]\nblue and yellow sign on building: [0.081, 0.565, 0.141, 0.615]\n\n<building: [0.004, 0.0, 0.704, 0.663]> <brick>\n<sign: [0.596, 0.55, 0.626, 0.645]> <black>\n<letter: [0.091, 0.583, 0.126, 0.598]> <blue, yellow>\n<sign: [0.092, 0.57, 0.135, 0.618]> <small>\n<line: [0.647, 0.912, 0.787, 0.943]> <blue>\n<container: [0.273, 0.657, 0.53, 0.997]> <grey, large>\n<dumpster: [0.006, 0.65, 0.27, 0.958]> <trash>\n<dumpster: [0.279, 0.653, 0.529, 0.997]> <trash>\n", "response": "Task: What is the color scheme of the sign indicated by <Region>[0.703, 0.528, 0.752, 0.578]</Region>, and what business does it represent?\nOutput: The sign is black with white lettering, and it represents an optician's business (Optica).", "instruction": "What is the color scheme of the sign indicated by <Region>[0.703, 0.528, 0.752, 0.578]</Region>, and what business does it represent?", "input": "", "output": "The sign is black with white lettering, and it represents an optician's business (Optica).", "is_classification": false, "dataset": "VG", "img_info": "753.jpg"}
{"img_id": 107949, "query": "A green awning in front of the building. : [0.457, 0.272, 0.548, 0.344]\norange and white construction caution cone: [0.377, 0.493, 0.485, 0.736]\nAn orange construction cone.: [0.175, 0.486, 0.294, 0.688]\nA man wearing a orange hard hat.: [0.568, 0.249, 0.624, 0.321]\ntwo yellow three-light traffic lights: [0.305, 0.199, 0.354, 0.266]\nOrange and white caution rope. : [0.126, 0.716, 0.713, 0.779]\na cone that is white and orange: [0.646, 0.647, 0.761, 0.959]\nA yellow taxi cab driving down the road. : [0.148, 0.259, 0.555, 0.533]\nTwo red rear lights are on: [0.361, 0.375, 0.545, 0.46]\na yellow taxi cab with an advertisement on top: [0.141, 0.262, 0.549, 0.545]\n\n<hard hat: [0.576, 0.258, 0.624, 0.328]> <orange>\n<taxi cab: [0.152, 0.258, 0.545, 0.556]> <yellow>\n<taxi cab: [0.695, 0.334, 0.999, 0.575]> <yellow>\n<rope: [0.127, 0.713, 0.716, 0.747]> <orange, white>\n<taxi cab: [0.121, 0.258, 0.495, 0.514]> <yellow>\n<awning: [0.45, 0.272, 0.541, 0.35]> <green>\n<suit: [0.59, 0.34, 0.698, 0.549]> <orange>\n<cone: [0.208, 0.473, 0.29, 0.69]> <orange, white>\n<cab: [0.722, 0.338, 0.996, 0.556]> <yellow>\n<helment: [0.572, 0.269, 0.628, 0.327]> <red>\n<bus: [0.021, 0.098, 0.209, 0.51]> <city>\n<plate: [0.101, 0.428, 0.145, 0.473]> <white>\n<light: [0.359, 0.389, 0.421, 0.46]> <red>\n<light: [0.499, 0.398, 0.55, 0.469]> <red>\n<worker: [0.566, 0.25, 0.696, 0.6]> <construction>\n", "response": "Task: What is the color of the taxi cab shown in <Region>[0.121, 0.258, 0.495, 0.514]</Region>?\nOutput: The taxi cab shown in the given region is yellow.", "instruction": "What is the color of the taxi cab shown in <Region>[0.121, 0.258, 0.495, 0.514]</Region>?", "input": "", "output": "The taxi cab shown in the given region is yellow.", "is_classification": false, "dataset": "VG", "img_info": "107949.jpg"}
{"img_id": 712986, "query": "fence around the bottom of the tower: [0.356, 0.814, 0.761, 0.942]\nA window on a building.: [0.161, 0.676, 0.199, 0.736]\nA window on a building.: [0.923, 0.685, 0.971, 0.742]\nman in tan hat and vest: [0.256, 0.758, 0.36, 0.99]\nA window on a building.: [0.322, 0.623, 0.359, 0.662]\nbase of the clock tower: [0.373, 0.703, 0.691, 0.918]\nA window on a building.: [0.172, 0.615, 0.204, 0.64]\nclock on the top of tower: [0.52, 0.33, 0.576, 0.389]\nA window on a building.: [0.33, 0.677, 0.365, 0.732]\nA window on a building.: [0.802, 0.769, 0.902, 0.84]\n\n<building: [0.104, 0.507, 0.59, 0.896]> <tan>\n<window: [0.172, 0.624, 0.213, 0.644]> <clear>\n<window: [0.342, 0.779, 0.359, 0.816]> <clear>\n<building: [0.103, 0.553, 0.549, 0.909]> <tan>\n<window: [0.339, 0.758, 0.377, 0.773]> <clear>\n<building: [0.103, 0.551, 0.596, 0.923]> <tan>\n<window: [0.16, 0.68, 0.185, 0.732]> <clear>\n<building: [0.111, 0.616, 0.311, 0.929]> <tan>\n<tower: [0.358, 0.003, 0.681, 0.891]> <tall, brick, tan>\n<building: [0.004, 0.402, 0.107, 0.952]> <white>\n<building: [0.082, 0.511, 0.997, 0.878]> <white, tan>\n<tower: [0.382, 0.001, 0.749, 0.944]> <tan, tall>\n<clock: [0.51, 0.334, 0.579, 0.392]> <round, blue, black, gold>\n<tower: [0.342, 0.0, 0.727, 0.924]> <tall>\n<sign: [0.512, 0.863, 0.567, 0.927]> <black, white>\n<sign: [0.443, 0.831, 0.511, 0.921]> <chalkboard>\n<tower: [0.308, 0.0, 0.753, 0.92]> <tall>\n<fence: [0.337, 0.829, 0.756, 0.928]> <black, metal>\n<buildings: [0.088, 0.521, 0.997, 0.882]> <tan, white>\n<window: [0.809, 0.774, 0.889, 0.832]> <clear>\n<window: [0.912, 0.683, 0.977, 0.75]> <clear>\n<window: [0.817, 0.686, 0.876, 0.751]> <clear>\n<building: [0.684, 0.588, 0.995, 0.873]> <white>\n<hat: [0.295, 0.769, 0.345, 0.793]> <tan>\n", "response": "Task: What is the color and material of the fence surrounding the bottom of the clock tower, indicated in <Region>[0.337, 0.829, 0.756, 0.928]</Region>?\nOutput: The fence surrounding the bottom of the clock tower in the indicated region is black and made of metal.", "instruction": "What is the color and material of the fence surrounding the bottom of the clock tower, indicated in <Region>[0.337, 0.829, 0.756, 0.928]</Region>?", "input": "", "output": "The fence surrounding the bottom of the clock tower in the indicated region is black and made of metal.", "is_classification": false, "dataset": "VG", "img_info": "712986.jpg"}
{"img_id": 498047, "query": "Curly hair of a chef: [0.49, 0.231, 0.572, 0.363]\nthe chef working on the food: [0.264, 0.212, 0.839, 0.993]\na chef is cooking: [0.364, 0.19, 0.824, 0.959]\nLarge black and silver scale: [0.137, 0.635, 0.449, 0.818]\nKitchen scale on the butcher block top: [0.129, 0.546, 0.421, 0.821]\nit is the hat of the chef : [0.369, 0.199, 0.516, 0.447]\nthe apron is white: [0.519, 0.296, 0.781, 0.968]\nthe baker has a tall hat: [0.297, 0.18, 0.585, 0.451]\nthe table is brown: [0.002, 0.246, 0.815, 0.886]\nthe hair is brown: [0.502, 0.225, 0.577, 0.403]\n\n<shirt: [0.531, 0.231, 0.769, 0.719]> <white>\n<apron: [0.508, 0.329, 0.753, 0.991]> <white>\n<pants: [0.693, 0.558, 0.825, 0.974]> <grey>\n<table: [0.057, 0.256, 0.627, 0.833]> <brown>\n<hat: [0.313, 0.174, 0.502, 0.403]> <large>\n<chef: [0.248, 0.174, 0.852, 0.779]> <frosting>\n<pastry chef: [0.373, 0.264, 0.82, 0.947]> <working>\n<apron: [0.515, 0.433, 0.73, 0.943]> <white>\n<scale: [0.266, 0.608, 0.496, 0.852]> <digital>\n<pants: [0.602, 0.619, 0.825, 1.0]> <grey>\n<hair: [0.509, 0.3, 0.526, 0.321]> <brown>\n", "response": "Task: What color is the apron worn by the chef in the <Region>[0.515, 0.433, 0.73, 0.943]</Region> region of the image?\nOutput: The apron worn by the chef in that region is white.", "instruction": "What color is the apron worn by the chef in the <Region>[0.515, 0.433, 0.73, 0.943]</Region> region of the image?", "input": "", "output": "The apron worn by the chef in that region is white.", "is_classification": false, "dataset": "VG", "img_info": "498047.jpg"}
{"img_id": 179, "query": "gray helium tank: [0.09, 0.396, 0.124, 0.575]\nyellow bucket in pool room: [0.109, 0.459, 0.178, 0.577]\nsilver pool climb rail: [0.365, 0.386, 0.51, 0.642]\ngrey tall laundry basket: [0.139, 0.406, 0.231, 0.567]\ngray laundry basket : [0.151, 0.427, 0.214, 0.551]\nblue cushion on top of white metal stool: [0.454, 0.346, 0.519, 0.386]\nyellow bucket in pool room: [0.109, 0.459, 0.178, 0.577]\na long lap pool: [0.133, 0.294, 0.889, 0.95]\nitems on a counter: [0.186, 0.272, 0.403, 0.378]\nA large blue tank: [0.085, 0.394, 0.13, 0.571]\n\n<laundry basket: [0.145, 0.419, 0.222, 0.555]> <gray>\n<pool: [0.087, 0.372, 0.817, 0.994]> <silver, small, lap>\n<lines: [0.436, 0.557, 0.744, 0.966]> <black>\n<stool: [0.461, 0.346, 0.516, 0.412]> <blue, white>\n<tank: [0.084, 0.396, 0.13, 0.579]> <light blue>\n<bucket: [0.115, 0.477, 0.174, 0.559]> <yellow, Black>\n<drain: [0.942, 0.523, 0.982, 0.563]> <white>\n<ladder: [0.373, 0.431, 0.466, 0.579]> <metal, small, pool>\n<bucket: [0.114, 0.477, 0.175, 0.573]> <yellow>\n<laundry basket: [0.139, 0.421, 0.217, 0.545]> <gray, tall>\n<bucket: [0.085, 0.392, 0.13, 0.567]> <yellow>\n<tube: [0.085, 0.402, 0.13, 0.575]> <tall, metal>\n<vent: [0.0, 0.344, 0.088, 0.414]> <metal>\n<stool: [0.452, 0.338, 0.524, 0.431]> <white, metal>\n<cushion: [0.458, 0.35, 0.513, 0.386]> <blue>\n<hand rail: [0.0, 0.477, 0.475, 0.801]> <long, metal>\n<door: [0.692, 0.127, 0.771, 0.304]> <brown>\n<door: [0.768, 0.139, 0.838, 0.302]> <brown>\n<chemicals: [0.124, 0.485, 0.168, 0.545]> <pool>\n<bucket: [0.12, 0.477, 0.162, 0.559]> <yellow>\n<water: [0.123, 0.404, 0.81, 0.95]> <blue>\n<laundry basket: [0.154, 0.425, 0.213, 0.547]> <gray, laundry>\n<tank: [0.09, 0.398, 0.12, 0.573]> <gray, helium>\n<cushion: [0.452, 0.342, 0.515, 0.384]> <blue>\n<counter: [0.175, 0.306, 0.397, 0.523]> <long, gray>\n<lines: [0.452, 0.581, 0.734, 0.95]> <black>\n<rail: [0.024, 0.771, 0.656, 0.994]> <metal>\n<basket: [0.141, 0.427, 0.216, 0.539]> <large, grey>\n<bucket: [0.115, 0.473, 0.162, 0.553]> <large, yellow>\n<tank: [0.081, 0.402, 0.121, 0.565]> <large, blue>\n", "response": "Task: What color is the stool in <Region>[0.461, 0.346, 0.516, 0.412]</Region> and what is on top of it?\nOutput: The stool color is white, and there is a blue cushion on top of it.", "instruction": "What color is the stool in <Region>[0.461, 0.346, 0.516, 0.412]</Region> and what is on top of it?", "input": "", "output": "The stool color is white, and there is a blue cushion on top of it.", "is_classification": false, "dataset": "VG", "img_info": "179.jpg"}
{"img_id": 3516, "query": "woman has a mouth: [0.492, 0.627, 0.605, 0.696]\nwoman has a nostral: [0.55, 0.546, 0.575, 0.588]\na silver necklace is surrounding the neck of the woman: [0.116, 0.127, 0.978, 0.994]\nwoman with pink lips : [0.475, 0.606, 0.634, 0.702]\nwoman has thin eyebrow: [0.577, 0.35, 0.67, 0.419]\nthe woman with silver necklace on black dress: [0.117, 0.123, 0.975, 0.99]\nclosed lips of mouth: [0.497, 0.629, 0.62, 0.696]\nwoman has thin eyebrow: [0.406, 0.377, 0.505, 0.442]\nwoman has an ear: [0.705, 0.471, 0.762, 0.631]\nwoman has a nose: [0.512, 0.517, 0.584, 0.583]\n\n<background: [0.008, 0.015, 0.998, 0.996]> <green>\n<dress: [0.109, 0.79, 0.988, 1.0]> <black>\n<woman: [0.084, 0.102, 0.983, 1.0]> <young>\n<necklace: [0.414, 0.835, 0.723, 0.998]> <silver>\n<smile: [0.328, 0.094, 0.784, 0.942]> <pinkish white, brown, pulled back>\n<lips: [0.486, 0.623, 0.623, 0.71]> <closed, small>\n<mole: [0.658, 0.613, 0.672, 0.644]> <brown>\n<brows: [0.405, 0.36, 0.678, 0.431]> <brown>\n", "response": "Task: What is the color of the necklace encircling the neck of the woman in <Region>[0.414, 0.835, 0.723, 0.998]</Region>?\nOutput: The necklace is silver in color.", "instruction": "What is the color of the necklace encircling the neck of the woman in <Region>[0.414, 0.835, 0.723, 0.998]</Region>?", "input": "", "output": "The necklace is silver in color.", "is_classification": false, "dataset": "VG", "img_info": "3516.jpg"}
{"img_id": 1054, "query": "Wine glass on the table : [0.229, 0.66, 0.345, 0.928]\nbrown ribbed wooden table: [0.072, 0.702, 0.638, 0.996]\nCloth napkins on the table : [0.072, 0.691, 0.669, 0.887]\nSalt and pepper shaker on the table : [0.401, 0.725, 0.467, 0.849]\nWhite plate on the table: [0.506, 0.838, 0.635, 0.925]\nWooden table top: [0.08, 0.694, 0.638, 0.955]\nplate on the table: [0.5, 0.792, 0.663, 0.958]\nplate on the table: [0.5, 0.792, 0.663, 0.958]\nblue menu standing on a table: [0.425, 0.574, 0.492, 0.834]\ndark brown slatted wood table: [0.069, 0.698, 0.633, 0.985]\n\n<plate: [0.511, 0.849, 0.633, 0.917]> <white>\n<plate: [0.53, 0.702, 0.608, 0.747]> <white>\n<plate: [0.229, 0.702, 0.329, 0.74]> <white>\n<menu: [0.815, 0.449, 0.856, 0.566]> <blue>\n<sea: [0.0, 0.279, 1.0, 0.37]> <stone, wall>\n<table: [0.077, 0.687, 0.66, 0.992]> <wooden>\n<wall: [0.0, 0.321, 0.992, 0.532]> <building's>\n", "response": "Task: What items are on the table besides the plate mentioned in <Region>[0.511, 0.849, 0.633, 0.917]</Region>?\nOutput: There is not enough information provided about the table to give a confident answer to this question.", "instruction": "What items are on the table besides the plate mentioned in <Region>[0.511, 0.849, 0.633, 0.917]</Region>?", "input": "", "output": "There is not enough information provided about the table to give a confident answer to this question.", "is_classification": false, "dataset": "VG", "img_info": "1054.jpg"}
{"img_id": 498100, "query": "The concrete wall seen beyond the railing: [0.379, 0.631, 0.954, 0.758]\na laptop sitting on a round table: [0.004, 0.536, 0.549, 0.996]\nA tile in a floor.: [0.055, 0.804, 0.203, 0.863]\nthis is a laptop: [0.214, 0.488, 0.569, 0.799]\nA tile in a floor.: [0.091, 0.78, 0.263, 0.816]\nmonitor on a laptop: [0.107, 0.537, 0.384, 0.683]\n a tile in a floor : [0.621, 0.81, 0.798, 0.867]\n a tile in a floor : [0.581, 0.84, 0.77, 0.919]\nA tile in a floor.: [0.594, 0.848, 0.779, 0.908]\nsmall glass and metal table: [0.001, 0.638, 0.569, 0.998]\n\n<table: [0.0, 0.655, 0.539, 0.996]> <Round>\n<laptop: [0.085, 0.535, 0.535, 0.731]> <black>\n<railing: [0.102, 0.466, 0.957, 0.768]> <Metal>\n<clouds: [0.005, 0.015, 0.997, 0.4]> <Gray>\n<floor: [0.0, 0.77, 0.906, 0.997]> <tiled>\n<wall: [0.57, 0.654, 0.957, 0.741]> <concrete>\n<safety rail: [0.105, 0.462, 0.961, 0.773]> <black>\n", "response": "Task: What is the shape of the table in <Region>[0.001, 0.638, 0.569, 0.998]</Region> and what materials is it made of?\nOutput: The table in that region is small, made of glass and metal, and is not described as having a specific shape.", "instruction": "What is the shape of the table in <Region>[0.001, 0.638, 0.569, 0.998]</Region> and what materials is it made of?", "input": "", "output": "The table in that region is small, made of glass and metal, and is not described as having a specific shape.", "is_classification": false, "dataset": "VG", "img_info": "498100.jpg"}
{"img_id": 3619, "query": "circle on the wood door: [0.708, 0.649, 0.737, 0.68]\nred circle on brown door: [0.45, 0.757, 0.505, 0.805]\ncircle on brown door: [0.392, 0.282, 0.476, 0.361]\ncircle on the wood door: [0.45, 0.755, 0.5, 0.797]\ncircle on the wood door: [0.708, 0.649, 0.737, 0.68]\nGreen circle on wooden door: [0.4, 0.099, 0.524, 0.205]\ncircle on the wood door: [0.395, 0.282, 0.466, 0.357]\nRed circle on wooden door: [0.439, 0.751, 0.503, 0.797]\nGreen circle on wooden door: [0.413, 0.598, 0.492, 0.669]\ncircle on the wood door: [0.397, 0.099, 0.524, 0.213]\n\n<door: [0.221, 0.002, 0.776, 0.996]> <brown, wooden>\n<circle: [0.374, 0.28, 0.479, 0.365]> <brown>\n<circle: [0.413, 0.598, 0.503, 0.667]> <green>\n<circle: [0.387, 0.282, 0.476, 0.357]> <red>\n<circle: [0.416, 0.596, 0.497, 0.675]> <brown>\n<handle: [0.626, 0.124, 0.695, 0.815]> <wooden>\n<keylock: [0.705, 0.643, 0.739, 0.68]> <gray>\n<green circle: [0.405, 0.099, 0.516, 0.203]> <green>\n<circle: [0.379, 0.434, 0.487, 0.519]> <blue>\n<circle: [0.416, 0.602, 0.497, 0.669]> <green>\n<hinge: [0.226, 0.292, 0.239, 0.361]> <silver>\n<circle: [0.389, 0.278, 0.482, 0.363]> <red>\n<circle: [0.408, 0.101, 0.513, 0.205]> <green>\n<wall: [0.0, 0.0, 0.25, 0.996]> <painted, white>\n", "response": "Task: How many blue circles can be seen in <Region>[0.221, 0.002, 0.776, 0.996]</Region>?\nOutput: No blue circles can be seen in this region.", "instruction": "How many blue circles can be seen in <Region>[0.221, 0.002, 0.776, 0.996]</Region>?", "input": "", "output": "No blue circles can be seen in this region.", "is_classification": false, "dataset": "VG", "img_info": "3619.jpg"}
{"img_id": 4920, "query": "blue upholstered chair: [0.43, 0.534, 0.552, 0.637]\nsolid wood door and frame: [0.279, 0.298, 0.417, 0.702]\nAn outdated bedroom : [0.002, 0.005, 0.992, 0.988]\nceramic pot on the fireplace mantel: [0.156, 0.351, 0.205, 0.422]\nframed painting on the wall: [0.708, 0.283, 0.827, 0.541]\ncabinet has a dark wooden door: [0.081, 0.517, 0.116, 0.737]\ncabinet has a dark wooden door: [0.081, 0.517, 0.116, 0.737]\na beautiful view of door: [0.246, 0.278, 0.497, 0.673]\ncabinet has a dark wooden door: [0.029, 0.537, 0.08, 0.751]\ncarved four poster bed: [0.313, 0.202, 0.889, 0.995]\n\n<post: [0.319, 0.21, 0.355, 1.0]> <tall>\n<post: [0.85, 0.259, 0.886, 0.732]> <tall>\n<wooden door: [0.075, 0.52, 0.127, 0.934]> <dark>\n<wooden door: [0.026, 0.527, 0.094, 0.998]> <dark>\n<door: [0.301, 0.337, 0.399, 0.693]> <wooden>\n<bed frame: [0.318, 0.21, 0.888, 1.0]> <wooden>\n<chair: [0.798, 0.72, 0.912, 0.998]> <wooden>\n<painting: [0.712, 0.298, 0.826, 0.539]> <framed>\n<pot: [0.155, 0.363, 0.205, 0.412]> <ceramic>\n<chair: [0.427, 0.546, 0.546, 0.632]> <blue, upholstered>\n<room: [0.0, 0.0, 0.998, 0.993]> <tidy>\n", "response": "Task: Please describe the appearance of the four-poster bed in <Region>[0.313, 0.202, 0.889, 0.995]</Region>.\nOutput: The four-poster bed in that region is carved, indicating intricate designs on the wooden frame. The details of the carvings are not specified.", "instruction": "Please describe the appearance of the four-poster bed in <Region>[0.313, 0.202, 0.889, 0.995]</Region>.", "input": "", "output": "The four-poster bed in that region is carved, indicating intricate designs on the wooden frame. The details of the carvings are not specified.", "is_classification": false, "dataset": "VG", "img_info": "4920.jpg"}
{"img_id": 4764, "query": "The roof above the garage doors.: [0.453, 0.41, 0.89, 0.497]\nthe roof is black: [0.068, 0.133, 0.735, 0.363]\nthe roof is black: [0.068, 0.39, 0.91, 0.517]\nthe front window of a home: [0.135, 0.51, 0.253, 0.667]\na column color brown: [0.282, 0.473, 0.328, 0.697]\nroof of a house: [0.068, 0.147, 0.73, 0.34]\n\n<home: [0.075, 0.14, 0.902, 0.703]> <nearly finished>\n<roof: [0.892, 0.42, 0.995, 0.493]> <black>\n<leaves: [0.14, 0.89, 0.42, 0.94]> <dry>\n<column: [0.295, 0.48, 0.32, 0.7]> <brown>\n", "response": "Task: Please describe the variable indicated by <Region>[0.135, 0.51, 0.253, 0.667]</Region>.\nOutput: The region shows the front window of a home, however, no color information is provided in the attributes.", "instruction": "Please describe the variable indicated by <Region>[0.135, 0.51, 0.253, 0.667]</Region>.", "input": "", "output": "The region shows the front window of a home, however, no color information is provided in the attributes.", "is_classification": false, "dataset": "VG", "img_info": "4764.jpg"}
{"img_id": 715, "query": "Sign on the dock: [0.033, 0.41, 0.115, 0.712]\nsmall flag on the front of the white boat: [0.48, 0.532, 0.504, 0.622]\nbrown board on dock: [0.359, 0.728, 0.391, 0.872]\nthis boat is parked: [0.142, 0.377, 0.465, 0.645]\nboard on the dock: [0.158, 0.605, 0.185, 0.647]\nthis is a waterfront: [0.062, 0.155, 0.95, 0.898]\nbrown board on dock: [0.385, 0.728, 0.417, 0.862]\nboard on the dock: [0.158, 0.605, 0.185, 0.647]\nbrown board on dock: [0.333, 0.732, 0.369, 0.872]\nbrown board on dock: [0.429, 0.758, 0.46, 0.865]\n\n<dock: [0.501, 0.467, 0.6, 0.615]> <close, brown>\n<woman: [0.6, 0.418, 0.68, 0.573]> <alone, looking, dark blue, close, standing>\n<board: [0.391, 0.732, 0.412, 0.868]> <brown>\n<water: [0.672, 0.37, 0.885, 0.563]> <smooth, calm, green, dirty, brown, dark>\n<boat: [0.599, 0.287, 0.946, 0.417]> <parked, sailing, far, white, blue, large, long>\n<building: [0.794, 0.088, 0.936, 0.23]> <large>\n", "response": "Task: What color is the flag on the front of the white boat indicated by <Region>[0.48, 0.532, 0.504, 0.622]</Region>?\nOutput: There is a flag on the front of the white boat in that region, but its color is not mentioned.", "instruction": "What color is the flag on the front of the white boat indicated by <Region>[0.48, 0.532, 0.504, 0.622]</Region>?", "input": "", "output": "There is a flag on the front of the white boat in that region, but its color is not mentioned.", "is_classification": false, "dataset": "VG", "img_info": "715.jpg"}
{"img_id": 1074, "query": "a mirror on left side of a car: [0.551, 0.847, 0.611, 0.913]\nair conditioning unit in window: [0.217, 0.438, 0.289, 0.482]\nclear sky above cars: [0.416, 0.02, 0.656, 0.21]\nWindow with black shutters on side: [0.186, 0.285, 0.321, 0.492]\nTwo cars parked in the driveway : [0.004, 0.745, 0.995, 0.998]\ndark car and light car: [0.11, 0.677, 0.97, 0.997]\nBlue front door: [0.427, 0.652, 0.504, 0.833]\n Someone's silver sedan: [0.006, 0.755, 0.501, 0.997]\nDice hanging inside the silver car: [0.278, 0.838, 0.31, 0.912]\nName of the car in silver: [0.759, 0.943, 0.884, 0.985]\n\n<window: [0.216, 0.293, 0.301, 0.513]> <white>\n<shutter: [0.706, 0.348, 0.746, 0.515]> <blue, rectangle>\n<car: [0.033, 0.762, 0.46, 0.995]> <silver>\n<car: [0.561, 0.77, 0.97, 0.983]> <blue>\n<house: [0.0, 0.08, 0.938, 0.893]> <two-story>\n<shutter: [0.284, 0.29, 0.321, 0.483]> <black>\n<shutter: [0.18, 0.293, 0.225, 0.488]> <black>\n<house: [0.01, 0.132, 0.97, 0.848]> <large, tan>\n<sedan: [0.556, 0.74, 0.993, 0.998]> <blue>\n<sedan: [0.01, 0.778, 0.492, 0.997]> <silver>\n<name: [0.762, 0.945, 0.885, 0.978]> <silver>\n<door: [0.43, 0.655, 0.502, 0.843]> <black>\n<shutter: [0.713, 0.608, 0.755, 0.758]> <black>\n<rails: [0.516, 0.762, 0.574, 0.868]> <black>\n<walk: [0.438, 0.822, 0.554, 0.995]> <concrete>\n", "response": "Task: What type of car is indicated by <Region>[0.556, 0.74, 0.993, 0.998]</Region>? What special object is visible on its interior?\nOutput: The type of car indicated is a blue sedan. Inside the car, there are dice hanging visible on the window.", "instruction": "What type of car is indicated by <Region>[0.556, 0.74, 0.993, 0.998]</Region>? What special object is visible on its interior?", "input": "", "output": "The type of car indicated is a blue sedan. Inside the car, there are dice hanging visible on the window.", "is_classification": false, "dataset": "VG", "img_info": "1074.jpg"}
{"img_id": 4802, "query": "knife next to the plate: [0.696, 0.341, 0.79, 0.922]\na flower on the plate: [0.524, 0.427, 0.544, 0.464]\na flower on the plate: [0.62, 0.481, 0.646, 0.536]\nflowers on a dish: [0.434, 0.437, 0.648, 0.836]\nred flower on teacup.: [0.696, 0.147, 0.724, 0.191]\nplate on the tray: [0.466, 0.631, 0.62, 0.802]\na flower on the plate: [0.54, 0.474, 0.56, 0.498]\na flower on the plate: [0.46, 0.532, 0.474, 0.549]\nspoon above the plate: [0.35, 0.164, 0.596, 0.29]\nRound plate on square placemat : [0.236, 0.266, 0.72, 0.918]\n\n<plate: [0.252, 0.283, 0.708, 0.911]> <small, large>\n<dish: [0.082, 0.099, 0.33, 0.396]> <small>\n<cup: [0.688, 0.014, 0.858, 0.27]> <white>\n<plate: [0.298, 0.334, 0.668, 0.836]> <larger>\n<flower: [0.694, 0.143, 0.722, 0.195]> <red>\n<plate: [0.084, 0.102, 0.328, 0.399]> <a saucer>\n", "response": "Task: What is the shape of the placemat in <Region>[0.236, 0.266, 0.72, 0.918]</Region>?\nOutput: The placemat is square.", "instruction": "What is the shape of the placemat in <Region>[0.236, 0.266, 0.72, 0.918]</Region>?", "input": "", "output": "The placemat is square.", "is_classification": false, "dataset": "VG", "img_info": "4802.jpg"}
{"img_id": 1593133, "query": "woman wearing a green shirt: [0.366, 0.072, 0.655, 0.326]\nboy wearing a striped shirt: [0.087, 0.479, 0.921, 0.996]\nboy wearing a white shirt: [0.661, 0.214, 0.924, 0.516]\na boy's orange and white striped shirt: [0.073, 0.631, 0.626, 0.996]\na boy's white shirt: [0.718, 0.246, 0.93, 0.471]\na boy wearing a white shirt: [0.637, 0.206, 0.946, 0.524]\na boy wearing an orange shirt: [0.062, 0.466, 0.947, 0.997]\nblue pants on kid: [0.562, 0.862, 0.888, 0.992]\ngreen food items on bench: [0.565, 0.585, 0.818, 0.822]\nkid in a white shirt: [0.586, 0.215, 0.932, 0.506]\n\n<lines: [0.116, 0.707, 0.298, 0.762]> <orange>\n<blue pants: [0.626, 0.845, 0.938, 0.996]> <blue>\n<food: [0.526, 0.493, 0.855, 0.818]> <green>\n<shirt: [0.722, 0.262, 0.94, 0.47]> <white>\n", "response": "Task: What color is the shirt worn by the person in <Region>[0.586, 0.215, 0.932, 0.506]</Region>?\nOutput: The shirt worn by the person in this region is white.", "instruction": "What color is the shirt worn by the person in <Region>[0.586, 0.215, 0.932, 0.506]</Region>?", "input": "", "output": "The shirt worn by the person in this region is white.", "is_classification": false, "dataset": "VG", "img_info": "1593133.jpg"}
{"img_id": 713754, "query": "green leaves on the tree: [0.305, 0.056, 0.334, 0.085]\nblue sign on side of road: [0.477, 0.186, 0.527, 0.246]\nA red sign on a pole.: [0.403, 0.154, 0.451, 0.288]\na sign color red: [0.054, 0.183, 0.113, 0.275]\ntrangle sign is red: [0.054, 0.187, 0.091, 0.21]\nA hill covered in trees.: [0.006, 0.016, 0.414, 0.203]\nA tree in the woods.: [0.225, 0.073, 0.265, 0.124]\na sign : [0.483, 0.185, 0.53, 0.253]\nred car in the street: [0.422, 0.205, 0.496, 0.244]\nA tree in the woods.: [0.23, 0.037, 0.258, 0.075]\n\n<tree: [0.163, 0.119, 0.281, 0.23]> <in woods>\n<tree: [0.17, 0.114, 0.286, 0.23]> <in woods, in woods, in woods>\n<tree: [0.17, 0.114, 0.288, 0.221]> <in woods>\n<tree: [0.177, 0.103, 0.286, 0.219]> <in woods>\n<jacket: [0.042, 0.416, 0.262, 0.608]> <leather>\n<car: [0.555, 0.237, 0.959, 0.338]> <white>\n<sign: [0.603, 0.19, 0.63, 0.242]> <blue>\n<sign: [0.486, 0.183, 0.527, 0.249]> <blue>\n<sign: [0.407, 0.16, 0.457, 0.193]> <red, triangle>\n<sign: [0.059, 0.189, 0.094, 0.21]> <triangle, red>\n", "response": "Task: What shape and color is the sign in the <Region>[0.407, 0.16, 0.457, 0.193]</Region>?\nOutput: The sign in the region is a red triangle.", "instruction": "What shape and color is the sign in the <Region>[0.407, 0.16, 0.457, 0.193]</Region>?", "input": "", "output": "The sign in the region is a red triangle.", "is_classification": false, "dataset": "VG", "img_info": "713754.jpg"}
{"img_id": 2688, "query": "window on the building: [0.895, 0.711, 0.963, 0.795]\nbarrel near the building : [0.812, 0.794, 0.873, 0.879]\nA brown door to a building: [0.14, 0.615, 0.245, 0.691]\nwindow on the building: [0.427, 0.616, 0.45, 0.661]\nA black and white clock: [0.073, 0.616, 0.148, 0.669]\nwindow on the building: [0.427, 0.616, 0.45, 0.661]\nsmall window with window sill underneath: [0.415, 0.534, 0.465, 0.584]\nwindow on the building : [0.183, 0.54, 0.225, 0.588]\nwindow on the building : [0.295, 0.441, 0.352, 0.494]\nwindow on the building: [0.895, 0.711, 0.963, 0.795]\n\n<clock: [0.08, 0.624, 0.142, 0.666]> <round, white>\n<car: [0.508, 0.705, 0.653, 0.815]> <parked, black>\n<pole: [0.085, 0.667, 0.148, 0.834]> <black, skinny>\n<light: [0.757, 0.676, 0.832, 0.743]> <black>\n<barrel: [0.788, 0.8, 0.878, 0.884]> <black>\n<window: [0.298, 0.357, 0.358, 0.409]> <tiny, small, closed, shut, clear, open>\n<window: [0.178, 0.352, 0.25, 0.412]> <open>\n<building: [0.008, 0.128, 0.633, 0.704]> <yellow, tall, wide, rusty, old, gold, thick, huge>\n<sidewalk: [0.553, 0.68, 0.983, 0.994]> <grey>\n<lights: [0.563, 0.766, 0.653, 0.784]> <red>\n<sky: [0.01, 0.009, 0.995, 0.217]> <white>\n<right building: [0.632, 0.188, 0.997, 0.85]> <yellow>\n", "response": "Task: What is the color of the <Region>[0.788, 0.8, 0.878, 0.884]</Region>?\nOutput: The color of the object in that region is black.", "instruction": "What is the color of the <Region>[0.788, 0.8, 0.878, 0.884]</Region>?", "input": "", "output": "The color of the object in that region is black.", "is_classification": false, "dataset": "VG", "img_info": "2688.jpg"}
{"img_id": 1159796, "query": "closed red umbrella: [0.58, 0.28, 0.701, 0.478]\na man and a woman holding an umbrella: [0.374, 0.251, 0.603, 0.71]\nan open umbrella outside: [0.364, 0.132, 0.964, 0.486]\nopen silver umbrella: [0.286, 0.256, 0.601, 0.395]\nrain water falling down from a big umbrella: [0.333, 0.085, 0.841, 0.239]\ngray umbrella above man: [0.311, 0.259, 0.585, 0.381]\nan open umbrella outside: [0.331, 0.245, 0.66, 0.445]\nan open umbrella outside: [0.829, 0.242, 0.984, 0.453]\nan open umbrella outside: [0.296, 0.195, 0.688, 0.476]\nopen silver umbrella: [0.286, 0.256, 0.601, 0.395]\n\n<umbrella: [0.318, 0.252, 0.619, 0.383]> <large, open>\n<umbrella: [0.791, 0.237, 0.994, 0.334]> <open>\n", "response": "Task: What is the shape of the object in the <Region>[0.791, 0.237, 0.994, 0.334]</Region>?\nOutput: The object in the region is an open umbrella, but the shape of the umbrella is not clear from the given information.", "instruction": "What is the shape of the object in the <Region>[0.791, 0.237, 0.994, 0.334]</Region>?", "input": "", "output": "The object in the region is an open umbrella, but the shape of the umbrella is not clear from the given information.", "is_classification": false, "dataset": "VG", "img_info": "1159796.jpg"}
{"img_id": 680, "query": "Light colored pebbles and stones.: [0.029, 0.079, 0.41, 0.636]\nLight colored pebbles and stones.: [0.029, 0.079, 0.41, 0.636]\n\n<stones: [0.085, 0.109, 0.296, 0.28]> <light colored>\n<pebbles: [0.195, 0.338, 0.307, 0.433]> <light colored>\n", "response": "Task: What is the object indicated by <Region>[0.195, 0.338, 0.307, 0.433]</Region> in the image, and what kind of colors do they have?\nOutput: The object indicated by this region is pebbles, and they have a light color.", "instruction": "What is the object indicated by <Region>[0.195, 0.338, 0.307, 0.433]</Region> in the image, and what kind of colors do they have?", "input": "", "output": "The object indicated by this region is pebbles, and they have a light color.", "is_classification": false, "dataset": "VG", "img_info": "680.jpg"}
{"img_id": 1592134, "query": "orange drink sitting on street: [0.053, 0.577, 0.068, 0.628]\ncordened off construction site in road: [0.452, 0.384, 0.686, 0.492]\nA red and white stop sign on a wooden stick.: [0.113, 0.169, 0.18, 0.27]\nman is wearing pants : [0.09, 0.482, 0.158, 0.611]\nwhite houses on street: [0.662, 0.207, 0.997, 0.43]\nthe trees are tall: [0.171, 0.044, 0.462, 0.421]\nA red and white stop sign on a wooden stick.: [0.113, 0.169, 0.18, 0.27]\na stop sign : [0.108, 0.18, 0.181, 0.263]\nman in white pants: [0.076, 0.29, 0.164, 0.633]\nA work truck with a metal frame parked on a road.: [0.216, 0.362, 0.334, 0.523]\n\n<shoe: [0.179, 0.71, 0.342, 0.995]> <BLACK>\n<traffic cones: [0.447, 0.428, 0.843, 0.53]> <ORANGE>\n<sign: [0.3, 0.361, 0.336, 0.409]> <ROUND>\n<sign: [0.107, 0.164, 0.186, 0.266]> <RED>\n<man: [0.072, 0.288, 0.168, 0.634]> <standing>\n<stop sign: [0.11, 0.169, 0.177, 0.629]> <white, red>\n<sleeve: [0.085, 0.344, 0.146, 0.401]> <long>\n<shirt: [0.078, 0.329, 0.154, 0.484]> <yellow, black, green>\n<pants: [0.089, 0.47, 0.154, 0.625]> <gray>\n<road: [0.001, 0.482, 0.97, 0.99]> <concrete, dark gray>\n<line: [0.463, 0.487, 0.97, 0.732]> <white>\n<tree: [0.007, 0.007, 0.229, 0.396]> <tall>\n<tree: [0.171, 0.004, 0.315, 0.393]> <tall>\n<tree: [0.239, 0.001, 0.32, 0.398]> <tall>\n<tree: [0.294, 0.001, 0.386, 0.323]> <tall>\n<tree: [0.332, 0.138, 0.438, 0.453]> <tall>\n<traffic cone: [0.794, 0.445, 0.832, 0.527]> <orange, white>\n<car: [0.918, 0.378, 0.969, 0.536]> <white>\n<car: [0.001, 0.477, 0.064, 0.648]> <dark colored>\n<frame: [0.205, 0.389, 0.321, 0.488]> <metal>\n<stop sign: [0.11, 0.174, 0.179, 0.271]> <red, white>\n<stick: [0.14, 0.268, 0.159, 0.632]> <wooden>\n<sky: [0.003, 0.004, 0.897, 0.447]> <bright, hazy>\n<person: [0.072, 0.288, 0.172, 0.632]> <standing>\n<sign: [0.109, 0.172, 0.18, 0.271]> <red and white>\n<line: [0.695, 0.574, 0.831, 0.659]> <yellow>\n<pants: [0.104, 0.473, 0.146, 0.612]> <white>\n<drink: [0.037, 0.581, 0.073, 0.643]> <orange>\n<car: [0.079, 0.389, 0.251, 0.5]> <white>\n<cone: [0.617, 0.428, 0.681, 0.525]> <orange, white>\n<truck: [0.216, 0.378, 0.319, 0.517]> <utility>\n", "response": "Task: What is the color of the shoes in <Region>[0.179, 0.71, 0.342, 0.995]</Region>?\nOutput: The shoes in that region are black.", "instruction": "What is the color of the shoes in <Region>[0.179, 0.71, 0.342, 0.995]</Region>?", "input": "", "output": "The shoes in that region are black.", "is_classification": false, "dataset": "VG", "img_info": "1592134.jpg"}
{"img_id": 1159838, "query": "man has arm bent: [0.205, 0.381, 0.419, 0.993]\numbrella is open: [0.412, 0.097, 0.629, 0.414]\nman has arm outstretched: [0.807, 0.205, 0.889, 0.376]\nwoman is dressed in blue and yellow: [0.88, 0.284, 0.986, 0.734]\n a large open umbrella : [0.033, 0.216, 0.182, 0.372]\n a large open umbrella : [0.42, 0.089, 0.635, 0.47]\nlarge blue and white umbrella: [0.411, 0.091, 0.642, 0.256]\nlarge blue open umbrella: [0.738, 0.155, 0.885, 0.247]\nlight blue and green umbrella: [0.263, 0.134, 0.434, 0.28]\n\n<arm: [0.312, 0.509, 0.422, 0.702]> <bent>\n<dressed: [0.878, 0.29, 0.986, 0.722]> <blue, yellow>\n<umbrella: [0.245, 0.107, 0.447, 0.293]> <large, open>\n", "response": "Task: What are the colors of the umbrella shown in <Region>[0.411, 0.091, 0.642, 0.256]</Region>?\nOutput: The umbrella in that region is blue and white.", "instruction": "What are the colors of the umbrella shown in <Region>[0.411, 0.091, 0.642, 0.256]</Region>?", "input": "", "output": "The umbrella in that region is blue and white.", "is_classification": false, "dataset": "VG", "img_info": "1159838.jpg"}
{"img_id": 1461, "query": "brown UPS truck backed in by building: [0.037, 0.443, 0.269, 0.627]\nawning over windows on brick building: [0.003, 0.36, 0.125, 0.445]\nawning over windows on brick building: [0.003, 0.36, 0.125, 0.445]\nglass window on building: [0.0, 0.427, 0.033, 0.45]\nglass window on building: [0.003, 0.542, 0.034, 0.56]\nglass window on building: [0.0, 0.482, 0.025, 0.498]\nglass window on building: [0.031, 0.452, 0.065, 0.475]\nbuilding is orange brick: [0.004, 0.275, 0.225, 0.525]\nthe building is orange: [0.003, 0.305, 0.246, 0.625]\nThe awning on the building : [0.003, 0.362, 0.122, 0.437]\n\n<building: [0.003, 0.29, 0.255, 0.62]> <orange>\n<building: [0.006, 0.298, 0.258, 0.593]> <orange>\n<building: [0.003, 0.283, 0.278, 0.622]> <orange>\n<window: [0.003, 0.427, 0.034, 0.462]> <glassy>\n<window: [0.003, 0.443, 0.036, 0.492]> <glassy>\n<window: [0.006, 0.507, 0.041, 0.547]> <glassy>\n<building: [0.007, 0.307, 0.255, 0.557]> <glassy>\n<window: [0.006, 0.535, 0.05, 0.575]> <glass>\n<window: [0.029, 0.425, 0.071, 0.462]> <glass>\n<window: [0.033, 0.445, 0.079, 0.475]> <glass>\n<window: [0.294, 0.408, 0.31, 0.435]> <glass>\n<window: [0.036, 0.52, 0.058, 0.557]> <glass>\n<building: [0.004, 0.322, 0.247, 0.567]> <glass>\n<writing: [0.818, 0.485, 0.931, 0.6]> <white, yellow>\n<vehicle: [0.807, 0.487, 0.96, 0.633]> <black>\n", "response": "Task: What is the color of the writing in <Region>[0.818, 0.485, 0.931, 0.6]</Region>, and what kind of building or object does the writing advertise?\nOutput: The writing in that region is white and yellow, and it is not clear what kind of building or object the writing is advertising.", "instruction": "What is the color of the writing in <Region>[0.818, 0.485, 0.931, 0.6]</Region>, and what kind of building or object does the writing advertise?", "input": "", "output": "The writing in that region is white and yellow, and it is not clear what kind of building or object the writing is advertising.", "is_classification": false, "dataset": "VG", "img_info": "1461.jpg"}
{"img_id": 1592045, "query": "arm of the person: [0.255, 0.453, 0.324, 0.524]\nthe glasses on the man's face: [0.778, 0.05, 0.968, 0.174]\nsticker on the laptop: [0.26, 0.737, 0.335, 0.892]\na sticker on the laptop: [0.202, 0.512, 0.33, 0.723]\nA person eating a orange. : [0.659, 0.72, 0.773, 0.922]\nsticker with a heart and padlock on it: [0.155, 0.683, 0.219, 0.876]\nA person eating a orange. : [0.659, 0.72, 0.773, 0.922]\narm of the person: [0.255, 0.453, 0.324, 0.524]\nA person eating a orange. : [0.659, 0.72, 0.773, 0.922]\n a person is sitting down : [0.499, 0.016, 0.997, 0.913]\n\n<bottle: [0.357, 0.419, 0.506, 0.99]> <for holding liquid, clear>\n<person: [0.149, 0.013, 0.716, 0.919]> <sitting down>\n<person: [0.498, 0.0, 0.996, 0.931]> <sitting down>\n<person: [0.525, 0.004, 0.961, 0.863]> <sitting down>\n<person: [0.259, 0.004, 0.702, 0.791]> <sitting down>\n<cap: [0.415, 0.428, 0.46, 0.472]> <blue>\n<sticker: [0.225, 0.55, 0.314, 0.665]> <rectangular, yellow>\n<man: [0.449, 0.007, 0.998, 0.913]> <serious>\n<button down: [0.312, 0.264, 0.71, 0.794]> <blue>\n", "response": "Task: What color is the button in <Region>[0.312, 0.264, 0.71, 0.794]</Region>? \nOutput: The button in this region is blue.", "instruction": "What color is the button in <Region>[0.312, 0.264, 0.71, 0.794]</Region>?", "input": "", "output": "The button in this region is blue.", "is_classification": false, "dataset": "VG", "img_info": "1592045.jpg"}
{"img_id": 61539, "query": "a baseball player stands behind a fence: [0.807, 0.162, 0.925, 0.75]\na yellow and black and silver baseball bat: [0.305, 0.378, 0.528, 0.546]\norange cooler on wooden bench: [0.644, 0.394, 0.71, 0.71]\nblack catcher helmet: [0.066, 0.415, 0.166, 0.565]\nhome plate embedded in dirt : [0.397, 0.879, 0.514, 0.903]\nDrink cooler on bench: [0.641, 0.4, 0.693, 0.587]\nblack metal fence: [0.156, 0.063, 0.768, 0.204]\nThe batter has on a dark helmet: [0.516, 0.147, 0.631, 0.347]\nA green and orange sports drink bottle: [0.695, 0.463, 0.728, 0.591]\nopen catcher's mitt waiting for ball: [0.156, 0.525, 0.33, 0.684]\n\n<player: [0.47, 0.178, 0.69, 0.912]> <standing, grey, gree, watching>\n<bat: [0.295, 0.334, 0.563, 0.549]> <metal, yellow, chrome, ready>\n<game: [0.012, 0.024, 0.998, 0.993]> <happening, here, watched>\n<fence: [0.376, 0.054, 0.978, 0.666]> <black, metal>\n<helmet: [0.529, 0.219, 0.624, 0.307]> <here>\n<cooler: [0.628, 0.406, 0.732, 0.654]> <orange>\n<team member: [0.722, 0.076, 0.91, 0.732]> <waiting>\n<catcher: [0.012, 0.335, 0.24, 0.912]> <waiting, young>\n<uniform: [0.007, 0.418, 0.212, 0.844]> <red, white>\n<glove: [0.244, 0.538, 0.332, 0.668]> <leather>\n<mitt: [0.242, 0.528, 0.305, 0.657]> <open, worn>\n<bottle: [0.698, 0.487, 0.728, 0.572]> <green, orange>\n<baseball: [0.812, 0.481, 0.854, 0.594]> <spinning, played>\n<grass: [0.701, 0.626, 0.982, 0.765]> <tall>\n<shoes: [0.435, 0.737, 0.734, 0.999]> <black>\n<dirt: [0.252, 0.749, 0.878, 0.994]> <brown>\n<bench: [0.628, 0.547, 0.959, 0.712]> <wooden>\n", "response": "Task: What is the color of the catcher's helmet in <Region>[0.529, 0.219, 0.624, 0.307]</Region>?\nOutput: The catcher's helmet in the region is black.", "instruction": "What is the color of the catcher's helmet in <Region>[0.529, 0.219, 0.624, 0.307]</Region>?", "input": "", "output": "The catcher's helmet in the region is black.", "is_classification": false, "dataset": "VG", "img_info": "61539.jpg"}
{"img_id": 713774, "query": "spectator watching skater on ramp: [0.647, 0.835, 0.682, 0.878]\nvans logo on the skate ramp: [0.534, 0.705, 0.599, 0.741]\nspectator watching skater on ramp: [0.694, 0.837, 0.73, 0.874]\n a person is sitting down : [0.816, 0.886, 0.853, 0.934]\nthe yellow wheel of the skateboard: [0.579, 0.195, 0.616, 0.211]\nwhite colored wheel on skateboard: [0.747, 0.294, 0.796, 0.331]\nyellow wheel on red skateboard: [0.528, 0.239, 0.565, 0.261]\nthe yellow wheel of the skateboard: [0.579, 0.195, 0.616, 0.211]\nthe black and white vans sticker: [0.384, 0.966, 0.519, 0.997]\nperson wearing a yellow top: [0.716, 0.84, 0.755, 0.877]\n\n<wheel: [0.752, 0.301, 0.798, 0.332]> <yellow>\n<logo: [0.517, 0.759, 0.574, 0.775]> <black, yellow>\n<flag: [0.065, 0.467, 0.13, 0.58]> <red>\n<helmet: [0.651, 0.318, 0.704, 0.369]> <black>\n<sky: [0.003, 0.002, 0.969, 0.701]> <clear, blue>\n<shadow: [0.003, 0.879, 0.915, 0.997]> <big>\n<sticker: [0.049, 0.892, 0.168, 0.943]> <blue>\n<sticker: [0.145, 0.924, 0.284, 0.974]> <white>\n<skateboard: [0.512, 0.195, 0.914, 0.361]> <airborne, red>\n<shirt: [0.906, 0.868, 0.952, 0.904]> <orange>\n<top: [0.708, 0.844, 0.77, 0.874]> <yellow>\n<van: [0.519, 0.705, 0.602, 0.735]> <word>\n<vans: [0.142, 0.913, 0.281, 0.978]> <word>\n<vans: [0.218, 0.658, 0.327, 0.707]> <word>\n<skater: [0.469, 0.195, 0.852, 0.482]> <on ramp>\n<skater: [0.397, 0.176, 0.827, 0.506]> <on ramp>\n<skater: [0.46, 0.215, 0.915, 0.53]> <on ramp>\n<skater: [0.452, 0.235, 0.863, 0.53]> <on ramp>\n<skater: [0.383, 0.219, 0.843, 0.534]> <on ramp>\n<skater: [0.417, 0.236, 0.846, 0.54]> <on ramp>\n<skater: [0.409, 0.208, 0.84, 0.539]> <on ramp>\n<skater: [0.432, 0.199, 0.818, 0.563]> <on ramp>\n<skater: [0.46, 0.216, 0.83, 0.532]> <on ramp>\n<advertisement: [0.025, 0.557, 0.321, 0.669]> <red>\n<helmet: [0.647, 0.317, 0.708, 0.367]> <black>\n<table: [0.711, 0.887, 0.829, 0.937]> <judge, white>\n<pants: [0.466, 0.321, 0.745, 0.467]> <black>\n<wheel: [0.532, 0.241, 0.551, 0.258]> <yellow>\n<skateboard: [0.522, 0.21, 0.912, 0.363]> <red>\n<wheel: [0.582, 0.194, 0.61, 0.213]> <yellow>\n<wheel: [0.752, 0.298, 0.798, 0.331]> <yellow>\n<sticker: [0.264, 0.954, 0.392, 0.987]> <black, white>\n<sticker: [0.384, 0.968, 0.491, 0.997]> <white, black>\n<sticker: [0.514, 0.974, 0.639, 0.997]> <black, white>\n<sticker: [0.627, 0.964, 0.778, 0.993]> <white, black>\n<sticker: [0.727, 0.954, 0.827, 0.986]> <black, white, vans>\n<person: [0.762, 0.878, 0.809, 0.909]> <sitting>\n<wheel: [0.752, 0.298, 0.79, 0.323]> <yellow>\n<wheel: [0.804, 0.247, 0.838, 0.27]> <yellow>\n", "response": "Task: What is the color of the person's shirt in <Region>[0.716, 0.84, 0.755, 0.877]</Region>?\nOutput: The region describes a person wearing a yellow top. Therefore, the color of the person's shirt is yellow.", "instruction": "What is the color of the person's shirt in <Region>[0.716, 0.84, 0.755, 0.877]</Region>?", "input": "", "output": "The region describes a person wearing a yellow top. Therefore, the color of the person's shirt is yellow.", "is_classification": false, "dataset": "VG", "img_info": "713774.jpg"}
{"img_id": 2392244, "query": "basket holding items on table: [0.581, 0.004, 0.731, 0.102]\nstainless steel spoon in bowl: [0.304, 0.71, 0.848, 0.934]\na large white plate: [0.267, 0.482, 0.723, 0.722]\nChild has straight hair: [0.144, 0.004, 0.584, 0.254]\nThe spoon is silver.: [0.408, 0.756, 0.851, 0.866]\nThe bowl is black.: [0.317, 0.198, 0.608, 0.312]\na red bowl with a spoon: [0.288, 0.72, 0.749, 0.924]\na bowl with a handle sticking out of it: [0.352, 0.072, 0.68, 0.302]\nThe girl is young.: [0.181, 0.012, 0.477, 0.358]\nWhite plate is full of fried rice: [0.293, 0.482, 0.784, 0.73]\n\n<bowl: [0.381, 0.202, 0.592, 0.294]> <empty, red, pink, black>\n<spoon: [0.528, 0.082, 0.632, 0.186]> <silver>\n<plate: [0.264, 0.48, 0.709, 0.706]> <full>\n<rice: [0.421, 0.574, 0.547, 0.618]> <brown>\n<stool: [0.587, 0.238, 0.792, 0.372]> <yellow>\n<table: [0.413, 0.052, 0.829, 0.134]> <black>\n<napkin: [0.461, 0.376, 0.733, 0.52]> <white>\n<girl: [0.189, 0.018, 0.579, 0.408]> <holding, young>\n<hair: [0.277, 0.004, 0.48, 0.066]> <brown>\n", "response": "Task: What color is the bowl in <Region>[0.381, 0.202, 0.592, 0.294]</Region>, and is it empty or not?\nOutput: The bowl in that region is red in color, and it is empty.", "instruction": "What color is the bowl in <Region>[0.381, 0.202, 0.592, 0.294]</Region>, and is it empty or not?", "input": "", "output": "The bowl in that region is red in color, and it is empty.", "is_classification": false, "dataset": "VG", "img_info": "2392244.jpg"}
{"img_id": 713051, "query": "license plate on the pickup truck : [0.105, 0.715, 0.132, 0.73]\nElectric wires on the pole : [0.105, 0.335, 0.18, 0.478]\norange and blue gas price sign: [0.888, 0.002, 0.997, 0.537]\nElectric wires on the pole : [0.332, 0.105, 0.408, 0.358]\nA parked silver vehicle: [0.134, 0.618, 0.268, 0.722]\ntruck next to a metal fence: [0.293, 0.368, 0.997, 0.888]\ngreen leaves on the tree: [0.769, 0.32, 0.806, 0.382]\npickup truck on the street: [0.033, 0.651, 0.174, 0.758]\nwindshield wiper on truck: [0.562, 0.575, 0.677, 0.625]\nThe colorful front side of the truck: [0.46, 0.38, 0.782, 0.82]\n\n<tarp: [0.367, 0.402, 0.469, 0.734]> <black>\n<tarp: [0.289, 0.43, 0.37, 0.719]> <black>\n<wire: [0.251, 0.152, 0.383, 0.283]> <electric>\n<wire: [0.236, 0.245, 0.393, 0.367]> <electric>\n<wire: [0.24, 0.324, 0.391, 0.425]> <electric>\n<wires: [0.251, 0.147, 0.396, 0.442]> <electric>\n<wires: [0.637, 0.0, 0.732, 0.307]> <electric>\n<wires: [0.18, 0.245, 0.326, 0.447]> <electric>\n<sign: [0.905, 0.032, 0.996, 0.532]> <orange, blue, price>\n<flag: [0.251, 0.611, 0.274, 0.644]> <orange>\n<flag: [0.182, 0.611, 0.208, 0.654]> <blue>\n<flag: [0.144, 0.615, 0.165, 0.661]> <orange>\n<flag: [0.105, 0.624, 0.134, 0.654]> <blue>\n<sky: [0.009, 0.007, 0.997, 0.574]> <hazy>\n<poles: [0.063, 0.002, 0.783, 0.561]> <wooden>\n<poles: [0.006, 0.002, 0.78, 0.582]> <wooden>\n<truck: [0.02, 0.656, 0.179, 0.759]> <tan>\n<truck: [0.013, 0.63, 0.172, 0.768]> <tan>\n<vehicle: [0.129, 0.648, 0.273, 0.725]> <silver>\n<vehicle: [0.133, 0.635, 0.249, 0.716]> <silver>\n<leaves: [0.587, 0.308, 0.914, 0.449]> <green>\n<leaves: [0.519, 0.294, 0.914, 0.427]> <green>\n<leaves: [0.122, 0.458, 0.264, 0.647]> <green>\n<leaves: [0.129, 0.497, 0.237, 0.634]> <green>\n<leaves: [0.107, 0.506, 0.22, 0.639]> <green>\n<leaves: [0.049, 0.505, 0.221, 0.63]> <green>\n<leaves: [0.205, 0.484, 0.309, 0.599]> <green>\n", "response": "Task: What is the object located in <Region>[0.293, 0.368, 0.997, 0.888]</Region>, and what is next to it?\nOutput: The object in the region is a truck, and it is next to a metal fence.", "instruction": "What is the object located in <Region>[0.293, 0.368, 0.997, 0.888]</Region>, and what is next to it?", "input": "", "output": "The object in the region is a truck, and it is next to a metal fence.", "is_classification": false, "dataset": "VG", "img_info": "713051.jpg"}
{"img_id": 2096, "query": "white door on cabinet : [0.314, 0.008, 0.414, 0.235]\nglass window on building: [0.001, 0.517, 0.051, 0.672]\nwhite door on cabinet : [0.21, 0.642, 0.294, 0.993]\nwindow next to range: [0.0, 0.135, 0.077, 0.418]\nvertical blinds covering window: [0.706, 0.0, 0.858, 0.405]\nwhite door on cabinet : [0.314, 0.008, 0.414, 0.235]\nA window on the wall.: [0.731, 0.098, 0.856, 0.415]\nwhite door on cabinet : [0.21, 0.642, 0.294, 0.993]\ncabinet door made of white wood: [0.29, 0.712, 0.41, 0.997]\ncabinet door made of white wood: [0.401, 0.0, 0.554, 0.247]\n\n<window: [0.003, 0.425, 0.086, 0.795]> <glass>\n<window: [0.001, 0.012, 0.098, 0.505]> <glass>\n<window: [0.714, 0.01, 0.877, 0.443]> <glass>\n<door: [0.131, 0.003, 0.223, 0.207]> <white>\n<door: [0.2, 0.63, 0.422, 0.997]> <white>\n<door: [0.28, 0.687, 0.444, 0.997]> <white>\n<door: [0.314, 0.015, 0.566, 0.272]> <white>\n<door: [0.306, 0.007, 0.424, 0.243]> <white>\n<door: [0.231, 0.005, 0.319, 0.122]> <white>\n<door: [0.169, 0.017, 0.299, 0.157]> <white>\n", "response": "Task: Please describe the window in <Region>[0.714, 0.01, 0.877, 0.443]</Region>. \nOutput: The window is made of glass and has vertical blinds covering it. The window is positioned vertically and has a rectangular shape. It is located on the right side of the room.", "instruction": "Please describe the window in <Region>[0.714, 0.01, 0.877, 0.443]</Region>.", "input": "", "output": "The window is made of glass and has vertical blinds covering it. The window is positioned vertically and has a rectangular shape. It is located on the right side of the room.", "is_classification": false, "dataset": "VG", "img_info": "2096.jpg"}
{"img_id": 713330, "query": "A key on a keyboard.: [0.494, 0.771, 0.517, 0.793]\nA key on a keyboard.: [0.453, 0.741, 0.469, 0.767]\nA key on a keyboard.: [0.515, 0.759, 0.527, 0.772]\nA key on a keyboard.: [0.527, 0.784, 0.554, 0.809]\nBlack keyboard on the desk : [0.318, 0.721, 0.752, 0.842]\nComputer keyboard on pullout desk tray: [0.229, 0.674, 0.853, 0.961]\nkeys of a black colored keyboard: [0.351, 0.745, 0.382, 0.812]\nA key on a keyboard.: [0.713, 0.779, 0.724, 0.812]\nA key on a keyboard.: [0.587, 0.79, 0.6, 0.812]\nkeys of a black colored keyboard: [0.392, 0.745, 0.421, 0.811]\n\n<screen: [0.348, 0.203, 0.642, 0.522]> <large, square, black>\n<keyboard: [0.324, 0.724, 0.768, 0.845]> <large, wide, long>\n<keyboard: [0.263, 0.711, 0.795, 0.885]> <black>\n<walls: [0.005, 0.014, 0.995, 0.538]> <dark yellow>\n", "response": "Task: What is the color of the keys of the black-colored keyboard located in <Region>[0.392, 0.745, 0.421, 0.811]</Region>?\nOutput: The color of the keys of the black-colored keyboard located in that region is not mentioned in the given information.", "instruction": "What is the color of the keys of the black-colored keyboard located in <Region>[0.392, 0.745, 0.421, 0.811]</Region>?", "input": "", "output": "The color of the keys of the black-colored keyboard located in that region is not mentioned in the given information.", "is_classification": false, "dataset": "VG", "img_info": "713330.jpg"}
{"img_id": 1160192, "query": "glass is clear and clean: [0.676, 0.415, 0.688, 0.435]\nglass is clear and clean: [0.719, 0.438, 0.73, 0.461]\nnumbers on side of taxi: [0.477, 0.643, 0.561, 0.691]\nglass is clear and clean: [0.639, 0.423, 0.664, 0.445]\nglass is clear and clean: [0.733, 0.432, 0.75, 0.457]\nglass is clear and clean: [0.694, 0.406, 0.719, 0.432]\nglass is clear and clean: [0.733, 0.432, 0.75, 0.457]\ntaxi in the distance: [0.535, 0.549, 0.75, 0.624]\nback of the taxi: [0.616, 0.63, 0.818, 0.758]\nback tire of taxi: [0.44, 0.682, 0.621, 0.801]\n\n<taxi: [0.089, 0.596, 0.776, 0.779]> <back>\n<tire: [0.458, 0.704, 0.579, 0.783]> <back>\n<taxi: [0.594, 0.561, 0.682, 0.607]> <distance>\n<glass: [0.732, 0.323, 0.743, 0.34]> <clear, clean>\n<glass: [0.932, 0.448, 0.956, 0.474]> <clean, clear>\n<glass: [0.934, 0.479, 0.966, 0.491]> <clear, clean>\n<glass: [0.732, 0.435, 0.747, 0.455]> <clean, clear>\n<glass: [0.685, 0.404, 0.717, 0.432]> <clear, clean>\n<glass: [0.671, 0.413, 0.689, 0.438]> <clean, clear>\n<glass: [0.637, 0.421, 0.659, 0.447]> <clear, clean>\n<glass: [0.596, 0.435, 0.618, 0.455]> <clean, clear>\n", "response": "Task: What can you say about the back tire of the taxi indicated by <Region>[0.458, 0.704, 0.579, 0.783]</Region> in the image?\nOutput: The region indicates the back tire of a taxi in the image. No other information about the region is given.", "instruction": "What can you say about the back tire of the taxi indicated by <Region>[0.458, 0.704, 0.579, 0.783]</Region> in the image?", "input": "", "output": "The region indicates the back tire of a taxi in the image. No other information about the region is given.", "is_classification": false, "dataset": "VG", "img_info": "1160192.jpg"}
{"img_id": 1159280, "query": "person sitting on square structure: [0.646, 0.205, 0.776, 0.725]\nlarge black square structure in the sidewalk: [0.562, 0.358, 0.675, 0.523]\nlarge black square structure in the sidewalk: [0.47, 0.469, 0.634, 0.811]\nlarge black square structure in the sidewalk: [0.562, 0.358, 0.675, 0.523]\nperson sitting on square structure: [0.646, 0.205, 0.776, 0.725]\nlarge black square structure in the sidewalk: [0.562, 0.358, 0.675, 0.523]\nlarge black square structure in the sidewalk: [0.562, 0.358, 0.675, 0.523]\nlarge black square structure in the sidewalk: [0.217, 0.585, 0.403, 0.927]\nDistant person window shopping.: [0.872, 0.013, 0.95, 0.146]\nlarge black square structure in the sidewalk: [0.47, 0.469, 0.634, 0.811]\n\n<square structure: [0.479, 0.534, 0.646, 0.782]> <large, black, square>\n<square structure: [0.561, 0.372, 0.673, 0.544]> <black, large>\n<square structure: [0.704, 0.474, 0.828, 0.69]> <large, black>\n<square structure: [0.696, 0.348, 0.803, 0.461]> <black, large>\n<square structure: [0.233, 0.593, 0.41, 0.892]> <large, black>\n<structure: [0.675, 0.35, 0.847, 0.712]> <square>\n<cube: [0.23, 0.596, 0.41, 0.898]> <black>\n<pole: [0.598, 0.019, 0.614, 0.321]> <black>\n<truck: [0.601, 0.008, 0.79, 0.275]> <white>\n<window: [0.481, 0.024, 0.551, 0.132]> <grey>\n<geometric shape: [0.48, 0.523, 0.643, 0.782]> <geometrics>\n", "response": "Task: What is the shape of the <Region>[0.479, 0.534, 0.646, 0.782]</Region> in the image?\nOutput: The shape in that region is a large black square structure.", "instruction": "What is the shape of the <Region>[0.479, 0.534, 0.646, 0.782]</Region> in the image?", "input": "", "output": "The shape in that region is a large black square structure.", "is_classification": false, "dataset": "VG", "img_info": "1159280.jpg"}
{"img_id": 1592680, "query": "A light colored straw hat.: [0.067, 0.406, 0.131, 0.461]\npink flowers on top of shelter: [0.025, 0.061, 0.344, 0.189]\nthe red seat of the carriage: [0.729, 0.427, 0.825, 0.552]\nA light colored straw hat.: [0.067, 0.406, 0.131, 0.461]\nman holding horse bridle: [0.046, 0.342, 0.235, 0.845]\nhorse pulling a carriage: [0.12, 0.363, 0.92, 0.827]\nwheel on the carriage: [0.521, 0.539, 0.655, 0.737]\nA stroller with one child sitting in it.: [0.922, 0.449, 0.984, 0.548]\nthe white carriage behind the horse: [0.458, 0.362, 0.91, 0.708]\nthe banner on the lightpost: [0.477, 0.249, 0.509, 0.312]\n\n<horse: [0.148, 0.418, 0.554, 0.798]> <large, brown>\n<hat: [0.042, 0.423, 0.2, 0.466]> <brown>\n<carriage: [0.549, 0.401, 0.952, 0.772]> <red, white>\n<post: [0.153, 0.263, 0.251, 0.393]> <green>\n<shirt: [0.023, 0.464, 0.135, 0.565]> <white>\n<stroller: [0.906, 0.439, 0.996, 0.531]> <large>\n<light: [0.417, 0.228, 0.507, 0.418]> <gray>\n<letter: [0.268, 0.327, 0.324, 0.378]> <red>\n<flowers: [0.0, 0.082, 0.149, 0.188]> <purple>\n<horse: [0.142, 0.372, 0.479, 0.737]> <pulling, brown>\n<carriage: [0.456, 0.352, 0.905, 0.724]> <white>\n", "response": "Task: What are the colors of the flowers shown in <Region>[0.025, 0.061, 0.344, 0.189]</Region> in the image?\nOutput: The flowers shown in the region are pink in color.", "instruction": "What are the colors of the flowers shown in <Region>[0.025, 0.061, 0.344, 0.189]</Region> in the image?", "input": "", "output": "The flowers shown in the region are pink in color.", "is_classification": false, "dataset": "VG", "img_info": "1592680.jpg"}
{"img_id": 3772, "query": "A tree in a city.: [0.241, 0.441, 0.294, 0.552]\nA tree in a city.: [0.16, 0.443, 0.217, 0.544]\nwater next to bridge: [0.846, 0.602, 0.99, 0.71]\n a window on a building : [0.055, 0.413, 0.065, 0.423]\ncalm dark water surrounding walkway: [0.01, 0.594, 0.99, 0.98]\ntrees next to the building: [0.015, 0.429, 0.28, 0.617]\nbuilding near the trees: [0.031, 0.233, 0.245, 0.599]\nv shaped stone walkway with trees: [0.19, 0.614, 0.848, 0.987]\n a tree in a city : [0.009, 0.419, 0.096, 0.569]\nmany branches of the trees: [0.389, 0.473, 0.655, 0.614]\n\n<tower: [0.034, 0.338, 0.12, 0.441]> <brown>\n<tree: [0.728, 0.456, 0.764, 0.642]> <green>\n<tree: [0.665, 0.428, 0.725, 0.634]> <green>\n<tree: [0.515, 0.378, 0.667, 0.632]> <green>\n<tree: [0.352, 0.394, 0.519, 0.634]> <green>\n<tree: [0.292, 0.449, 0.374, 0.636]> <green>\n<water: [0.026, 0.727, 0.14, 0.854]> <calm>\n<water: [0.019, 0.596, 0.289, 0.973]> <calm>\n<grass: [0.292, 0.576, 0.76, 0.844]> <green, short>\n<building: [0.333, 0.406, 0.613, 0.611]> <red, bricked>\n<sky: [0.013, 0.017, 0.99, 0.469]> <light blue, clear>\n", "response": "Task: What can be seen next to the calm dark water, as indicated by <Region>[0.846, 0.602, 0.99, 0.71]</Region>?\nOutput: It is not clear from the information provided what exactly can be seen next to the calm dark water, as the image description only mentions the water itself without any other objects specified in the vicinity.", "instruction": "What can be seen next to the calm dark water, as indicated by <Region>[0.846, 0.602, 0.99, 0.71]</Region>?", "input": "", "output": "It is not clear from the information provided what exactly can be seen next to the calm dark water, as the image description only mentions the water itself without any other objects specified in the vicinity.", "is_classification": false, "dataset": "VG", "img_info": "3772.jpg"}
{"img_id": 1820, "query": "wavy hair on a woman: [0.214, 0.792, 0.334, 0.997]\nmountains in the painting: [0.019, 0.02, 0.584, 0.288]\nlady in the painting: [0.049, 0.273, 0.32, 0.753]\nprincess that the monsters on the mural are chasing: [0.059, 0.248, 0.263, 0.818]\nmonster drawn on wall mural: [0.2, 0.24, 0.44, 0.81]\nmonster drawn on wall mural: [0.365, 0.205, 0.619, 0.672]\nRed boot in the painting: [0.627, 0.535, 0.708, 0.683]\nmonster drawn on wall mural: [0.365, 0.205, 0.619, 0.672]\nwoman in the painting: [0.08, 0.253, 0.244, 0.79]\nmonster drawn on wall mural: [0.2, 0.24, 0.44, 0.81]\n\n<mural: [0.069, 0.072, 0.979, 0.62]> <wall>\n<mural: [0.1, 0.132, 0.794, 0.7]> <wall>\n<mural: [0.106, 0.157, 0.916, 0.738]> <wall>\n<painting: [0.02, 0.042, 0.874, 0.763]> <is large>\n<wavy hair: [0.2, 0.78, 0.325, 0.923]> <is wavy>\n", "response": "Task: Who or what is depicted in the painting indicated by the region <Region>[0.049, 0.273, 0.32, 0.753]</Region>?\nOutput: The painting contains the depiction of a lady.", "instruction": "Who or what is depicted in the painting indicated by the region <Region>[0.049, 0.273, 0.32, 0.753]</Region>?", "input": "", "output": "The painting contains the depiction of a lady.", "is_classification": false, "dataset": "VG", "img_info": "1820.jpg"}
{"img_id": 2391909, "query": "a cable on the pole: [0.341, 0.672, 0.413, 0.996]\na small hand-made signe: [0.328, 0.758, 0.688, 0.888]\nthe red and white stop sign: [0.083, 0.076, 0.965, 0.724]\na cable on the pole: [0.341, 0.672, 0.413, 0.996]\nRusty metal pole on telephone pole : [0.656, 0.698, 0.717, 0.996]\nstaples stuck in the telephone pole: [0.443, 0.906, 0.651, 0.974]\nwooden pole for mounting sign: [0.405, 0.68, 0.637, 0.788]\nsmall wooden sign on telephone pole: [0.349, 0.748, 0.68, 0.898]\nenjoy sign under stop sign: [0.344, 0.758, 0.675, 0.878]\nRusty metal pole on telephone pole : [0.656, 0.698, 0.717, 0.996]\n\n<sign: [0.107, 0.086, 0.917, 0.676]> <stop sign, red, white>\n<pole: [0.344, 0.004, 0.72, 0.996]> <rusty, brown, tall, rust, thick, wooden, small>\n<trees: [0.011, 0.012, 1.0, 0.988]> <thick, green, full>\n<enjoy sign: [0.355, 0.748, 0.677, 0.878]> <yellow, blue, red>\n<pole: [0.344, 0.0, 0.64, 0.094]> <wood>\n<leaves: [0.749, 0.014, 0.947, 0.18]> <green>\n<telephone pole: [0.344, 0.0, 0.704, 0.998]> <brown>\n<sky: [0.008, 0.024, 0.312, 0.646]> <big, white>\n<clips: [0.645, 0.796, 0.709, 0.834]> <small>\n", "response": "Task: What is the object indicated by <Region>[0.344, 0.0, 0.704, 0.998]</Region>? Is it a wooden or a metal pole?\nOutput: The object is a telephone pole, and it is made of wood.", "instruction": "What is the object indicated by <Region>[0.344, 0.0, 0.704, 0.998]</Region>? Is it a wooden or a metal pole?", "input": "", "output": "The object is a telephone pole, and it is made of wood.", "is_classification": false, "dataset": "VG", "img_info": "2391909.jpg"}
{"img_id": 286036, "query": "the mans nose : [0.485, 0.376, 0.517, 0.414]\na man with a black shirt on: [0.181, 0.155, 0.757, 0.983]\nred and white logo on shirt: [0.384, 0.63, 0.455, 0.732]\na birghtly colored safety poster: [0.797, 0.25, 0.873, 0.404]\nlogo on the shirt : [0.364, 0.605, 0.465, 0.759]\nman wears a long sleeve shirt: [0.097, 0.1, 0.767, 0.996]\nthe hair on the mans face : [0.395, 0.447, 0.436, 0.497]\nA man with a beard: [0.122, 0.133, 0.808, 0.995]\nThe man sitting in the black chair: [0.1, 0.186, 0.703, 0.965]\na red and white fist logo: [0.356, 0.599, 0.465, 0.802]\n\n<logo: [0.36, 0.591, 0.473, 0.793]> <red, white>\n<beard: [0.362, 0.327, 0.475, 0.526]> <brown>\n<poster: [0.788, 0.24, 0.882, 0.414]> <colorful>\n<man: [0.082, 0.083, 0.827, 0.995]> <happy>\n", "response": "Task: What is the color of the logo on the shirt of the man in <Region>[0.181, 0.155, 0.757, 0.983]</Region>?\nOutput: The color of the logo on the shirt of the man in the mentioned region is red and white.", "instruction": "What is the color of the logo on the shirt of the man in <Region>[0.181, 0.155, 0.757, 0.983]</Region>?", "input": "", "output": "The color of the logo on the shirt of the man in the mentioned region is red and white.", "is_classification": false, "dataset": "VG", "img_info": "286036.jpg"}
{"img_id": 3678, "query": "air terminal with slanted roof: [0.0, 0.386, 0.933, 0.669]\nsurface of green grass: [0.0, 0.762, 0.997, 0.992]\nshort green and yellow grass: [0.779, 0.782, 0.872, 0.927]\n a window on a building : [0.314, 0.434, 0.326, 0.484]\nA window on the side of a building: [0.449, 0.456, 0.466, 0.486]\nblue yellow and orange tail of plane: [0.062, 0.261, 0.198, 0.466]\n a window on a building : [0.324, 0.441, 0.361, 0.499]\n a window on a building : [0.391, 0.436, 0.408, 0.486]\n a window on a building : [0.27, 0.444, 0.286, 0.491]\nA window on the side of a building: [0.391, 0.456, 0.404, 0.486]\n\n<wheel: [0.765, 0.602, 0.832, 0.717]> <small, round>\n<stabilizer: [0.02, 0.459, 0.181, 0.599]> <horizontal>\n<stabilizer: [0.037, 0.268, 0.266, 0.511]> <vertical>\n<green: [0.273, 0.777, 0.587, 0.957]> <grass>\n<surface: [0.113, 0.697, 0.491, 0.805]> <paved>\n<asphalt: [0.156, 0.689, 0.436, 0.762]> <black>\n<roof: [0.175, 0.396, 0.551, 0.456]> <slanted>\n<plane: [0.047, 0.238, 0.892, 0.729]> <white>\n<tail: [0.027, 0.241, 0.265, 0.642]> <blue>\n<engine: [0.461, 0.642, 0.687, 0.694]> <jet>\n<design: [0.055, 0.288, 0.175, 0.469]> <sun>\n<plane: [0.025, 0.261, 0.877, 0.674]> <parked, white>\n<plane: [0.042, 0.231, 0.855, 0.699]> <white>\n<tail: [0.07, 0.256, 0.2, 0.546]> <blue, yellow, orange>\n<logo: [0.303, 0.501, 0.747, 0.549]> <red>\n<grass: [0.0, 0.664, 1.0, 0.992]> <short, green and yellow, green>\n<clouds: [0.002, 0.0, 0.997, 0.396]> <white, thick>\n<sky: [0.0, 0.0, 1.0, 0.401]> <blue, gray and white>\n<pines: [0.0, 0.133, 1.0, 0.401]> <green, tall>\n<trees: [0.0, 0.14, 0.993, 0.541]> <tall>\n<runway: [0.002, 0.699, 0.997, 0.769]> <dark gray>\n<line: [0.068, 0.747, 0.985, 0.789]> <yellow>\n<engine: [0.531, 0.584, 0.644, 0.657]> <blue>\n<tail: [0.035, 0.266, 0.296, 0.494]> <red and blue>\n<letters: [0.293, 0.504, 0.747, 0.536]> <red>\n<plane: [0.063, 0.263, 0.9, 0.762]> <white>\n<window: [0.604, 0.436, 0.621, 0.481]> <building's>\n<window: [0.582, 0.446, 0.604, 0.486]> <building's>\n<window: [0.594, 0.436, 0.611, 0.476]> <building's>\n<window: [0.587, 0.451, 0.604, 0.476]> <building's>\n<window: [0.571, 0.429, 0.587, 0.481]> <building's>\n<window: [0.611, 0.446, 0.627, 0.484]> <building's>\n<window: [0.564, 0.436, 0.577, 0.484]> <building's>\n<window: [0.8, 0.444, 0.824, 0.499]> <building's>\n<window: [0.807, 0.446, 0.824, 0.501]> <building's>\n<window: [0.809, 0.451, 0.829, 0.499]> <building's>\n<window: [0.797, 0.446, 0.819, 0.501]> <building's>\n<window: [0.797, 0.454, 0.819, 0.501]> <building's>\n<window: [0.802, 0.459, 0.824, 0.499]> <building's>\n<window: [0.807, 0.454, 0.822, 0.499]> <building's>\n<window: [0.8, 0.451, 0.817, 0.501]> <building's>\n", "response": "Task: What is the color of the grass in <Region>[0.0, 0.762, 0.997, 0.992]</Region>?\nOutput: The grass in this region is green.", "instruction": "What is the color of the grass in <Region>[0.0, 0.762, 0.997, 0.992]</Region>?", "input": "", "output": "The grass in this region is green.", "is_classification": false, "dataset": "VG", "img_info": "3678.jpg"}
{"img_id": 2391769, "query": "pink card on shelf: [0.312, 0.563, 0.496, 0.824]\nA wood shelf with various items on it: [0.08, 0.736, 0.974, 0.963]\nA ribbon tied into a bow: [0.598, 0.677, 0.788, 0.824]\nA light pink greeting card sitting on a shelf: [0.34, 0.56, 0.47, 0.867]\npink bag on shelf: [0.826, 0.52, 0.93, 0.765]\npink bow on box: [0.584, 0.653, 0.738, 0.763]\nWhite ceiling tiles: [0.8, 0.003, 0.998, 0.312]\nflowers have white petals: [0.144, 0.251, 0.358, 0.677]\nflowers have white petals: [0.144, 0.251, 0.358, 0.677]\ngreeting card on shelf: [0.342, 0.603, 0.464, 0.877]\n\n<wood frame: [0.21, 0.067, 0.412, 0.336]> <white, tan>\n<clock hands: [0.286, 0.133, 0.34, 0.235]> <colored black, black>\n<bow: [0.63, 0.675, 0.734, 0.776]> <pink>\n<shelf: [0.112, 0.768, 0.986, 0.997]> <greeting card>\n<pink greeting card: [0.352, 0.603, 0.464, 0.845]> <lavender>\n<clear vase: [0.216, 0.581, 0.314, 0.856]> <holding flowers, vase, clear>\n<petal: [0.236, 0.464, 0.26, 0.491]> <white>\n<petal: [0.188, 0.472, 0.218, 0.512]> <white>\n<petal: [0.186, 0.344, 0.212, 0.387]> <white>\n<petal: [0.294, 0.533, 0.324, 0.571]> <white>\n<petal: [0.354, 0.285, 0.386, 0.32]> <white>\n<tile: [0.822, 0.099, 0.996, 0.259]> <White>\n<bow: [0.624, 0.669, 0.734, 0.827]> <pink>\n", "response": "Task: What is the color of the ribbon in the <Region>[0.598, 0.677, 0.788, 0.824]</Region>?\nOutput: The ribbon in the region is pink in color.", "instruction": "What is the color of the ribbon in the <Region>[0.598, 0.677, 0.788, 0.824]</Region>?", "input": "", "output": "The ribbon in the region is pink in color.", "is_classification": false, "dataset": "VG", "img_info": "2391769.jpg"}
{"img_id": 244, "query": "Painting next to shelves: [0.417, 0.121, 0.454, 0.241]\nA light wooden floor: [0.001, 0.652, 0.599, 0.998]\nA black book: [0.618, 0.683, 0.725, 0.733]\nred chair in the bedroom: [0.555, 0.458, 0.995, 0.996]\nred chair in the bedroom: [0.555, 0.458, 0.995, 0.996]\nbeige pillow on top of bed: [0.105, 0.404, 0.268, 0.553]\nWhite flowers next to candles: [0.667, 0.441, 0.743, 0.629]\nwhite sash on window: [0.531, 0.005, 0.739, 0.598]\nWhite ceiling ball light: [0.062, 0.0, 0.255, 0.205]\nred pillow on bed: [0.03, 0.51, 0.207, 0.6]\n\n<candles: [0.711, 0.607, 0.757, 0.636]> <lit, red, small>\n<chair: [0.569, 0.479, 0.99, 0.996]> <red, stuffed>\n<radiator: [0.532, 0.497, 0.635, 0.724]> <white>\n<globe: [0.066, 0.0, 0.254, 0.211]> <tan, white, bright>\n<picture: [0.419, 0.128, 0.46, 0.256]> <framed, small>\n<pillow: [0.045, 0.537, 0.194, 0.595]> <red, square>\n<knobs: [0.909, 0.431, 0.949, 0.458]> <bronze>\n<flowers: [0.67, 0.447, 0.741, 0.605]> <white>\n<light: [0.276, 0.438, 0.306, 0.524]> <white>\n<pillow: [0.114, 0.429, 0.258, 0.532]> <beige, white, square>\n<book: [0.619, 0.679, 0.724, 0.737]> <black, small>\n<bed: [0.001, 0.411, 0.444, 0.877]> <made, white>\n<shelves: [0.275, 0.106, 0.379, 0.53]> <light>\n<window: [0.546, 0.0, 0.681, 0.378]> <rectangular>\n", "response": "Task: What color is the sash on the window indicated by <Region>[0.531, 0.005, 0.739, 0.598]</Region>?\nOutput: The sash on the window is white.", "instruction": "What color is the sash on the window indicated by <Region>[0.531, 0.005, 0.739, 0.598]</Region>?", "input": "", "output": "The sash on the window is white.", "is_classification": false, "dataset": "VG", "img_info": "244.jpg"}
{"img_id": 674, "query": "yellow and green umbrella: [0.003, 0.678, 0.104, 0.845]\nwindows with green awning: [0.55, 0.55, 0.672, 0.678]\nwindow on the building: [0.265, 0.503, 0.33, 0.612]\nwindow of a red building: [0.892, 0.1, 0.979, 0.293]\nUmbrellas over a group of people: [0.415, 0.725, 0.689, 0.787]\nTwo people standing together.: [0.902, 0.705, 0.998, 0.995]\nA yellow and white striped umbrella.: [0.598, 0.733, 0.7, 0.898]\nwindow on the building: [0.792, 0.692, 0.859, 0.773]\nA yellow awning on a building: [0.562, 0.677, 0.67, 0.743]\nPeople sitting near a building: [0.043, 0.812, 0.142, 0.923]\n\n<building: [0.555, 0.002, 1.0, 0.9]> <red>\n<shirt: [0.917, 0.752, 0.991, 0.865]> <blue, orange>\n<awning: [0.698, 0.352, 0.74, 0.478]> <green>\n<curtain: [0.629, 0.558, 0.656, 0.667]> <white>\n<umbrella: [0.456, 0.73, 0.545, 0.775]> <red, white>\n<umbrella: [0.0, 0.68, 0.109, 0.735]> <yellow, green>\n<bench: [0.182, 0.843, 0.292, 0.897]> <empty, dark brown>\n<planter: [0.831, 0.877, 0.879, 0.907]> <brown>\n<plant: [0.831, 0.795, 0.884, 0.877]> <green>\n<pants: [0.926, 0.855, 0.996, 0.997]> <khaki>\n<chairs: [0.421, 0.82, 0.695, 0.885]> <white>\n<umbrellas: [0.412, 0.735, 0.7, 0.78]> <together>\n<laundry: [0.104, 0.355, 0.259, 0.432]> <hanging>\n<umbrella: [0.6, 0.732, 0.696, 0.777]> <white, yellow>\n<people: [0.705, 0.805, 0.823, 0.907]> <sitting>\n<building: [0.015, 0.0, 0.297, 0.852]> <yellow>\n<doorway: [0.69, 0.69, 0.751, 0.863]> <arched>\n", "response": "Task: Are there any green windows in the <Region>[0.555, 0.002, 1.0, 0.9]</Region>?\nOutput: Yes, there is a building in that region with green awnings on its windows.", "instruction": "Are there any green windows in the <Region>[0.555, 0.002, 1.0, 0.9]</Region>?", "input": "", "output": "Yes, there is a building in that region with green awnings on its windows.", "is_classification": false, "dataset": "VG", "img_info": "674.jpg"}
{"img_id": 150521, "query": "windshield of a large plane: [0.065, 0.5, 0.146, 0.547]\nWriting on the airplane: [0.164, 0.512, 0.419, 0.607]\na view of windows in plane: [0.209, 0.471, 0.67, 0.557]\nAirplanes at the airport: [0.063, 0.324, 0.962, 0.762]\nthe emergency exit of a large plane: [0.151, 0.487, 0.218, 0.601]\nthe wing of a large plane: [0.467, 0.513, 0.671, 0.641]\nthe logo of a large plane: [0.198, 0.534, 0.395, 0.582]\nblue stripe on plane: [0.812, 0.366, 0.933, 0.434]\nred white and blue plane on ground: [0.051, 0.212, 0.99, 0.743]\nlarge door on plane: [0.736, 0.478, 0.787, 0.591]\n\n<plane: [0.05, 0.201, 0.985, 0.676]> <large, white, red, blue>\n<plane: [0.032, 0.21, 0.961, 0.656]> <large, white, red, blue>\n<plane: [0.056, 0.328, 0.964, 0.656]> <red, white, blue>\n<plane: [0.056, 0.297, 0.986, 0.663]> <white, blue, red>\n<clouds: [0.581, 0.026, 0.82, 0.243]> <white, blue>\n<plane: [0.022, 0.278, 0.979, 0.729]> <red, white, blue>\n<plane: [0.035, 0.147, 0.973, 0.644]> <white>\n<engine: [0.271, 0.588, 0.491, 0.719]> <large, blue>\n<tail: [0.788, 0.226, 0.991, 0.554]> <red, white, blue>\n<clouds: [0.361, 0.118, 0.512, 0.207]> <white, blue>\n<clouds: [0.354, 0.109, 0.482, 0.226]> <white, blue>\n", "response": "Task: What colors are on the <Region>[0.788, 0.226, 0.991, 0.554]</Region>?\nOutput: The colors on the region are red, white, and blue.", "instruction": "What colors are on the <Region>[0.788, 0.226, 0.991, 0.554]</Region>?", "input": "", "output": "The colors on the region are red, white, and blue.", "is_classification": false, "dataset": "VG", "img_info": "150521.jpg"}
{"img_id": 498144, "query": "woman kneeling by a black cat: [0.0, 0.13, 0.775, 0.993]\nThe black cat on the bench: [0.625, 0.255, 0.76, 0.542]\nblack cat on top of green bench: [0.631, 0.28, 0.755, 0.538]\nwoman's left ear behind dark hair: [0.153, 0.281, 0.185, 0.377]\nblack furry cat on green bench: [0.635, 0.288, 0.75, 0.533]\nBlack cat is sleeping: [0.635, 0.285, 0.751, 0.528]\nGrass is visible behind the bench: [0.0, 0.0, 0.998, 0.075]\ngreen bench behind blonde girl: [0.001, 0.021, 0.733, 0.918]\nThe hands are clasped: [0.351, 0.793, 0.432, 0.955]\nblack furry cat on green bench: [0.635, 0.288, 0.75, 0.533]\n\n<bench: [0.012, 0.0, 0.741, 0.925]> <light blue, green>\n<cat: [0.631, 0.274, 0.75, 0.54]> <black, furry>\n<bush: [0.661, 0.01, 0.975, 0.269]> <small>\n<jacket: [0.0, 0.25, 0.402, 0.993]> <dark, blue>\n<woman: [0.005, 0.132, 0.429, 0.995]> <smiling, bending>\n<hair: [0.135, 0.132, 0.32, 0.589]> <large, blonde>\n<nose: [0.254, 0.339, 0.285, 0.389]> <small, profiled>\n<teeth: [0.249, 0.378, 0.284, 0.418]> <white>\n<girl: [0.007, 0.137, 0.442, 0.995]> <blonde>\n<cat: [0.632, 0.283, 0.759, 0.516]> <black>\n<bench: [0.0, 0.066, 0.718, 0.991]> <blue>\n<wall: [0.311, 0.326, 0.999, 0.625]> <stone>\n<path: [0.271, 0.59, 0.999, 0.97]> <stone>\n<hands: [0.348, 0.809, 0.436, 0.932]> <clasped>\n<jacket: [0.013, 0.236, 0.363, 0.995]> <black>\n", "response": "Task: What color is the bench behind the blonde girl in <Region>[0.001, 0.021, 0.733, 0.918]</Region>?\nOutput: The bench behind the blonde girl is green.", "instruction": "What color is the bench behind the blonde girl in <Region>[0.001, 0.021, 0.733, 0.918]</Region>?", "input": "", "output": "The bench behind the blonde girl is green.", "is_classification": false, "dataset": "VG", "img_info": "498144.jpg"}
{"img_id": 498092, "query": "woman wearing dark green headwrap: [0.681, 0.15, 0.839, 0.871]\na woman standing in front of a green cabinet: [0.597, 0.134, 0.836, 0.868]\na white stove with black burners: [0.025, 0.656, 0.326, 0.996]\na square green stool : [0.742, 0.855, 0.971, 0.997]\nthe skirt is long: [0.673, 0.49, 0.784, 0.87]\nwoman wearing dark green headwrap: [0.681, 0.15, 0.839, 0.871]\nwoman wearing striped shirt: [0.205, 0.154, 0.429, 0.99]\na woman's long striped skirt: [0.471, 0.605, 0.595, 0.945]\na woman's long skirt: [0.454, 0.596, 0.595, 0.927]\nthe white knobson the oven: [0.025, 0.658, 0.329, 0.997]\n\n<skirt: [0.674, 0.504, 0.786, 0.865]> <GREEN>\n<shirt: [0.219, 0.285, 0.375, 0.585]> <STRIPED>\n<woman: [0.459, 0.242, 0.58, 0.923]> <BLUE>\n<skirt: [0.482, 0.634, 0.573, 0.9]> <PATTERNED>\n<pitchers: [0.137, 0.383, 0.194, 0.479]> <ORANGE>\n<utensils: [0.801, 0.215, 0.92, 0.382]> <COOKING, HANGING>\n<stool: [0.727, 0.862, 0.951, 0.983]> <DARK, GREEN, WOODEN>\n<headwrap: [0.729, 0.22, 0.766, 0.292]> <GREEN, DARK>\n<bucket: [0.584, 0.777, 0.609, 0.823]> <WHITE, CHECKERED, BLUE>\n<oven: [0.066, 0.664, 0.337, 0.993]> <RANGE, WHITE>\n<burners: [0.097, 0.754, 0.175, 0.841]> <GRAY>\n<pitchers: [0.132, 0.339, 0.191, 0.5]> <ORANGE>\n<skirt: [0.719, 0.518, 0.772, 0.885]> <LONG>\n<shirt: [0.459, 0.333, 0.577, 0.587]> <WHITE>\n<stool: [0.768, 0.831, 0.893, 0.992]> <DARK, GREEN>\n<scarf: [0.735, 0.242, 0.762, 0.276]> <HEAD>\n<table: [0.857, 0.647, 0.968, 0.872]> <small>\n", "response": "Task: What are the colors of the clothing worn by the woman in the <Region>[0.219, 0.285, 0.375, 0.585]</Region>?\nOutput: The woman in the region is wearing a striped shirt, but the colors of the stripes are not specified in the provided information.", "instruction": "What are the colors of the clothing worn by the woman in the <Region>[0.219, 0.285, 0.375, 0.585]</Region>?", "input": "", "output": "The woman in the region is wearing a striped shirt, but the colors of the stripes are not specified in the provided information.", "is_classification": false, "dataset": "VG", "img_info": "498092.jpg"}
{"img_id": 285677, "query": "Large metal pipe on back of vehicle.: [0.764, 0.421, 0.883, 0.48]\nlogo on front of truck: [0.428, 0.574, 0.462, 0.659]\nBlack license plate with silver letters and numbers.: [0.418, 0.702, 0.469, 0.754]\nthe windshield on the truck: [0.397, 0.356, 0.648, 0.485]\nside window on truck: [0.657, 0.329, 0.702, 0.466]\nwindshield wiper on the truck : [0.462, 0.316, 0.552, 0.413]\nLong brown wooden fence. : [0.004, 0.509, 0.998, 0.694]\nyellow logo on front of truck: [0.508, 0.517, 0.555, 0.595]\ntire is attached to truck : [0.837, 0.598, 0.895, 0.75]\nFour white headlights on front of vehicle.: [0.369, 0.61, 0.561, 0.669]\n\n<truck: [0.354, 0.283, 0.97, 0.876]> <green, red>\n<print: [0.655, 0.467, 0.709, 0.53]> <yellow>\n<building: [0.661, 0.262, 0.997, 0.611]> <brown>\n<sky: [0.005, 0.005, 0.999, 0.317]> <blue>\n<building: [0.621, 0.242, 0.999, 0.589]> <Beige>\n<window: [0.779, 0.302, 0.87, 0.422]> <white>\n<license: [0.423, 0.71, 0.475, 0.754]> <Black>\n<pipe: [0.794, 0.439, 0.888, 0.488]> <Large>\n<vehicle: [0.37, 0.279, 0.949, 0.823]> <Green and red>\n<headlight: [0.366, 0.607, 0.402, 0.651]> <white>\n<steering wheel: [0.427, 0.417, 0.495, 0.478]> <Black>\n<fence: [0.02, 0.467, 0.993, 0.702]> <Long, brown>\n<circle: [0.383, 0.533, 0.411, 0.574]> <yellow>\n<circle: [0.51, 0.525, 0.551, 0.589]> <yellow>\n<tire: [0.6, 0.628, 0.721, 0.86]> <black>\n", "response": "Task: What color are the letters and numbers on the <Region>[0.418, 0.702, 0.469, 0.754]</Region> of the truck's license plate?\nOutput: The letters and numbers on the license plate are silver.", "instruction": "What color are the letters and numbers on the <Region>[0.418, 0.702, 0.469, 0.754]</Region> of the truck's license plate?", "input": "", "output": "The letters and numbers on the license plate are silver.", "is_classification": false, "dataset": "VG", "img_info": "285677.jpg"}
{"img_id": 4401, "query": "white house in front of road : [0.066, 0.221, 0.39, 0.49]\nthe sign board is supported by a white post: [0.567, 0.434, 0.68, 0.636]\nthe sign has a white arrow. : [0.568, 0.434, 0.683, 0.596]\n a house on a street : [0.071, 0.219, 0.376, 0.486]\nthe green grass are grown in dense: [0.13, 0.499, 0.997, 0.657]\n a house on a street : [0.37, 0.297, 0.427, 0.371]\nclouds are covering the blue sky: [0.0, 0.002, 0.925, 0.326]\n a house on a street : [0.654, 0.293, 0.706, 0.375]\nthe road is smooth in texture. : [0.003, 0.476, 0.992, 0.985]\n a tree in a field : [0.418, 0.057, 0.562, 0.379]\n\n<sign: [0.543, 0.406, 0.726, 0.651]> <white, dark, blue>\n<road: [0.287, 0.684, 0.543, 0.914]> <smooth, paved, black>\n<sky: [0.086, 0.013, 0.265, 0.175]> <dark blue, colorful, cloudy, white, dark, blue>\n<grass: [0.737, 0.518, 0.867, 0.642]> <dark, green>\n<tree: [0.421, 0.088, 0.602, 0.377]> <full, lush, green>\n<house: [0.086, 0.21, 0.372, 0.417]> <black, white, wide, tall, large>\n", "response": "Task: What is the color of the sign board in <Region>[0.543, 0.406, 0.726, 0.651]</Region>?\nOutput: The sign board in that region is white, and it has dark blue writing on it.", "instruction": "What is the color of the sign board in <Region>[0.543, 0.406, 0.726, 0.651]</Region>?", "input": "", "output": "The sign board in that region is white, and it has dark blue writing on it.", "is_classification": false, "dataset": "VG", "img_info": "4401.jpg"}
{"img_id": 3548, "query": "nutritional info on the cereal: [0.201, 0.142, 0.324, 0.642]\nWhite button on a shirt: [0.5, 0.297, 0.514, 0.32]\nempty white bowl on the table: [0.406, 0.578, 0.629, 0.808]\nMouth of a man: [0.485, 0.053, 0.546, 0.107]\nBowl on a table: [0.409, 0.57, 0.632, 0.83]\ngreen lettering on the cereal box: [0.124, 0.257, 0.196, 0.345]\nCollar on a shirt: [0.54, 0.072, 0.6, 0.22]\na spoon on the table: [0.64, 0.63, 0.705, 0.725]\nman sitting at table: [0.312, 0.002, 0.966, 0.62]\nsilver watch the man is wearing: [0.374, 0.503, 0.405, 0.588]\n\n<man: [0.333, 0.013, 0.801, 0.547]> <sitting>\n<watch: [0.366, 0.472, 0.415, 0.587]> <silver>\n<carton: [0.693, 0.263, 0.961, 0.863]> <red, white>\n<bowl: [0.393, 0.547, 0.606, 0.75]> <white, glass>\n<can: [0.0, 0.472, 0.089, 0.602]> <aluminum>\n<box: [0.064, 0.045, 0.449, 0.82]> <yellow, white>\n<spoon: [0.624, 0.613, 0.736, 0.728]> <white, plastic>\n<table: [0.024, 0.54, 0.804, 0.887]> <light, wooden>\n<ring: [0.476, 0.518, 0.539, 0.568]> <gold>\n<milk: [0.655, 0.262, 0.927, 0.982]> <boxed>\n<cereal: [0.062, 0.05, 0.305, 0.743]> <boxed>\n<bowl: [0.406, 0.54, 0.755, 0.835]> <white>\n<shirt: [0.351, 0.11, 0.853, 0.667]> <brown, blue>\n<can: [0.0, 0.4, 0.125, 0.588]> <silver>\n<mouth: [0.45, 0.05, 0.595, 0.187]> <closed>\n<man: [0.335, 0.038, 0.78, 0.713]> <reaching>\n<striped shirt: [0.314, 0.108, 0.748, 0.592]> <short sleeve>\n<bowl: [0.415, 0.537, 0.636, 0.833]> <white>\n<shirt: [0.315, 0.097, 0.733, 0.598]> <patterned, striped>\n<button: [0.492, 0.222, 0.519, 0.275]> <white>\n<ring: [0.492, 0.533, 0.525, 0.562]> <gold>\n<bowl: [0.415, 0.582, 0.62, 0.803]> <white>\n", "response": "Task: What is the color of the button located in <Region>[0.492, 0.222, 0.519, 0.275]</Region>?\nOutput: The button is white.", "instruction": "What is the color of the button located in <Region>[0.492, 0.222, 0.519, 0.275]</Region>?", "input": "", "output": "The button is white.", "is_classification": false, "dataset": "VG", "img_info": "3548.jpg"}
{"img_id": 2391807, "query": "Red light upon the water: [0.556, 0.828, 0.749, 0.944]\nname beside seabird could be photoshopped out in thirty seconds: [0.222, 0.76, 0.285, 0.786]\nThis bird is sitting down: [0.166, 0.696, 0.359, 0.86]\na man? a bird? a sign? way in the distance, on the horizon: [0.139, 0.8, 0.164, 0.822]\nsingle bird flying in sky: [0.612, 0.088, 0.753, 0.242]\ntwo birds looking at water: [0.137, 0.642, 0.518, 0.88]\nhorizon line between sky and water: [0.531, 0.808, 0.993, 0.878]\nreflection of sunlight is orange red on the dark water: [0.33, 0.834, 0.812, 0.994]\nnothing on horizon in photo: [0.0, 0.688, 0.984, 0.876]\nTwo birds on the rock: [0.204, 0.732, 0.659, 0.902]\n\n<sun: [0.522, 0.098, 0.623, 0.2]> <glowing, bright, orange, white, yellow, setting>\n<bird: [0.659, 0.148, 0.758, 0.228]> <flying, small, black>\n<sky: [0.004, 0.002, 0.966, 0.842]> <orange>\n<birds: [0.224, 0.736, 0.507, 0.862]> <together, standing>\n<reflection: [0.357, 0.828, 0.807, 0.996]> <orange, red>\n<water: [0.004, 0.812, 0.966, 0.992]> <dark>\n<bill: [0.332, 0.78, 0.35, 0.794]> <curved>\n<seabird: [0.309, 0.742, 0.491, 0.87]> <silhouetted>\n<wing: [0.661, 0.184, 0.709, 0.216]> <perpendicular>\n<wing: [0.675, 0.162, 0.715, 0.18]> <perpendicular>\n<light: [0.381, 0.828, 0.821, 0.996]> <red>\n<foot: [0.406, 0.84, 0.419, 0.874]> <black>\n<foot: [0.415, 0.84, 0.424, 0.868]> <black>\n<horizon: [0.002, 0.812, 0.966, 0.85]> <yellow, gold>\n<head: [0.437, 0.742, 0.478, 0.782]> <small, white>\n<sun: [0.52, 0.11, 0.608, 0.188]> <bright>\n<object: [0.143, 0.804, 0.159, 0.818]> <large, unidentified>\n", "response": "Task: What are the colors reflected in the water, described in <Region>[0.357, 0.828, 0.807, 0.996]</Region>?\nOutput: The reflection in the water described in that region has colors of orange and red.", "instruction": "What are the colors reflected in the water, described in <Region>[0.357, 0.828, 0.807, 0.996]</Region>?", "input": "", "output": "The reflection in the water described in that region has colors of orange and red.", "is_classification": false, "dataset": "VG", "img_info": "2391807.jpg"}
{"img_id": 1159391, "query": "boy is wearing blue shirt: [0.703, 0.78, 0.806, 0.996]\nboy in red shirt beside woman: [0.795, 0.269, 0.996, 0.993]\nman is wearing a suit: [0.093, 0.138, 0.313, 0.515]\nA person is standing up: [0.505, 0.362, 0.562, 0.511]\nboy is wearing blue shirt: [0.703, 0.78, 0.806, 0.996]\nboy in red shirt with hands on table: [0.57, 0.432, 0.679, 0.734]\nman is wearing tie: [0.207, 0.228, 0.272, 0.397]\ngirl with black shirt and red tie: [0.292, 0.318, 0.42, 0.657]\nyoung boy in a red uniform shirt: [0.522, 0.408, 0.602, 0.656]\nman is wearing tie: [0.207, 0.228, 0.272, 0.397]\n\n<shirt: [0.232, 0.498, 0.313, 0.704]> <red>\n<shirt: [0.388, 0.408, 0.466, 0.593]> <red>\n<shirt: [0.431, 0.492, 0.521, 0.635]> <red>\n<shirt: [0.515, 0.485, 0.602, 0.644]> <red>\n<shirt: [0.563, 0.512, 0.678, 0.7]> <red>\n<woman: [0.774, 0.266, 0.969, 0.925]> <standing>\n<jacket: [0.795, 0.454, 0.945, 0.829]> <black>\n<skirt: [0.799, 0.814, 0.893, 0.925]> <gray>\n<man: [0.116, 0.042, 0.313, 0.533]> <standing>\n<suit: [0.128, 0.184, 0.316, 0.495]> <gray>\n<bow: [0.324, 0.703, 0.371, 0.77]> <black>\n<shirt: [0.708, 0.801, 0.795, 0.982]> <blue>\n<headband: [0.519, 0.354, 0.565, 0.4]> <red>\n<shirt: [0.211, 0.583, 0.276, 0.723]> <black>\n<tie: [0.229, 0.624, 0.266, 0.742]> <red>\n<wooden table: [0.128, 0.63, 0.778, 0.991]> <wooden, tan, small>\n<stool: [0.406, 0.231, 0.482, 0.353]> <small, wooden>\n<seat: [0.413, 0.246, 0.477, 0.291]> <tan>\n<hair: [0.198, 0.041, 0.285, 0.163]> <gray>\n<suit: [0.106, 0.171, 0.308, 0.545]> <gray>\n<tie: [0.214, 0.228, 0.261, 0.388]> <brown, tan, striped>\n<person: [0.293, 0.328, 0.435, 0.668]> <standing>\n<person: [0.669, 0.41, 0.725, 0.527]> <standing up>\n", "response": "Task: What is the color of the tie worn by the person in <Region>[0.229, 0.624, 0.266, 0.742]</Region>?\nOutput: The person in the given region is wearing a red tie.", "instruction": "What is the color of the tie worn by the person in <Region>[0.229, 0.624, 0.266, 0.742]</Region>?", "input": "", "output": "The person in the given region is wearing a red tie.", "is_classification": false, "dataset": "VG", "img_info": "1159391.jpg"}
{"img_id": 4543, "query": "the fence is long and it is made of wood: [0.003, 0.433, 0.486, 0.607]\na white ball in sand: [0.489, 0.627, 0.579, 0.73]\nNet on the volleyball court : [0.049, 0.343, 0.861, 0.513]\nLarge body of sand: [0.231, 0.69, 0.425, 0.92]\na volley ball in the sand: [0.515, 0.675, 0.537, 0.707]\na small pine tree: [0.486, 0.117, 0.632, 0.552]\nLarge body of sand: [0.719, 0.625, 0.824, 0.83]\na sandy volleyball court: [0.001, 0.525, 0.998, 0.997]\na tall wooden fence: [0.0, 0.418, 0.463, 0.635]\na tall pine tree: [0.052, 0.093, 0.145, 0.442]\n\n<sky: [0.004, 0.005, 0.826, 0.168]> <clear, blue>\n<trees: [0.004, 0.012, 0.998, 0.557]> <tall>\n<leaves: [0.0, 0.0, 0.989, 0.518]> <green>\n<fence: [0.0, 0.42, 0.476, 0.61]> <long, wooden>\n<wooden pole: [0.013, 0.337, 0.049, 0.625]> <wooden>\n<volleyball court: [0.003, 0.523, 0.996, 0.995]> <sandy>\n<pine tree: [0.453, 0.028, 0.695, 0.543]> <small>\n<pine tree: [0.175, 0.0, 0.415, 0.472]> <large>\n<privacy fence: [0.028, 0.417, 0.521, 0.573]> <wooden>\n<pine tree: [0.671, 0.017, 0.724, 0.212]> <large>\n<pine tree: [0.056, 0.038, 0.165, 0.457]> <tall>\n<fence: [0.151, 0.445, 0.274, 0.587]> <new, old>\n<sand: [0.04, 0.55, 0.89, 0.99]> <Large, Large>\n<court: [0.014, 0.293, 0.894, 0.827]> <for  volleyball>\n", "response": "Task: What is the object indicated by <Region>[0.056, 0.038, 0.165, 0.457]</Region> , and what is one of its attributes?\nOutput: The object indicated by the region is a pine tree, and one of its attributes is that it is tall.", "instruction": "What is the object indicated by <Region>[0.056, 0.038, 0.165, 0.457]</Region> , and what is one of its attributes?", "input": "", "output": "The object indicated by the region is a pine tree, and one of its attributes is that it is tall.", "is_classification": false, "dataset": "VG", "img_info": "4543.jpg"}
{"img_id": 498172, "query": "the back windows on the bus: [0.273, 0.262, 0.561, 0.443]\na red bus: [0.256, 0.096, 0.861, 0.885]\nthe back windows on the bus: [0.273, 0.262, 0.561, 0.443]\nthe red bus parked next to the green bus: [0.001, 0.069, 0.857, 0.908]\nwindow on the bus: [0.638, 0.257, 0.73, 0.442]\n a window on a bus : [0.769, 0.351, 0.8, 0.487]\na large green bus: [0.0, 0.243, 0.258, 0.778]\nwindow on the bus: [0.464, 0.292, 0.564, 0.442]\nTail light on a bus: [0.281, 0.79, 0.315, 0.848]\na large green bus: [0.0, 0.243, 0.258, 0.778]\n\n<bus: [0.223, 0.092, 0.858, 0.821]> <red>\n<people: [0.829, 0.474, 0.983, 0.666]> <standing>\n<shirt: [0.829, 0.52, 0.923, 0.666]> <blue>\n<bus: [0.024, 0.246, 0.327, 0.758]> <large, green>\n<bus: [0.206, 0.064, 0.812, 0.978]> <red>\n<door: [0.293, 0.222, 0.545, 0.717]> <back>\n<bus: [0.211, 0.092, 0.857, 0.93]> <red>\n<windows: [0.265, 0.233, 0.564, 0.49]> <back>\n<windows: [0.636, 0.214, 0.879, 0.542]> <side>\n<bus: [0.002, 0.192, 0.243, 0.819]> <parked outside, green>\n<bus: [0.232, 0.076, 0.854, 0.996]> <red, parked outside>\n<bus: [0.002, 0.222, 0.232, 0.831]> <green>\n<bus: [0.216, 0.111, 0.912, 0.965]> <red>\n<bus: [0.015, 0.19, 0.236, 0.799]> <green>\n<clouds: [0.007, 0.035, 0.312, 0.213]> <white>\n<sky: [0.013, 0.02, 0.303, 0.213]> <blue>\n<people: [0.836, 0.491, 0.993, 0.71]> <standing>\n<license plate: [0.473, 0.567, 0.564, 0.722]> <black>\n<bus: [0.018, 0.214, 0.53, 0.783]> <green>\n<bus: [0.015, 0.159, 0.249, 0.84]> <green>\n<vest: [0.848, 0.539, 0.901, 0.617]> <black>\n", "response": "Task: What color is the large bus seen in <Region>[0.002, 0.192, 0.243, 0.819]</Region>?\nOutput: The bus' color is green.", "instruction": "What color is the large bus seen in <Region>[0.002, 0.192, 0.243, 0.819]</Region>?", "input": "", "output": "The bus' color is green.", "is_classification": false, "dataset": "VG", "img_info": "498172.jpg"}
{"img_id": 3159, "query": "glass window on the building: [0.661, 0.008, 0.761, 0.268]\nwindow on a building: [0.671, 0.023, 0.757, 0.268]\nA window on a building.: [0.417, 0.523, 0.52, 0.785]\nblue/green plastic over the windows: [0.146, 0.002, 0.346, 0.402]\nwindow on a building: [0.448, 0.083, 0.521, 0.313]\nbucket in the window: [0.669, 0.642, 0.733, 0.753]\nwindow on a building: [0.841, 0.005, 0.896, 0.302]\nglass window on the building: [0.591, 0.022, 0.674, 0.285]\nglass window on the building: [0.594, 0.027, 0.667, 0.282]\nwindow on a building: [0.517, 0.065, 0.589, 0.295]\n\n<name: [0.401, 0.308, 0.664, 0.417]> <white>\n<car: [0.0, 0.697, 0.145, 0.997]> <white>\n<building: [0.001, 0.013, 0.152, 0.748]> <white>\n<door: [0.853, 0.438, 0.968, 0.857]> <black>\n<strip: [0.859, 0.33, 0.995, 0.425]> <yellow>\n<plastic: [0.149, 0.0, 0.416, 0.415]> <green, blue, over>\n<window: [0.311, 0.508, 0.401, 0.77]> <glass>\n<window: [0.414, 0.535, 0.511, 0.793]> <glass>\n", "response": "Task: Please describe the appearance of the object located in <Region>[0.853, 0.438, 0.968, 0.857]</Region> and state its color.\nOutput: The object in the region is a door, and its appearance is not further described. However, it is colored black.", "instruction": "Please describe the appearance of the object located in <Region>[0.853, 0.438, 0.968, 0.857]</Region> and state its color.", "input": "", "output": "The object in the region is a door, and its appearance is not further described. However, it is colored black.", "is_classification": false, "dataset": "VG", "img_info": "3159.jpg"}
{"img_id": 3514, "query": "a blue truck on the street: [0.216, 0.077, 0.286, 0.158]\nSmall blue truck : [0.212, 0.071, 0.295, 0.165]\nthe green fence in front of the car: [0.606, 0.058, 0.998, 0.225]\nWhite car parked on the side of the road : [0.278, 0.094, 0.328, 0.154]\na white line : [0.33, 0.212, 0.377, 0.273]\nAsphalted road with vehicles : [0.0, 0.067, 0.998, 0.8]\na white dump truck : [0.008, 0.052, 0.211, 0.212]\nWhite lines painted on the street : [0.855, 0.283, 0.998, 0.433]\nthe white lines for the crosswalk: [0.0, 0.223, 0.458, 0.254]\nWhite truck parked on the side of the road: [0.045, 0.079, 0.181, 0.192]\n\n<road: [0.002, 0.131, 0.997, 0.819]> <gray>\n<line: [0.058, 0.219, 0.142, 0.256]> <white>\n<line: [0.166, 0.219, 0.237, 0.254]> <white>\n<line: [0.272, 0.219, 0.33, 0.254]> <white>\n<line: [0.388, 0.227, 0.42, 0.26]> <white>\n<line: [0.331, 0.225, 0.378, 0.254]> <white>\n<fence: [0.517, 0.0, 1.0, 0.225]> <green>\n<entrance: [0.062, 0.677, 0.972, 0.994]> <driveway entrance>\n<dump truck: [0.048, 0.062, 0.17, 0.194]> <white>\n<truck: [0.045, 0.065, 0.173, 0.198]> <good sized>\n<truck: [0.217, 0.083, 0.281, 0.156]> <blue>\n<material: [0.608, 0.071, 0.998, 0.221]> <green>\n<sedan: [0.277, 0.09, 0.328, 0.138]> <white>\n<truck: [0.044, 0.069, 0.167, 0.2]> <white>\n<car: [0.533, 0.087, 0.742, 0.229]> <black>\n<truck: [0.212, 0.073, 0.289, 0.154]> <blue>\n<car: [0.278, 0.09, 0.323, 0.154]> <white>\n<partition: [0.606, 0.073, 0.998, 0.212]> <green>\n", "response": "Task: What color is the truck in <Region>[0.045, 0.065, 0.173, 0.198]</Region>?\nOutput: The truck in that region is white.", "instruction": "What color is the truck in <Region>[0.045, 0.065, 0.173, 0.198]</Region>?", "input": "", "output": "The truck in that region is white.", "is_classification": false, "dataset": "VG", "img_info": "3514.jpg"}
{"img_id": 2143, "query": "the steps are on the house: [0.78, 0.62, 0.894, 0.842]\nA gray electrical box on a house: [0.694, 0.543, 0.746, 0.645]\ngray roof of house: [0.177, 0.0, 0.651, 0.177]\nthe meters are outside the house: [0.701, 0.558, 0.731, 0.628]\nthe pole holding up the sign: [0.547, 0.442, 0.574, 0.727]\na grey electrical box with meters: [0.684, 0.528, 0.751, 0.665]\nconcrete sidewalk on side of house: [0.57, 0.803, 0.998, 0.987]\nthe meters are outside the house: [0.701, 0.558, 0.731, 0.628]\nDark gray steps near a house: [0.781, 0.612, 0.904, 0.84]\na grey car parked next to a sidewalk: [0.016, 0.607, 0.586, 0.962]\n\n<car: [0.001, 0.605, 0.579, 0.982]> <silver, parked>\n<walk: [0.601, 0.807, 0.998, 0.99]> <concrete>\n<stairs: [0.752, 0.582, 0.938, 0.86]> <gray>\n<house: [0.146, 0.002, 0.996, 0.813]> <gray, blue, white>\n<sign: [0.054, 0.555, 0.115, 0.625]> <red, white>\n<leaves: [0.605, 0.902, 0.791, 0.968]> <dry, brown>\n<house: [0.152, 0.002, 0.998, 0.698]> <gray>\n<trim: [0.169, 0.46, 0.219, 0.632]> <white>\n<electrical box: [0.69, 0.537, 0.744, 0.645]> <grey, electrical>\n<meter: [0.713, 0.555, 0.733, 0.583]> <electrical, grey>\n<meter: [0.706, 0.597, 0.724, 0.625]> <grey, electrical>\n<grey car: [0.003, 0.617, 0.576, 0.963]> <grey>\n<grey handrail: [0.863, 0.537, 0.909, 0.812]> <grey>\n<steps: [0.769, 0.618, 0.866, 0.838]> <grey>\n<brown leaves: [0.636, 0.787, 0.694, 0.822]> <brown>\n<sign: [0.552, 0.367, 0.583, 0.453]> <one>\n<sign: [0.573, 0.368, 0.606, 0.457]> <one>\n<electrical wires: [0.521, 0.005, 0.731, 0.167]> <electrical>\n<porch: [0.77, 0.212, 0.968, 0.628]> <small>\n<car: [0.003, 0.628, 0.579, 0.955]> <grey>\n<tire: [0.24, 0.81, 0.334, 0.965]> <rubber>\n<sedan: [0.016, 0.62, 0.542, 0.915]> <silver, four-door>\n<steps: [0.787, 0.685, 0.877, 0.82]> <gray, set>\n<sedan: [0.046, 0.612, 0.515, 0.945]> <gray>\n<sidewalk: [0.626, 0.793, 0.926, 0.997]> <concrete>\n<roof: [0.23, 0.013, 0.615, 0.16]> <gray>\n<light: [0.39, 0.743, 0.475, 0.82]> <red>\n<plate: [0.479, 0.742, 0.541, 0.828]> <white>\n<box: [0.682, 0.518, 0.752, 0.658]> <gray, electrical>\n<steps: [0.739, 0.59, 0.905, 0.873]> <dark, gray>\n<window: [0.206, 0.387, 0.284, 0.558]> <white, framed>\n<fence: [0.911, 0.488, 0.978, 0.613]> <wooden>\n<house: [0.166, 0.133, 0.964, 0.92]> <gray>\n<sedan: [0.013, 0.577, 0.579, 1.0]> <silver, parked>\n<roof: [0.211, 0.382, 0.269, 0.39]> <gray, shingled>\n", "response": "Task: Are there any leaves on the tree near the <Region>[0.605, 0.902, 0.791, 0.968]</Region>?\nOutput: Yes, there are leaves on the tree near that region. The leaves appear to be dry and brown.", "instruction": "Are there any leaves on the tree near the <Region>[0.605, 0.902, 0.791, 0.968]</Region>?", "input": "", "output": "Yes, there are leaves on the tree near that region. The leaves appear to be dry and brown.", "is_classification": false, "dataset": "VG", "img_info": "2143.jpg"}
{"img_id": 4278, "query": "silver sink in the kitchen: [0.225, 0.547, 0.392, 0.658]\nfloor is dark brown: [0.019, 0.831, 0.312, 0.952]\nA door for a cabinet.: [0.239, 0.622, 0.322, 0.919]\nA door for a cabinet.: [0.914, 0.008, 0.963, 0.134]\nA door for a cabinet.: [0.191, 0.626, 0.244, 0.881]\nThe right side window in the room.: [0.056, 0.251, 0.122, 0.486]\nThe cabinet doors under the sink.: [0.202, 0.62, 0.383, 0.954]\nwindows are dark brown: [0.0, 0.186, 0.15, 0.505]\nceramic brown tiles on a floor: [0.002, 0.833, 0.372, 0.994]\na set of cabinets: [0.15, 0.132, 0.43, 0.42]\n\n<surface: [0.453, 0.653, 0.598, 0.689]> <heating, flat>\n<floor: [0.008, 0.806, 0.372, 0.987]> <brown, tiled>\n<cabinets: [0.111, 0.572, 0.892, 0.994]> <off white>\n<faucet: [0.32, 0.514, 0.378, 0.605]> <silver>\n<cabinet: [0.658, 0.01, 0.914, 0.284]> <white>\n<window frame: [0.002, 0.219, 0.161, 0.541]> <brown, wooden>\n<oven door: [0.653, 0.522, 0.912, 0.944]> <black>\n<sink: [0.206, 0.566, 0.406, 0.651]> <silver>\n<electrical outlet: [0.459, 0.534, 0.502, 0.576]> <white>\n<countertop: [0.102, 0.526, 0.673, 0.772]> <dark brown>\n<kitchen sink: [0.22, 0.587, 0.405, 0.664]> <stainless steel>\n<shutter: [0.113, 0.259, 0.198, 0.476]> <wooden, brown>\n<sink: [0.198, 0.568, 0.402, 0.662]> <stainless steel>\n<cabinets: [0.166, 0.132, 0.447, 0.445]> <pale, brown>\n<hood: [0.38, 0.04, 0.666, 0.432]> <white>\n<window: [0.0, 0.209, 0.156, 0.551]> <wood framed>\n<tiles: [0.073, 0.879, 0.209, 0.987]> <ceramic, brown>\n<stripes: [0.489, 0.084, 0.639, 0.129]> <blue>\n", "response": "Task: What is the color of the door for the cabinet in the <Region>[0.239, 0.622, 0.322, 0.919]</Region>?\nOutput: It is not clear what the color of the door for the cabinet in the specified region is as there could be more than one cabinet door in that region.", "instruction": "What is the color of the door for the cabinet in the <Region>[0.239, 0.622, 0.322, 0.919]</Region>?", "input": "", "output": "It is not clear what the color of the door for the cabinet in the specified region is as there could be more than one cabinet door in that region.", "is_classification": false, "dataset": "VG", "img_info": "4278.jpg"}
{"img_id": 713312, "query": "people riding a motorcycle : [0.08, 0.385, 0.442, 0.997]\ndirt next to the bike: [0.555, 0.558, 0.938, 0.9]\na pile of dirt: [0.482, 0.56, 0.996, 0.992]\na pile of dirt: [0.482, 0.56, 0.996, 0.992]\na long sleeve white shirt: [0.135, 0.488, 0.342, 0.775]\nthe sign is square: [0.338, 0.265, 0.364, 0.327]\ngas station has sign: [0.512, 0.529, 0.543, 0.679]\nthe dirt is in a pile: [0.488, 0.571, 0.998, 0.989]\nthe sign on the pole: [0.331, 0.262, 0.363, 0.672]\nsign is orange and blue: [0.333, 0.247, 0.398, 0.405]\n\n<vehicle: [0.364, 0.575, 0.508, 0.689]> <green, yellow, large>\n<pile: [0.476, 0.554, 0.998, 0.988]> <large>\n<shirt: [0.138, 0.488, 0.345, 0.771]> <white>\n<motorcycle: [0.074, 0.595, 0.455, 0.994]> <black>\n<dirt: [0.55, 0.555, 0.938, 0.9]> <black>\n<sign: [0.334, 0.259, 0.36, 0.321]> <white>\n<dirt: [0.488, 0.574, 0.993, 0.983]> <piled>\n", "response": "Task: What are the two colors of the sign shown in <Region>[0.333, 0.247, 0.398, 0.405]</Region>?\nOutput: The two colors of the sign in the given region are orange and blue.", "instruction": "What are the two colors of the sign shown in <Region>[0.333, 0.247, 0.398, 0.405]</Region>?", "input": "", "output": "The two colors of the sign in the given region are orange and blue.", "is_classification": false, "dataset": "VG", "img_info": "713312.jpg"}
{"img_id": 3072, "query": "car on the street: [0.147, 0.665, 0.37, 0.748]\na black compact car : [0.128, 0.617, 0.404, 0.823]\nwindow on the car: [0.235, 0.677, 0.291, 0.707]\ncar on the road: [0.154, 0.652, 0.359, 0.725]\na car in the street : [0.169, 0.655, 0.361, 0.783]\ncar on the road: [0.486, 0.445, 0.993, 0.77]\ndark blue colored car: [0.152, 0.657, 0.389, 0.787]\nbus sign on a pole: [0.031, 0.422, 0.101, 0.518]\nperson standing behind the car: [0.138, 0.652, 0.158, 0.74]\nA street sign indicating the red route.: [0.02, 0.407, 0.101, 0.505]\n\n<sign: [0.025, 0.4, 0.098, 0.523]> <bus>\n<car: [0.154, 0.627, 0.431, 0.843]> <black>\n", "response": "Task: What is the object indicated by <Region>[0.152, 0.657, 0.389, 0.787]</Region>, and what is its color?\nOutput: The object is a car, and it is colored dark blue.", "instruction": "What is the object indicated by <Region>[0.152, 0.657, 0.389, 0.787]</Region>, and what is its color?", "input": "", "output": "The object is a car, and it is colored dark blue.", "is_classification": false, "dataset": "VG", "img_info": "3072.jpg"}
{"img_id": 2391864, "query": "a round chrome base: [0.054, 0.677, 0.138, 0.751]\na round chrome base: [0.208, 0.76, 0.322, 0.844]\nan assortment of bar stools on the sidewalk outside a store: [0.054, 0.042, 0.976, 0.569]\nseven different colour barstools outside a furniture shop: [0.006, 0.057, 0.992, 0.994]\na round chrome base: [0.054, 0.677, 0.138, 0.751]\nseven differently shaped barstools behind a weathered wooden bench: [0.0, 0.443, 0.638, 0.994]\nsteel silver chair: [0.036, 0.204, 0.162, 0.757]\nblack and chrome chair: [0.066, 0.138, 0.36, 0.766]\na red chrome stool: [0.726, 0.126, 0.996, 0.985]\nblack and chrome chair: [0.066, 0.138, 0.36, 0.766]\n\n<chair: [0.542, 0.045, 0.846, 0.383]> <green, chained>\n<chair: [0.382, 0.048, 0.654, 0.368]> <red>\n<bench: [0.002, 0.488, 0.634, 0.997]> <wood, long, carved>\n<chair: [0.174, 0.153, 0.388, 0.371]> <orange, tall, lucite/acrylic>\n<chair: [0.086, 0.168, 0.304, 0.35]> <black, chrome, curved>\n<back cushion: [0.632, 0.048, 0.856, 0.177]> <green>\n<gate: [0.002, 0.006, 0.116, 0.491]> <white, folding>\n<wall: [0.156, 0.29, 0.994, 0.943]> <brick, beige, painted, storefront, dirty>\n<stool: [0.72, 0.314, 0.994, 0.997]> <backless>\n<arm rests: [0.538, 0.12, 0.634, 0.359]> <chrome>\n<arm rests: [0.728, 0.15, 0.818, 0.392]> <chrome>\n<arm rest: [0.38, 0.126, 0.464, 0.344]> <chrome>\n<foot rest: [0.74, 0.775, 0.868, 0.862]> <chrome>\n<foot rest: [0.6, 0.683, 0.72, 0.74]> <chrome>\n<base: [0.136, 0.716, 0.284, 0.808]> <round>\n<base: [0.416, 0.829, 0.626, 0.982]> <round>\n<base: [0.052, 0.701, 0.142, 0.766]> <round>\n<base: [0.214, 0.769, 0.302, 0.853]> <round>\n<sidewalk: [0.002, 0.674, 0.998, 1.0]> <concrete>\n<chairs: [0.38, 0.063, 0.852, 0.997]> <the same>\n<chairs: [0.014, 0.069, 0.984, 0.611]> <muticolored>\n", "response": "Task: What is the main similarity between <Region>[0.136, 0.716, 0.284, 0.808]</Region> and <Region>[0.052, 0.701, 0.142, 0.766]</Region> in the image?\nOutput: Both regions indicate a round chrome base in the image.", "instruction": "What is the main similarity between <Region>[0.136, 0.716, 0.284, 0.808]</Region> and <Region>[0.052, 0.701, 0.142, 0.766]</Region> in the image?", "input": "", "output": "Both regions indicate a round chrome base in the image.", "is_classification": false, "dataset": "VG", "img_info": "2391864.jpg"}
{"img_id": 1592873, "query": "unglazed doughnuts on the conveyor belt: [0.601, 0.748, 0.998, 0.974]\nunglazed doughnuts on the conveyor belt: [0.601, 0.748, 0.998, 0.974]\nA wall on the side of a building: [0.034, 0.056, 0.744, 0.991]\nA conveyor belt processing donuts : [0.0, 0.418, 0.995, 0.994]\nA donut coming off the line.: [0.142, 0.634, 0.189, 0.675]\nwhite door with gold door knob: [0.372, 0.246, 0.445, 0.552]\nA set of glazing liquid: [0.512, 0.621, 0.859, 0.808]\na donut is covered with glase: [0.269, 0.743, 0.336, 0.808]\na donut on the belt: [0.781, 0.772, 0.876, 0.871]\nA donut coming off the line.: [0.279, 0.748, 0.343, 0.799]\n\n<building: [0.001, 0.002, 0.994, 0.981]> <side>\n<bakery: [0.001, 0.004, 0.995, 0.993]> <large scale, muffin>\n<pipe: [0.583, 0.45, 0.944, 0.698]> <wide, strong, machine>\n<surface: [0.003, 0.94, 0.263, 0.994]> <brown, shiny>\n<cap: [0.655, 0.271, 0.708, 0.332]> <white>\n<doughnuts: [0.005, 0.496, 0.461, 0.834]> <glazed>\n<belt: [0.0, 0.403, 1.0, 0.989]> <conveyor>\n<doughnuts: [0.603, 0.771, 0.999, 0.944]> <unglazed>\n<sign: [0.641, 0.009, 0.998, 0.655]> <light up, red, neon>\n<shirt: [0.63, 0.368, 0.713, 0.519]> <pink>\n<visor: [0.685, 0.299, 0.725, 0.341]> <white>\n<door: [0.369, 0.233, 0.449, 0.547]> <white>\n<knob: [0.43, 0.444, 0.444, 0.453]> <gold>\n<wires: [0.295, 0.009, 0.465, 0.22]> <black>\n<donut: [0.15, 0.642, 0.182, 0.701]> <glaze>\n<donut: [0.274, 0.746, 0.328, 0.806]> <glaze>\n<donut: [0.041, 0.55, 0.081, 0.593]> <glaze>\n<donut: [0.041, 0.616, 0.081, 0.664]> <glaze>\n<liquid: [0.481, 0.616, 0.851, 0.875]> <glazing>\n<liquid: [0.477, 0.604, 0.844, 0.886]> <white, glazing>\n<hose: [0.579, 0.451, 0.935, 0.685]> <gray>\n<doughnuts: [0.011, 0.502, 0.432, 0.821]> <glazed>\n", "response": "Task: What is the object in <Region>[0.511, 0.621, 0.859, 0.808]</Region> of the image, and what is its purpose?\nOutput: The object in this region is a set of glazing liquid, which is used to make glazed doughnuts.", "instruction": "What is the object in <Region>[0.511, 0.621, 0.859, 0.808]</Region> of the image, and what is its purpose?", "input": "", "output": "The object in this region is a set of glazing liquid, which is used to make glazed doughnuts.", "is_classification": false, "dataset": "VG", "img_info": "1592873.jpg"}
{"img_id": 3434, "query": "car on the road: [0.454, 0.757, 0.495, 0.8]\nLicense plate on black of the car : [0.823, 0.777, 0.915, 0.823]\nLicense plate on black of the car : [0.823, 0.777, 0.915, 0.823]\nwindow on the building: [0.328, 0.418, 0.345, 0.493]\nLicense plate on the car: [0.845, 0.78, 0.901, 0.825]\nMan wearing brown pants : [0.625, 0.748, 0.666, 0.818]\nwindow on the building: [0.328, 0.418, 0.345, 0.493]\nwindow on the building: [0.285, 0.402, 0.309, 0.478]\nwindow on the building: [0.355, 0.442, 0.381, 0.512]\ngray suv in street: [0.802, 0.705, 0.96, 0.878]\n\n<suv: [0.802, 0.715, 0.956, 0.875]> <gray>\n<car: [0.184, 0.737, 0.339, 0.83]> <black>\n<leaf: [0.581, 0.155, 0.593, 0.172]> <green>\n<leaf: [0.676, 0.217, 0.693, 0.235]> <green>\n<leaf: [0.703, 0.338, 0.714, 0.352]> <green>\n<leaf: [0.554, 0.232, 0.566, 0.25]> <green>\n<sweater: [0.63, 0.722, 0.662, 0.768]> <blue>\n<pants: [0.627, 0.762, 0.66, 0.835]> <sandy>\n<sky: [0.004, 0.005, 0.998, 0.557]> <blue, clear, light blue>\n<lamppost: [0.884, 0.302, 0.994, 0.332]> <large>\n<building: [0.236, 0.317, 0.381, 0.512]> <big>\n<building: [0.004, 0.182, 0.285, 0.817]> <big>\n<overcoat: [0.04, 0.763, 0.074, 0.795]> <red>\n<car: [0.796, 0.717, 0.95, 0.868]> <gray>\n<license plate: [0.855, 0.793, 0.895, 0.812]> <white>\n", "response": "Task: What is the color of the license plate on the car indicated by <Region>[0.845, 0.78, 0.901, 0.825]</Region>?\nOutput: The color of the license plate on the car is white.", "instruction": "What is the color of the license plate on the car indicated by <Region>[0.845, 0.78, 0.901, 0.825]</Region>?", "input": "", "output": "The color of the license plate on the car is white.", "is_classification": false, "dataset": "VG", "img_info": "3434.jpg"}
{"img_id": 4913, "query": "illumination on the table from the lamp: [0.211, 0.678, 0.324, 0.733]\nthe white plug is in the wall socket: [0.058, 0.822, 0.096, 0.883]\nThe white wall on the right.: [0.954, 0.015, 0.995, 0.993]\nA small lamp sitting on a table.: [0.239, 0.61, 0.294, 0.714]\nsmall lamp on table: [0.241, 0.61, 0.299, 0.709]\nthe lamp shade : [0.247, 0.623, 0.293, 0.661]\nwhite cord plugged into outlet: [0.058, 0.817, 0.104, 0.896]\nA wood wall panel.: [0.619, 0.513, 0.665, 0.676]\nsmall lamp on table: [0.241, 0.61, 0.299, 0.709]\nA wood wall panel.: [0.619, 0.513, 0.665, 0.676]\n\n<strip: [0.732, 0.518, 0.82, 0.822]> <wood>\n<wall: [0.006, 0.011, 0.953, 0.991]> <light brown, paneled>\n<strip: [0.907, 0.502, 0.948, 0.932]> <wood>\n<stripe: [0.457, 0.667, 0.521, 0.753]> <wood>\n<plug: [0.065, 0.828, 0.079, 0.852]> <white>\n<lamp: [0.231, 0.604, 0.298, 0.714]> <yellow>\n<wall: [0.827, 0.522, 0.904, 0.85]> <brown>\n<lamp: [0.236, 0.604, 0.301, 0.72]> <small>\n<base: [0.249, 0.659, 0.287, 0.714]> <round>\n<lampshade: [0.238, 0.606, 0.302, 0.67]> <light colored>\n<table: [0.175, 0.7, 0.357, 0.83]> <small, wooden>\n<cord: [0.057, 0.824, 0.107, 0.896]> <white>\n<slanted ceiling: [0.019, 0.004, 0.976, 0.518]> <slanted, white>\n<lamp: [0.239, 0.608, 0.301, 0.711]> <small>\n<bedspread: [0.065, 0.659, 0.798, 0.991]> <red, blue>\n<cord: [0.057, 0.817, 0.107, 0.901]> <electrical>\n", "response": "Task: What is the color of the cord plugged into the outlet indicated by the <Region>[0.057, 0.817, 0.104, 0.896]</Region>? What is the color of the lampshade in the <Region>[0.238, 0.606, 0.302, 0.67]</Region>?\nOutput: The cord plugged into the outlet is white, and the lampshade in the region is light-colored.", "instruction": "What is the color of the cord plugged into the outlet indicated by the <Region>[0.057, 0.817, 0.104, 0.896]</Region>? What is the color of the lampshade in the <Region>[0.238, 0.606, 0.302, 0.67]</Region>?", "input": "", "output": "The cord plugged into the outlet is white, and the lampshade in the region is light-colored.", "is_classification": false, "dataset": "VG", "img_info": "4913.jpg"}
{"img_id": 1592891, "query": "writing on the boat : [0.696, 0.637, 0.771, 0.707]\nthe boat is large: [0.062, 0.336, 0.965, 0.771]\nOrange mast on large boat: [0.547, 0.008, 0.589, 0.521]\na view of boat: [0.317, 0.223, 0.991, 0.814]\nSmall tan and orange boat: [0.004, 0.419, 0.375, 0.87]\nthe rocks are grey : [0.864, 0.124, 0.936, 0.233]\nWhite covers on yellow boat: [0.162, 0.297, 0.565, 0.573]\nLarge yellow and orange boat: [0.001, 0.008, 0.981, 0.754]\nLarge yellow and orange boat: [0.001, 0.008, 0.981, 0.754]\nRocky hills behind the boat: [0.001, 0.004, 0.998, 0.531]\n\n<boat: [0.35, 0.486, 0.956, 0.74]> <large, yellow, orange>\n<boat: [0.006, 0.581, 0.395, 0.844]> <orange, tan, small>\n<hills: [0.187, 0.078, 0.486, 0.24]> <rocky>\n<stripes: [0.13, 0.396, 0.215, 0.577]> <blue, grey>\n<cover: [0.062, 0.514, 0.164, 0.659]> <white>\n<covers: [0.282, 0.309, 0.572, 0.562]> <white>\n<boat: [0.324, 0.449, 0.971, 0.72]> <yellow>\n<water: [0.413, 0.767, 0.891, 0.948]> <body, calm>\n<mast: [0.561, 0.038, 0.597, 0.277]> <orange>\n<boat: [0.219, 0.178, 0.938, 0.689]> <large>\n<boat: [0.379, 0.263, 0.962, 0.786]> <view>\n<water: [0.516, 0.789, 0.786, 0.97]> <view>\n<riddles: [0.733, 0.812, 0.942, 0.982]> <view>\n<cloth: [0.175, 0.418, 0.22, 0.543]> <view>\n<boat: [0.49, 0.474, 0.968, 0.757]> <yellow, red>\n<water: [0.451, 0.857, 0.769, 0.941]> <reflection>\n<rocks: [0.428, 0.171, 0.504, 0.286]> <gray>\n<pole: [0.551, 0.004, 0.583, 0.531]> <red>\n<tarps: [0.006, 0.29, 0.56, 0.573]> <white>\n<fabric: [0.072, 0.387, 0.244, 0.578]> <stripe>\n<boat: [0.049, 0.004, 0.97, 0.772]> <large>\n<boat: [0.004, 0.38, 0.382, 0.833]> <small>\n<water: [0.02, 0.628, 0.965, 0.986]> <ocean>\n<boat: [0.016, 0.482, 0.375, 0.854]> <small>\n<towel: [0.222, 0.414, 0.563, 0.583]> <white>\n<rocks: [0.028, 0.034, 0.948, 0.346]> <grey>\n<towel: [0.062, 0.383, 0.243, 0.591]> <stripped>\n", "response": "Task: What is the color of the mast on the boat indicated by <Region>[0.561, 0.038, 0.597, 0.277]</Region>?\nOutput: The mast on the boat is orange.", "instruction": "What is the color of the mast on the boat indicated by <Region>[0.561, 0.038, 0.597, 0.277]</Region>?", "input": "", "output": "The mast on the boat is orange.", "is_classification": false, "dataset": "VG", "img_info": "1592891.jpg"}
{"img_id": 1592444, "query": "cement and stone wall on side of water: [0.01, 0.776, 0.997, 0.87]\nbuilding has a window: [0.65, 0.603, 0.677, 0.639]\nwaves in the water: [0.145, 0.863, 0.456, 0.998]\nbuilding has a window: [0.725, 0.562, 0.758, 0.6]\nwindows on the building: [0.275, 0.498, 0.978, 0.742]\nround clock on tall tower: [0.454, 0.304, 0.514, 0.339]\nbuilding has a window: [0.65, 0.641, 0.674, 0.678]\nbuilding has a window: [0.725, 0.562, 0.758, 0.6]\nPeople siting on stone partition: [0.789, 0.698, 0.917, 0.793]\nman wearing a black jacket : [0.651, 0.718, 0.695, 0.749]\n\n<banner: [0.815, 0.365, 0.848, 0.408]> <blue>\n<building: [0.005, 0.0, 0.997, 0.763]> <ancient-looking, brick>\n<jeans: [0.694, 0.75, 0.724, 0.782]> <blue>\n<jacket: [0.69, 0.728, 0.738, 0.764]> <black>\n<jacket: [0.634, 0.709, 0.706, 0.792]> <black>\n<jacket: [0.18, 0.719, 0.21, 0.737]> <black>\n<jeans: [0.694, 0.751, 0.727, 0.78]> <blue>\n<shirt: [0.134, 0.76, 0.16, 0.777]> <white>\n<lid: [0.859, 0.709, 0.908, 0.727]> <yellow>\n<sky: [0.004, 0.0, 0.928, 0.494]> <clear, cloudless, blue>\n<water: [0.004, 0.834, 0.992, 0.997]> <dirty-looking, pool>\n<pillar: [0.749, 0.728, 0.788, 0.764]> <short, strong, stone>\n<partition: [0.0, 0.742, 0.997, 0.792]> <stone>\n<window: [0.316, 0.562, 0.383, 0.697]> <large, arc-shaped, dark>\n<window: [0.404, 0.552, 0.47, 0.689]> <large, arc-shaped, dark>\n<window: [0.491, 0.536, 0.572, 0.682]> <large, arc-shaped, dark>\n<window: [0.587, 0.529, 0.68, 0.688]> <large, arc-shaped, dark>\n<window: [0.712, 0.519, 0.799, 0.675]> <large, arc-shaped, dark>\n<woman: [0.319, 0.708, 0.362, 0.786]> <colored>\n<dress: [0.331, 0.722, 0.363, 0.773]> <grey>\n<clock: [0.445, 0.294, 0.521, 0.343]> <round>\n<tower: [0.392, 0.09, 0.577, 0.479]> <tall>\n<clock: [0.452, 0.303, 0.526, 0.339]> <round, white>\n<jeans: [0.694, 0.751, 0.727, 0.784]> <blue>\n<stone: [0.611, 0.813, 0.879, 0.87]> <broken, gray>\n<sky: [0.148, 0.028, 0.798, 0.516]> <clear, blue>\n", "response": "Task: What is the color and shape of the windows in the building within the <Region>[0.491, 0.536, 0.572, 0.682]</Region>? \nOutput: The windows are large, arc-shaped, and dark. However, there is no information about their color in this region.", "instruction": "What is the color and shape of the windows in the building within the <Region>[0.491, 0.536, 0.572, 0.682]</Region>?", "input": "", "output": "The windows are large, arc-shaped, and dark. However, there is no information about their color in this region.", "is_classification": false, "dataset": "VG", "img_info": "1592444.jpg"}
{"img_id": 1829, "query": "White clouds in the sky: [0.001, 0.0, 0.986, 0.482]\nPeak on the mountain: [0.005, 0.23, 0.996, 0.635]\nthe sky is blue in color: [0.003, 0.003, 0.998, 0.233]\nthe clouds are orange tinged: [0.005, 0.077, 0.986, 0.313]\nThe mountains have clouds.: [0.526, 0.148, 0.748, 0.25]\nThe mountains are covered in snow.: [0.586, 0.29, 0.82, 0.447]\nmountains in the forefront: [0.011, 0.258, 0.995, 0.995]\ncloud on the sky: [0.284, 0.178, 0.458, 0.313]\ncloud in the open blue sky: [0.427, 0.187, 0.471, 0.262]\nbillowing white clouds: [0.0, 0.063, 0.996, 0.358]\n\n<sky: [0.007, 0.002, 0.998, 0.158]> <blue>\n<mountains: [0.0, 0.24, 1.001, 0.977]> <brown, dense>\n<clouds: [0.304, 0.14, 0.829, 0.307]> <large>\n<clouds: [0.32, 0.147, 0.818, 0.325]> <large, white>\n<sky: [0.326, 0.188, 0.931, 0.415]> <cloudy>\n<mountain: [0.203, 0.22, 0.691, 0.575]> <cloudy, brown>\n", "response": "Task: What is the color of the sky in <Region>[0.007, 0.002, 0.998, 0.158]</Region> of the image?\nOutput: The sky in the given region is blue in color.", "instruction": "What is the color of the sky in <Region>[0.007, 0.002, 0.998, 0.158]</Region> of the image?", "input": "", "output": "The sky in the given region is blue in color.", "is_classification": false, "dataset": "VG", "img_info": "1829.jpg"}
{"img_id": 2391656, "query": "girl holding a piece of pizza: [0.168, 0.116, 0.946, 0.888]\nsmaller chunk of cheese pizza : [0.348, 0.834, 0.598, 0.996]\nsmaller chunk of cheese pizza : [0.348, 0.834, 0.598, 0.996]\ndiamond earring: [0.23, 0.31, 0.254, 0.33]\nThe plate is white.: [0.13, 0.824, 0.998, 0.992]\nThe pizza has cheese on it.: [0.316, 0.41, 0.886, 0.84]\nburnt crust of pizza: [0.644, 0.784, 0.878, 0.834]\nlarge white wall : [0.0, 0.008, 0.998, 0.3]\nyoung black child : [0.002, 0.008, 0.96, 0.928]\ntomato pizza sauce: [0.608, 0.678, 0.694, 0.718]\n\n<pizza: [0.344, 0.42, 0.886, 0.84]> <cheesy, large, toppingless, held, slice, burnt>\n<child: [0.0, 0.006, 0.962, 0.978]> <small, young>\n<plate: [0.094, 0.826, 0.996, 0.998]> <round, white>\n<sweater: [0.006, 0.398, 0.95, 1.0]> <red, dark, pink>\n<wall: [0.0, 0.0, 0.998, 0.626]> <yellow, white>\n<chunk: [0.406, 0.87, 0.57, 1.0]> <small>\n<flower: [0.002, 0.478, 0.084, 0.55]> <star, pink>\n<earring: [0.202, 0.292, 0.292, 0.358]> <diamond>\n<cheese: [0.448, 0.476, 0.744, 0.628]> <bubbly>\n", "response": "Task: Is there tomato sauce on the pizza identified by <Region>[0.344, 0.42, 0.886, 0.84]</Region>?\nOutput: Yes, there is tomato sauce on the pizza identified by the given region.", "instruction": "Is there tomato sauce on the pizza identified by <Region>[0.344, 0.42, 0.886, 0.84]</Region>?", "input": "", "output": "Yes, there is tomato sauce on the pizza identified by the given region.", "is_classification": false, "dataset": "VG", "img_info": "2391656.jpg"}
{"img_id": 534, "query": "Silver handle on white toilet: [0.048, 0.439, 0.107, 0.474]\nWindow next to white toilet: [0.745, 0.146, 0.997, 0.922]\nwhite moulding around the floor: [0.008, 0.624, 0.648, 0.994]\nwood framed picture on toilet tank: [0.107, 0.069, 0.478, 0.412]\nsilver toilet flushing handle: [0.055, 0.438, 0.113, 0.476]\ntank of the toilet: [0.037, 0.422, 0.497, 0.611]\na clean white toilet: [0.043, 0.355, 0.59, 0.998]\nmetal toilet flush handle : [0.035, 0.434, 0.122, 0.492]\nWindow above toilet paper holder: [0.75, 0.146, 0.998, 0.925]\nWhite toilet paper below window: [0.71, 0.759, 0.88, 0.912]\n\n<paper: [0.687, 0.731, 0.893, 0.929]> <white, rolled>\n<window: [0.752, 0.131, 0.998, 0.801]> <white>\n<floor: [0.012, 0.665, 0.613, 0.999]> <tiled, moulded, dirty, brown>\n<toilet: [0.04, 0.37, 0.54, 0.999]> <white, lidded, based, covered>\n<piping: [0.052, 0.615, 0.142, 0.73]> <silver>\n", "response": "Task: What is the color and material of the flushing handle in the <Region>[0.055, 0.438, 0.113, 0.476]</Region>?\nOutput: The flushing handle is silver in color and made of metal.", "instruction": "What is the color and material of the flushing handle in the <Region>[0.055, 0.438, 0.113, 0.476]</Region>?", "input": "", "output": "The flushing handle is silver in color and made of metal.", "is_classification": false, "dataset": "VG", "img_info": "534.jpg"}
{"img_id": 150424, "query": "Red baseball bat in hands: [0.539, 0.21, 0.574, 0.399]\nThe batter's team number on the back of his shirt.: [0.573, 0.468, 0.596, 0.516]\nYoung boy holding a baseball bat: [0.517, 0.213, 0.626, 0.741]\nred and white bat: [0.488, 0.171, 0.607, 0.441]\nThe batter's light gray baseball pants.: [0.534, 0.512, 0.606, 0.687]\nbatter wearing helmet: [0.527, 0.351, 0.599, 0.437]\nbatter's helmet is black: [0.52, 0.346, 0.598, 0.435]\nThe batting helmet on the player batting.: [0.531, 0.353, 0.601, 0.428]\nA boy holding a red baseball bat.: [0.51, 0.199, 0.626, 0.747]\nbatter holding baseball bat: [0.544, 0.218, 0.569, 0.369]\n\n<bat: [0.543, 0.21, 0.577, 0.382]> <red>\n", "response": "Task: What is the color of the batting helmet of the player at the bat, as shown in <Region>[0.531, 0.353, 0.601, 0.428]</Region>?\nOutput: The batting helmet of the player at bat is black, as shown in the specified region.", "instruction": "What is the color of the batting helmet of the player at the bat, as shown in <Region>[0.531, 0.353, 0.601, 0.428]</Region>?", "input": "", "output": "The batting helmet of the player at bat is black, as shown in the specified region.", "is_classification": false, "dataset": "VG", "img_info": "150424.jpg"}
{"img_id": 2083, "query": "the black handle on the microwave: [0.203, 0.067, 0.489, 0.297]\nhandle for the oven: [0.175, 0.647, 0.453, 0.727]\nmicrowave handle is black: [0.399, 0.125, 0.43, 0.295]\nthe handle on the oven: [0.176, 0.653, 0.448, 0.715]\nthe handle on the microwave door: [0.406, 0.128, 0.43, 0.293]\nThe black handle of the microwave.: [0.409, 0.125, 0.425, 0.278]\nthe shiny handle is black: [0.405, 0.133, 0.429, 0.282]\n\n<handle: [0.163, 0.645, 0.453, 0.74]> <black>\n", "response": "Task: What object is referred to in <Region>[0.163, 0.645, 0.453, 0.74]</Region>, and what color is the handle connected to it?\nOutput: The object in the region is a handle, and the handle is black.", "instruction": "What object is referred to in <Region>[0.163, 0.645, 0.453, 0.74]</Region>, and what color is the handle connected to it?", "input": "", "output": "The object in the region is a handle, and the handle is black.", "is_classification": false, "dataset": "VG", "img_info": "2083.jpg"}
{"img_id": 1592302, "query": "metal spatula with wood handle: [0.178, 0.654, 0.435, 0.82]\na pizza spatula: [0.188, 0.637, 0.425, 0.816]\na tray of pizza: [0.262, 0.488, 0.575, 0.568]\nwindow on the door: [0.4, 0.074, 0.509, 0.258]\npizza on a tray: [0.253, 0.448, 0.638, 0.615]\ndiamond shaped window in the door: [0.416, 0.082, 0.503, 0.257]\na tray of pizza: [0.262, 0.488, 0.575, 0.568]\na white door : [0.361, 0.052, 0.571, 0.497]\nround tray the pizza is on: [0.262, 0.46, 0.612, 0.602]\nThe people is holding a pizza.: [0.229, 0.432, 0.681, 0.632]\n\n<hair: [0.723, 0.275, 0.811, 0.359]> <blonde>\n<pizza: [0.26, 0.473, 0.612, 0.577]> <round>\n<tray: [0.252, 0.477, 0.63, 0.589]> <round>\n<handle: [0.184, 0.719, 0.323, 0.806]> <black>\n<tray: [0.013, 0.546, 0.502, 0.857]> <black>\n<door: [0.331, 0.013, 0.616, 0.534]> <in background>\n", "response": "Task: What are the two materials used in the object in <Region>[0.178, 0.654, 0.435, 0.82]</Region>?\nOutput: The spatula in that region is made of metal and has a wood handle.", "instruction": "What are the two materials used in the object in <Region>[0.178, 0.654, 0.435, 0.82]</Region>?", "input": "", "output": "The spatula in that region is made of metal and has a wood handle.", "is_classification": false, "dataset": "VG", "img_info": "1592302.jpg"}
{"img_id": 2391994, "query": "shadow of kitten cast on wall: [0.354, 0.064, 0.847, 0.244]\nshadow of kitten cast on wall: [0.354, 0.064, 0.847, 0.244]\nthe cat's two eyes: [0.48, 0.2, 0.598, 0.23]\nthe cats two ears: [0.41, 0.114, 0.665, 0.19]\nthe kittens shadow: [0.491, 0.084, 0.828, 0.2]\nthis kittens leg is on the other kitten: [0.555, 0.53, 0.836, 0.72]\na kitten hiding: [0.41, 0.12, 0.914, 0.274]\na pair of kittens playing.: [0.086, 0.37, 0.997, 0.964]\nthe eyes of a kitten.: [0.477, 0.2, 0.609, 0.24]\nfront leg of kitten: [0.509, 0.524, 0.826, 0.736]\n\n<blanket: [0.003, 0.232, 0.997, 1.0]> <black, white, zebra patterned, zebra striped, zebra print>\n<kitten: [0.418, 0.118, 0.847, 0.272]> <siamese, white, hiding>\n<kitten: [0.105, 0.366, 0.807, 0.958]> <white, playing, blurred>\n<kitten: [0.534, 0.36, 0.997, 0.722]> <white, playing, blurred>\n<ear: [0.359, 0.42, 0.437, 0.502]> <black>\n<ear: [0.643, 0.36, 0.702, 0.45]> <black>\n<ear: [0.421, 0.128, 0.499, 0.204]> <black>\n<ear: [0.584, 0.118, 0.66, 0.198]> <black>\n<pillow case: [0.0, 0.066, 0.375, 0.294]> <zebra patterned, zebra print>\n<eye: [0.566, 0.212, 0.598, 0.228]> <brown>\n<eye: [0.488, 0.212, 0.52, 0.232]> <brown>\n<fur: [0.48, 0.204, 0.611, 0.238]> <dark>\n<wall: [0.005, 0.004, 1.0, 0.31]> <pink, solid, bedroom wall, light pink, painted>\n<stripe: [0.536, 0.21, 0.555, 0.232]> <white>\n<tail: [0.22, 0.88, 0.475, 0.948]> <black>\n<paw: [0.665, 0.634, 0.772, 0.688]> <white>\n<leg: [0.456, 0.826, 0.815, 0.954]> <white, black>\n", "response": "Task: What is the object indicated by <Region>[0.003, 0.232, 0.375, 0.294]</Region> and what is its pattern?\nOutput: The object is a pillow case and it is zebra patterned or printed. It has a distinctive black and white striped pattern.", "instruction": "What is the object indicated by <Region>[0.003, 0.232, 0.375, 0.294]</Region> and what is its pattern?", "input": "", "output": "The object is a pillow case and it is zebra patterned or printed. It has a distinctive black and white striped pattern.", "is_classification": false, "dataset": "VG", "img_info": "2391994.jpg"}
{"img_id": 975, "query": "Orange flower in green foliage: [0.845, 0.531, 0.863, 0.547]\nOrange flower in green foliage: [0.942, 0.625, 0.962, 0.641]\nOrange flower in green foliage: [0.88, 0.611, 0.898, 0.632]\na brown building with a red roof: [0.012, 0.196, 0.683, 0.54]\nOrange flower in green foliage: [0.88, 0.611, 0.898, 0.632]\nOrange flower in green foliage: [0.942, 0.625, 0.962, 0.641]\nround and white electric lamp on top of a lamp post: [0.667, 0.331, 0.707, 0.497]\nOrange flower in green foliage: [0.845, 0.531, 0.863, 0.547]\na white light on a pole: [0.647, 0.318, 0.732, 0.509]\nshadow of the building on the street: [0.003, 0.535, 0.515, 0.61]\n\n<flower: [0.858, 0.605, 0.9, 0.637]> <orange>\n<flower: [0.733, 0.578, 0.807, 0.619]> <orange>\n<flower: [0.918, 0.611, 0.978, 0.656]> <orange>\n<flower: [0.823, 0.529, 0.89, 0.574]> <orange>\n<flower: [0.613, 0.561, 0.643, 0.58]> <orange>\n<building: [0.002, 0.214, 0.69, 0.552]> <brown>\n<lamp: [0.663, 0.334, 0.703, 0.364]> <round, white, electric>\n<roof: [0.012, 0.21, 0.647, 0.378]> <pink, red>\n<leaves: [0.58, 0.191, 0.962, 0.495]> <green>\n<light: [0.663, 0.333, 0.7, 0.362]> <white>\n<pole: [0.675, 0.356, 0.697, 0.502]> <black>\n<columns: [0.092, 0.466, 0.14, 0.536]> <cement>\n<post: [0.668, 0.36, 0.697, 0.505]> <black>\n<globe: [0.658, 0.328, 0.718, 0.375]> <white, glass>\n<roof: [0.005, 0.2, 0.647, 0.385]> <red>\n<entrance way: [0.01, 0.38, 0.663, 0.539]> <arched>\n<flower: [0.842, 0.532, 0.872, 0.55]> <orange>\n<flower: [0.917, 0.539, 0.945, 0.561]> <orange>\n<flower: [0.917, 0.615, 0.943, 0.635]> <orange>\n<flower: [0.92, 0.54, 0.943, 0.555]> <orange>\n<flower: [0.807, 0.495, 0.847, 0.516]> <orange>\n<trees: [0.527, 0.128, 0.993, 0.497]> <group>\n<spot: [0.163, 0.605, 0.21, 0.631]> <dark>\n", "response": "Task: What is the color of the light in <Region>[0.663, 0.333, 0.7, 0.362]</Region>?\nOutput: The color of the light in that region is white.", "instruction": "What is the color of the light in <Region>[0.663, 0.333, 0.7, 0.362]</Region>?", "input": "", "output": "The color of the light in that region is white.", "is_classification": false, "dataset": "VG", "img_info": "975.jpg"}
{"img_id": 2391969, "query": "Computer modem in background : [0.654, 0.125, 0.996, 0.587]\nAC jack for speaker power: [0.774, 0.283, 0.878, 0.368]\na see through glass table: [0.06, 0.387, 0.17, 0.48]\nWhite charger cord for computer : [0.012, 0.285, 0.404, 0.381]\na piece of white paper: [0.08, 0.107, 0.27, 0.32]\nsome sparkling blue strips on the laptop: [0.116, 0.445, 0.376, 0.717]\nWhite charger cord for computer : [0.012, 0.285, 0.404, 0.381]\nlight blue on dark blue plastic device: [0.346, 0.104, 0.528, 0.304]\nconnection cord between laptop and speaker: [0.658, 0.064, 0.986, 0.989]\nA roll of packing tape: [0.286, 0.0, 0.488, 0.133]\n\n<tape: [0.318, 0.008, 0.474, 0.131]> <clear, packaging tape, yellow, packing tape, for packing>\n<laptop: [0.034, 0.288, 0.932, 1.0]> <apple, silver, grey>\n<telephone: [0.272, 0.061, 0.352, 0.349]> <silver, cordless, grey>\n<paper: [0.088, 0.123, 0.276, 0.339]> <white>\n<cord: [0.574, 0.245, 0.898, 0.733]> <black>\n<stickers: [0.056, 0.435, 0.366, 0.749]> <blue>\n<back: [0.59, 0.088, 0.72, 0.251]> <white>\n<plastic: [0.374, 0.197, 0.486, 0.283]> <blue>\n<speaker: [0.802, 0.179, 0.978, 0.656]> <grey>\n<table: [0.014, 0.037, 0.972, 0.979]> <glass>\n<apple: [0.388, 0.683, 0.536, 0.824]> <white, apple>\n<device: [0.35, 0.109, 0.526, 0.293]> <blue, disk drive>\n<cable: [0.644, 0.181, 0.846, 0.571]> <grey>\n<cord: [0.046, 0.285, 0.376, 0.379]> <white>\n", "response": "Task: What are the colors of the sparkly strips on the laptop in <Region>[0.116, 0.445, 0.376, 0.717]</Region>?\nOutput: The sparkly strips on the laptop in that region are blue.", "instruction": "What are the colors of the sparkly strips on the laptop in <Region>[0.116, 0.445, 0.376, 0.717]</Region>?", "input": "", "output": "The sparkly strips on the laptop in that region are blue.", "is_classification": false, "dataset": "VG", "img_info": "2391969.jpg"}
{"img_id": 150323, "query": "White small foot stool.: [0.73, 0.735, 0.982, 0.961]\nPair of blue and white boots.: [0.598, 0.25, 0.815, 0.403]\nGray and black helmet with 8 R in white.: [0.695, 0.57, 0.917, 0.731]\nBlack and tan glove.: [0.605, 0.396, 0.695, 0.477]\nGray pair of boots.: [0.027, 0.746, 0.333, 0.998]\nthe glasses on the helmet: [0.827, 0.593, 0.917, 0.661]\nGray pair of boots.: [0.027, 0.746, 0.333, 0.998]\nthe black and gray helmet on the floor: [0.688, 0.581, 0.915, 0.715]\nBeige wool hat.: [0.793, 0.37, 0.988, 0.461]\nBlue coat hanging up.: [0.008, 0.001, 0.148, 0.601]\n\n<foot stool: [0.722, 0.734, 0.988, 0.968]> <white, small>\n<boots: [0.605, 0.263, 0.82, 0.411]> <blue and white>\n<glove: [0.597, 0.395, 0.683, 0.477]> <black and tan>\n<8r: [0.733, 0.64, 0.798, 0.671]> <white>\n<helmet: [0.695, 0.576, 0.912, 0.735]> <gray and black>\n<coat: [0.0, 0.0, 0.127, 0.626]> <blue>\n<boots: [0.033, 0.75, 0.33, 0.996]> <gray>\n<hat: [0.805, 0.381, 0.997, 0.454]> <beige, wool>\n", "response": "Task: What is the color of the foot stool referred to in <Region>[0.722, 0.734, 0.988, 0.968]</Region>?\nOutput: The color of the foot stool is white.", "instruction": "What is the color of the foot stool referred to in <Region>[0.722, 0.734, 0.988, 0.968]</Region>?", "input": "", "output": "The color of the foot stool is white.", "is_classification": false, "dataset": "VG", "img_info": "150323.jpg"}
{"img_id": 3469, "query": "a man standing behind a van: [0.054, 0.457, 0.091, 0.6]\nthe awning on a building: [0.695, 0.367, 0.996, 0.423]\nA white van: [0.065, 0.373, 0.323, 0.677]\nmetal columns supporting a highway: [0.041, 0.288, 0.274, 0.492]\ndark car on shadowed road: [0.296, 0.455, 0.999, 0.975]\nwhite van parked on the curb: [0.052, 0.372, 0.325, 0.685]\nthe car is yellow: [0.94, 0.463, 0.998, 0.495]\nthe building is white: [0.451, 0.375, 0.734, 0.465]\na white car turning onto the street: [-0.001, 0.475, 0.034, 0.517]\na black car on a street: [0.334, 0.475, 0.454, 0.575]\n\n<van: [0.083, 0.352, 0.324, 0.663]> <white, stopped>\n<windshield: [0.11, 0.417, 0.29, 0.507]> <front windshield>\n<suv: [0.576, 0.452, 0.7, 0.52]> <parked, white>\n<building: [0.505, 0.288, 0.998, 0.528]> <long, beige, industrial>\n<columns: [0.171, 0.167, 0.884, 0.54]> <metal>\n<car: [0.001, 0.46, 0.043, 0.53]> <white>\n", "response": "Task: Is the man in the <Region>[0.054, 0.457, 0.091, 0.6]</Region> standing in front of the white van?\nOutput: There is a man standing behind the white van, not in front of it.", "instruction": "Is the man in the <Region>[0.054, 0.457, 0.091, 0.6]</Region> standing in front of the white van?", "input": "", "output": "There is a man standing behind the white van, not in front of it.", "is_classification": false, "dataset": "VG", "img_info": "3469.jpg"}
{"img_id": 3946, "query": "small stone archway : [0.197, 0.431, 0.302, 0.477]\narchway is part of aqueduct: [0.144, 0.431, 0.181, 0.471]\nAn archway in a wall: [0.792, 0.477, 0.836, 0.581]\nA small archway in a wall: [0.372, 0.423, 0.402, 0.473]\nThe small archways : [0.084, 0.419, 0.2, 0.485]\narchway is part of aqueduct: [0.08, 0.431, 0.119, 0.473]\nAn archway in a wall: [0.839, 0.465, 0.866, 0.554]\nThe small archways : [0.084, 0.419, 0.2, 0.485]\narchway is part of aqueduct: [0.255, 0.431, 0.305, 0.469]\nThe small archways : [0.084, 0.419, 0.2, 0.485]\n\n<archway: [0.312, 0.429, 0.347, 0.471]> <SMALL>\n<archway: [0.259, 0.425, 0.294, 0.469]> <SMALL>\n<archway: [0.2, 0.431, 0.244, 0.469]> <SMALL>\n<archway: [0.144, 0.425, 0.178, 0.469]> <SMALL>\n<archway: [0.081, 0.431, 0.117, 0.473]> <SMALL>\n<archway: [0.203, 0.427, 0.239, 0.475]> <small, stone>\n<archway: [0.598, 0.481, 0.681, 0.625]> <large>\n<archway: [0.691, 0.479, 0.747, 0.594]> <large, stone>\n", "response": "Task: How would you describe the archway in <Region>[0.203, 0.427, 0.239, 0.475]</Region>? \nOutput: The archway in that region is made of small stones.", "instruction": "How would you describe the archway in <Region>[0.203, 0.427, 0.239, 0.475]</Region>?", "input": "", "output": "The archway in that region is made of small stones.", "is_classification": false, "dataset": "VG", "img_info": "3946.jpg"}
{"img_id": 1592241, "query": "a road construction worker walking on the road: [0.456, 0.542, 0.519, 0.797]\nevergreen tree in the distance: [0.005, 0.266, 0.062, 0.57]\nA woman holding a stop sign: [0.229, 0.448, 0.353, 0.883]\nworker is wearing a hard hat: [0.257, 0.57, 0.3, 0.608]\na black pickup truck on a road: [0.583, 0.509, 0.847, 0.898]\nyellow light on top of vehicle: [0.622, 0.539, 0.653, 0.572]\na stop sign in a workers hands: [0.292, 0.491, 0.353, 0.582]\na pine tree near the road: [0.002, 0.262, 0.052, 0.534]\na stop sign in a workers hands: [0.292, 0.491, 0.353, 0.582]\nfluorescent orange construction vest : [0.464, 0.581, 0.515, 0.682]\n\n<sign: [0.283, 0.467, 0.352, 0.59]> <stop, red, white>\n<pole: [0.02, 0.645, 0.11, 0.854]> <hazard, orange>\n<stripes: [0.038, 0.681, 0.068, 0.753]> <white>\n<vest: [0.454, 0.572, 0.522, 0.68]> <safety>\n<hat: [0.258, 0.561, 0.301, 0.604]> <hard>\n<worker: [0.249, 0.557, 0.347, 0.831]> <safety>\n<pants: [0.25, 0.681, 0.308, 0.831]> <orange>\n<pants: [0.247, 0.69, 0.307, 0.826]> <safety>\n<stripe: [0.263, 0.76, 0.297, 0.786]> <white>\n<stripe: [0.258, 0.78, 0.294, 0.806]> <white>\n<light: [0.737, 0.493, 0.768, 0.544]> <orange>\n<light: [0.619, 0.535, 0.66, 0.578]> <yellow>\n<sky: [0.005, 0.007, 0.657, 0.142]> <cloudy, blue>\n<mountain: [0.001, 0.004, 0.999, 0.457]> <big, brown>\n<sign: [0.283, 0.465, 0.357, 0.595]> <stop>\n<worker: [0.247, 0.543, 0.332, 0.836]> <woman, road, construction>\n<tree: [0.0, 0.249, 0.054, 0.531]> <pine>\n<suv: [0.722, 0.445, 0.999, 0.995]> <black>\n<truck: [0.6, 0.508, 0.85, 0.914]> <black, pickup>\n<worker: [0.445, 0.538, 0.526, 0.811]> <road, construction, walking>\n", "response": "Task: What color is the stop sign held by the person in the <Region>[0.283, 0.465, 0.357, 0.595]</Region>?\nOutput: The stop sign held by the person in the region is red with white letters.", "instruction": "What color is the stop sign held by the person in the <Region>[0.283, 0.465, 0.357, 0.595]</Region>?", "input": "", "output": "The stop sign held by the person in the region is red with white letters.", "is_classification": false, "dataset": "VG", "img_info": "1592241.jpg"}
{"img_id": 3180, "query": "window on tall red building: [0.487, 0.18, 0.52, 0.212]\nA window on a building.: [0.525, 0.135, 0.539, 0.162]\nwindow on tall red building: [0.487, 0.127, 0.52, 0.155]\nwindow on tall red building: [0.485, 0.23, 0.517, 0.265]\nwindow on tall red building: [0.487, 0.127, 0.52, 0.155]\nwindow on tall red building: [0.465, 0.127, 0.476, 0.158]\nA window on a building.: [0.522, 0.188, 0.535, 0.22]\nA woman carrying a plastic bag : [0.527, 0.537, 0.6, 0.72]\nwoman holding white bag: [0.549, 0.533, 0.596, 0.738]\nA window on a building.: [0.489, 0.128, 0.519, 0.158]\n\n<fence cover: [0.004, 0.418, 0.438, 0.992]> <with black canvas>\n<building cover: [0.215, 0.008, 0.432, 0.475]> <with green fence>\n<blazer: [0.511, 0.573, 0.598, 0.703]> <yellow>\n<pant: [0.535, 0.583, 0.632, 0.713]> <yellow>\n<bag: [0.53, 0.588, 0.56, 0.642]> <plastic>\n<woman: [0.506, 0.525, 0.676, 0.787]> <carrying>\n<bins: [0.306, 0.603, 0.611, 0.967]> <black>\n<gate: [0.014, 0.413, 0.48, 0.895]> <covered, black>\n<scaffolding: [0.254, 0.29, 0.44, 0.485]> <silver>\n<building: [0.421, 0.035, 0.583, 0.363]> <painted, maroon>\n<staircase: [0.426, 0.35, 0.659, 0.64]> <concrete>\n<building: [0.414, 0.043, 0.61, 0.43]> <red, tall>\n", "response": "Task: How many windows are there in the <Region>[0.414, 0.043, 0.61, 0.43]</Region> building?\nOutput: There are multiple windows in the building, but it is impossible to count how many there are just by looking at the Region.", "instruction": "How many windows are there in the <Region>[0.414, 0.043, 0.61, 0.43]</Region> building?", "input": "", "output": "There are multiple windows in the building, but it is impossible to count how many there are just by looking at the Region.", "is_classification": false, "dataset": "VG", "img_info": "3180.jpg"}
