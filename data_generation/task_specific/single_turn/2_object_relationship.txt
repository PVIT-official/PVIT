{"img_id": 3125, "query": "covered tire on back of suv: [0.681, 0.473, 0.736, 0.575]\nred suv parked on the side of the street: [0.675, 0.44, 0.991, 0.645]\nmanhole in middle of road: [0.9, 0.642, 0.998, 0.702]\nthe window is big: [0.606, 0.248, 0.666, 0.495]\nparked suv is small: [0.66, 0.418, 0.986, 0.64]\ncovered tire on back of suv: [0.681, 0.473, 0.736, 0.575]\nminivan in front of suv: [0.912, 0.42, 0.998, 0.608]\nred suv parked on the side of the street: [0.675, 0.44, 0.991, 0.645]\nback right rear wheel of the red suv: [0.786, 0.562, 0.831, 0.652]\nback right rear wheel of the red suv: [0.786, 0.562, 0.831, 0.652]\n\n<tire: [0.659, 0.417, 0.759, 0.597]> <on back of> <suv: [0.659, 0.417, 0.995, 0.652]>\n<manhole: [0.897, 0.642, 0.999, 0.685]> <in middle of> <road: [0.005, 0.573, 0.966, 0.912]>\n<minivan: [0.939, 0.437, 0.999, 0.605]> <in front of> <suv: [0.669, 0.428, 0.969, 0.618]>\n<window: [0.517, 0.283, 0.57, 0.493]> <on a> <building: [0.225, 0.003, 0.968, 0.608]>\n", "response": "Task: What is parked in front of the <Region>[0.659, 0.417, 0.995, 0.652]</Region>?\nOutput: A minivan is parked in front of the SUV.", "instruction": "What is parked in front of the <Region>[0.659, 0.417, 0.995, 0.652]</Region>?", "input": "", "output": "A minivan is parked in front of the SUV.", "is_classification": false, "dataset": "VG", "img_info": "3125.jpg"}
{"img_id": 285807, "query": "the cot standing behind the woman : [0.17, 0.147, 0.683, 0.52]\nthe brown bag next to the woman: [0.506, 0.493, 0.868, 0.99]\nLarge cardboard box on the floor: [0.034, 0.646, 0.233, 0.997]\nthe cot standing behind the woman : [0.17, 0.147, 0.683, 0.52]\na woman in a jacket sitting on the floor: [0.313, 0.217, 0.567, 0.724]\nRed sleeping bag rolled out on a cot: [0.164, 0.13, 0.655, 0.268]\nBlue bin sitting on a box: [0.003, 0.441, 0.214, 0.831]\nClear bin on top of a blue bin: [0.0, 0.296, 0.18, 0.607]\nwhite cardboard box with red words: [0.759, 0.0, 0.934, 0.087]\nthe glasses on the woman's face: [0.348, 0.284, 0.422, 0.329]\n\n<boot: [0.21, 0.704, 0.341, 0.846]> <by> <box: [0.048, 0.654, 0.236, 0.995]>\n<woman: [0.31, 0.217, 0.567, 0.673]> <WEARING> <jacket: [0.332, 0.314, 0.559, 0.639]>\n<bin: [0.0, 0.293, 0.178, 0.589]> <on top of> <bin: [0.0, 0.44, 0.205, 0.842]>\n<strap: [0.511, 0.863, 0.592, 0.993]> <OF> <bag: [0.563, 0.546, 0.91, 0.965]>\n<woman: [0.31, 0.217, 0.565, 0.672]> <sitting on> <floor: [0.325, 0.784, 0.509, 0.953]>\n<comforter: [0.157, 0.129, 0.66, 0.275]> <laying on> <cot: [0.173, 0.212, 0.68, 0.422]>\n<cot: [0.192, 0.163, 0.748, 0.509]> <behind> <woman: [0.274, 0.182, 0.621, 0.771]>\n", "response": "Task: What is the woman wearing in <Region>[0.31, 0.217, 0.567, 0.673]</Region>?\nOutput: She is wearing a jacket.", "instruction": "What is the woman wearing in <Region>[0.31, 0.217, 0.567, 0.673]</Region>?", "input": "", "output": "She is wearing a jacket.", "is_classification": false, "dataset": "VG", "img_info": "285807.jpg"}
{"img_id": 713245, "query": "the word bus on the bus: [0.618, 0.638, 0.682, 0.694]\na sign hanging over the bus: [0.006, 0.04, 0.797, 0.231]\nmore chinese writing on the top of the bus stop: [0.139, 0.072, 0.417, 0.148]\nmore chinese writing on the top of the bus stop: [0.139, 0.072, 0.417, 0.148]\na man getting on a bus: [0.09, 0.521, 0.193, 0.906]\nDigital sign on bus: [0.371, 0.403, 0.505, 0.502]\ndisplay is in the window of the bus: [0.374, 0.41, 0.509, 0.505]\nopened door on the bus: [0.038, 0.382, 0.25, 0.846]\nDigital sign on bus: [0.371, 0.403, 0.505, 0.502]\na door on the bus: [0.654, 0.36, 0.866, 0.846]\n\n<bus: [0.019, 0.243, 0.992, 0.868]> <on side of> <street: [0.002, 0.672, 0.03, 0.867]>\n<building: [0.767, 0.003, 0.997, 0.293]> <behind> <bus: [0.019, 0.243, 0.992, 0.868]>\n", "response": "Task: What is behind the object in <Region>[0.019, 0.243, 0.992, 0.868]</Region>?\nOutput: Behind the object, there is a building.", "instruction": "What is behind the object in <Region>[0.019, 0.243, 0.992, 0.868]</Region>?", "input": "", "output": "Behind the object, there is a building.", "is_classification": false, "dataset": "VG", "img_info": "713245.jpg"}
{"img_id": 1003, "query": "letter on a sign: [0.447, 0.423, 0.465, 0.458]\nchair the man is sitting in: [0.404, 0.532, 0.597, 0.993]\nletter on a sign: [0.431, 0.421, 0.45, 0.453]\nletter on a sign: [0.432, 0.453, 0.452, 0.485]\nletter on a sign: [0.399, 0.453, 0.417, 0.48]\nscreen of game machine is yellow, blue and white: [0.738, 0.196, 0.96, 0.582]\nletter on a sign: [0.417, 0.421, 0.442, 0.448]\nletter on a sign: [0.388, 0.441, 0.406, 0.488]\nletter on a sign: [0.404, 0.423, 0.422, 0.455]\nman in front a game machine: [0.422, 0.203, 0.744, 0.933]\n\n<letter: [0.386, 0.416, 0.408, 0.453]> <on a> <sign: [0.355, 0.354, 0.487, 0.495]>\n<man: [0.462, 0.252, 0.721, 0.923]> <in front of> <game: [0.606, 0.228, 0.71, 0.597]>\n", "response": "Task: What is the relationship between the object in <Region>[0.462, 0.252, 0.721, 0.923]</Region> and the object in <Region>[0.606, 0.228, 0.71, 0.597]</Region>?\nOutput: The man is in front of a game machine.", "instruction": "What is the relationship between the object in <Region>[0.462, 0.252, 0.721, 0.923]</Region> and the object in <Region>[0.606, 0.228, 0.71, 0.597]</Region>?", "input": "", "output": "The man is in front of a game machine.", "is_classification": false, "dataset": "VG", "img_info": "1003.jpg"}
{"img_id": 3020, "query": "bike parked next to the restaurant : [0.669, 0.253, 0.904, 0.432]\nfront tire on a motorbike: [0.807, 0.345, 0.849, 0.408]\nconcrete stand holding umbrella: [0.512, 0.877, 0.733, 0.998]\nan umbrella is white: [0.113, 0.023, 0.619, 0.187]\numbrella over table is white: [0.185, 0.005, 0.998, 0.16]\nthe tree branch has green leaves: [0.087, 0.005, 0.201, 0.058]\nan umbrella color white: [0.185, 0.0, 0.995, 0.205]\nseveral trees in the outdoor cafe area : [0.1, 0.013, 0.981, 0.48]\ngarbage can is yellow: [0.374, 0.273, 0.455, 0.453]\nPiece of paper on the concrete floor of the cafe : [0.286, 0.787, 0.386, 0.888]\n\n<chairs: [0.223, 0.213, 0.993, 0.982]> <outside of> <cafe: [0.228, 0.152, 0.99, 0.99]>\n<bike: [0.704, 0.253, 0.845, 0.387]> <parked next to> <restaurant: [0.588, 0.057, 0.996, 0.34]>\n<trees: [0.044, 0.002, 0.789, 0.318]> <in area of> <outdoor cafe: [0.033, 0.0, 0.981, 0.973]>\n<concrete floor: [0.079, 0.348, 0.424, 0.995]> <OF> <cafe: [0.142, 0.002, 0.996, 0.988]>\n<stand: [0.531, 0.9, 0.733, 0.997]> <holding> <umbrella: [0.191, 0.003, 0.996, 0.182]>\n<umbrella: [0.14, 0.002, 1.0, 0.185]> <over> <table: [0.525, 0.907, 0.731, 0.995]>\n<garbage: [0.391, 0.29, 0.441, 0.413]> <against> <tree: [0.455, 0.132, 0.511, 0.357]>\n<bike: [0.703, 0.293, 0.848, 0.395]> <by> <sidewalk: [0.514, 0.245, 0.999, 0.477]>\n", "response": "Task: What color is the umbrella in <Region>[0.191, 0.003, 0.996, 0.182]</Region>?\nOutput: The color of the umbrella is white.", "instruction": "What color is the umbrella in <Region>[0.191, 0.003, 0.996, 0.182]</Region>?", "input": "", "output": "The color of the umbrella is white.", "is_classification": false, "dataset": "VG", "img_info": "3020.jpg"}
{"img_id": 1501, "query": "man standing on street with a bag beside him: [0.685, 0.403, 0.74, 0.57]\nman standing on the sidewalk: [0.703, 0.397, 0.739, 0.548]\nwindow on the building: [0.284, 0.173, 0.371, 0.312]\nwoman standing on the sideawlk: [0.36, 0.425, 0.42, 0.578]\nblack and white sign on side of building: [0.245, 0.293, 0.302, 0.355]\nwindow on the building: [0.75, 0.303, 0.791, 0.483]\nwindow on the building: [0.324, 0.043, 0.367, 0.185]\nwindow on the building: [0.781, 0.038, 0.856, 0.198]\nwindow on side of building : [0.603, 0.33, 0.735, 0.482]\nwoman walking on sidewalk: [0.356, 0.405, 0.432, 0.593]\n\n<man: [0.689, 0.388, 0.748, 0.555]> <below> <building: [0.446, 0.03, 0.993, 0.318]>\n", "response": "Task: What object is located below the <Region>[0.446, 0.03, 0.993, 0.318]</Region> on the plane?\nOutput: This region represents the building, and the object located below it is a man with a bag beside him, standing on the street.", "instruction": "What object is located below the <Region>[0.446, 0.03, 0.993, 0.318]</Region> on the plane?", "input": "", "output": "This region represents the building, and the object located below it is a man with a bag beside him, standing on the street.", "is_classification": false, "dataset": "VG", "img_info": "1501.jpg"}
{"img_id": 713350, "query": "Bottles and cans strewn on gray desktop.: [0.561, 0.454, 0.947, 0.933]\nA grey metal desk chair.: [0.0, 0.417, 0.145, 0.73]\nA desk holding laptop and television.: [0.006, 0.218, 0.979, 0.982]\na button on the table: [0.322, 0.681, 0.326, 0.696]\na button on the table: [0.146, 0.647, 0.172, 0.709]\na button on the table: [0.201, 0.656, 0.221, 0.681]\n\n<box: [0.715, 0.684, 0.832, 0.957]> <for> <box: [0.719, 0.764, 0.828, 0.883]>\n<button: [0.311, 0.672, 0.326, 0.699]> <ON THE> <desk: [0.0, 0.684, 0.959, 1.0]>\n", "response": "Task: What object is on the desk in <Region>[0.0, 0.218, 0.979, 0.982]</Region>?\nOutput: There is a television and a laptop on the desk.", "instruction": "What object is on the desk in <Region>[0.0, 0.218, 0.979, 0.982]</Region>?", "input": "", "output": "There is a television and a laptop on the desk.", "is_classification": false, "dataset": "VG", "img_info": "713350.jpg"}
{"img_id": 1499, "query": "a man walking on a brick sidewalk: [0.314, 0.355, 0.496, 0.985]\na man walking on a brick sidewalk: [0.314, 0.355, 0.496, 0.985]\na man wearing a black baseball cap: [0.519, 0.378, 0.62, 0.635]\na man wearing a black jacket: [0.297, 0.412, 0.507, 0.707]\na tree planted in the middle of the sidewalk: [0.547, 0.065, 0.844, 0.893]\na man wearing gray sweatpants: [0.291, 0.328, 0.491, 0.985]\na man wearing gray sweatpants: [0.291, 0.328, 0.491, 0.985]\nTree on the sidewalk : [0.489, 0.003, 0.85, 0.902]\na man wearing gray sweatpants: [0.291, 0.328, 0.491, 0.985]\na sign that tells you the road is only one direction: [0.899, 0.292, 0.969, 0.38]\n\n<man: [0.302, 0.342, 0.516, 0.952]> <WEARING> <hat: [0.374, 0.355, 0.44, 0.402]>\n<sign: [0.549, 0.318, 0.989, 0.498]> <across from> <sidewalk: [0.019, 0.545, 0.921, 0.998]>\n<man: [0.302, 0.342, 0.516, 0.952]> <wearing a> <hat: [0.374, 0.355, 0.44, 0.402]>\n<man: [0.302, 0.342, 0.516, 0.952]> <wearing a black> <jacket: [0.304, 0.408, 0.495, 0.66]>\n<man: [0.302, 0.342, 0.516, 0.952]> <walking on> <sidewalk: [0.019, 0.545, 0.921, 0.998]>\n", "response": "Task: What clothes does the man <Region>[0.302, 0.342, 0.516, 0.952]</Region> wear? Is he wearing any accessories?\nOutput: The man in the given Region is wearing gray sweatpants and a black jacket. He is also wearing a black baseball cap.", "instruction": "What clothes does the man <Region>[0.302, 0.342, 0.516, 0.952]</Region> wear? Is he wearing any accessories?", "input": "", "output": "The man in the given Region is wearing gray sweatpants and a black jacket. He is also wearing a black baseball cap.", "is_classification": false, "dataset": "VG", "img_info": "1499.jpg"}
{"img_id": 150351, "query": "The wheels are down on the plane.: [0.357, 0.477, 0.793, 0.661]\nthe top of the airport building: [0.559, 0.386, 0.997, 0.46]\nlarge airplane on runway: [0.067, 0.227, 0.825, 0.656]\na body of water: [0.021, 0.762, 0.993, 0.974]\nA DHL airplane. : [0.061, 0.218, 0.823, 0.633]\nan airport control tower: [0.817, 0.26, 0.87, 0.423]\nA plane at an airport: [0.063, 0.201, 0.817, 0.63]\nvegetation in the water outside the airport: [0.005, 0.649, 0.92, 0.801]\nthe terminal at the airport: [0.594, 0.258, 0.992, 0.473]\nsmall island in the midst of the water: [0.042, 0.645, 0.469, 0.809]\n\n<top: [0.58, 0.392, 0.998, 0.437]> <fo> <building: [0.583, 0.386, 1.0, 0.596]>\n<wing: [0.322, 0.479, 0.515, 0.569]> <OF> <plane: [0.068, 0.227, 0.811, 0.638]>\n<plane: [0.068, 0.227, 0.811, 0.638]> <by> <water: [0.003, 0.683, 1.0, 0.994]>\n<fence: [0.008, 0.552, 1.0, 0.65]> <surrounding> <airport: [0.002, 0.267, 1.0, 0.691]>\n<water: [0.003, 0.683, 1.0, 0.994]> <outside> <airport: [0.002, 0.267, 1.0, 0.691]>\n", "response": "Task: Are the wheels up or down on the plane located at <Region>[0.068, 0.227, 0.825, 0.656]</Region>?\nOutput: The wheels are down on the plane.", "instruction": "Are the wheels up or down on the plane located at <Region>[0.068, 0.227, 0.825, 0.656]</Region>?", "input": "", "output": "The wheels are down on the plane.", "is_classification": false, "dataset": "VG", "img_info": "150351.jpg"}
{"img_id": 285826, "query": "person sitting on black bench: [0.15, 0.66, 0.32, 0.975]\nperson sitting on black bench: [0.154, 0.648, 0.332, 0.987]\nThe white tree is in the painting: [0.204, 0.093, 0.465, 0.622]\njacket worn by human : [0.196, 0.73, 0.277, 0.856]\nperson sitting on black bench: [0.154, 0.66, 0.306, 0.975]\na large painting in a museum: [0.168, 0.037, 0.861, 0.746]\nwoman sitting on the bench : [0.193, 0.7, 0.293, 0.973]\nbench is underneath woman : [0.164, 0.831, 0.471, 0.952]\nwoman sits in front of painting : [0.181, 0.693, 0.274, 0.964]\nlight blue coat the woman is wearing: [0.188, 0.729, 0.281, 0.842]\n\n<painting: [0.159, 0.023, 0.866, 0.766]> <behind> <human: [0.195, 0.7, 0.275, 0.959]>\n<human: [0.195, 0.7, 0.275, 0.959]> <wears> <coat: [0.189, 0.723, 0.28, 0.847]>\n<human: [0.195, 0.7, 0.275, 0.959]> <sitting on> <bench: [0.105, 0.777, 0.501, 0.921]>\n<leg: [0.152, 0.861, 0.201, 0.961]> <on a> <bench: [0.072, 0.776, 0.501, 0.955]>\n<painting: [0.159, 0.023, 0.866, 0.766]> <of a> <fountain: [0.433, 0.188, 0.638, 0.662]>\n<human: [0.195, 0.7, 0.275, 0.959]> <has a> <book: [0.203, 0.785, 0.265, 0.835]>\n<bench: [0.149, 0.817, 0.467, 0.93]> <underneath> <woman: [0.186, 0.71, 0.277, 0.967]>\n<coat: [0.195, 0.726, 0.273, 0.85]> <worn by> <human: [0.196, 0.701, 0.343, 0.973]>\n", "response": "Task: What object is underneath the object in <Region>[0.186, 0.71, 0.277, 0.967]</Region>?\nOutput: The bench is underneath the woman.", "instruction": "What object is underneath the object in <Region>[0.186, 0.71, 0.277, 0.967]</Region>?", "input": "", "output": "The bench is underneath the woman.", "is_classification": false, "dataset": "VG", "img_info": "285826.jpg"}
{"img_id": 713523, "query": "advertisment printed on the side of a train engine: [0.3, 0.495, 0.533, 0.729]\nA window on a train.: [0.614, 0.428, 0.723, 0.553]\nwindow on side of blue train: [0.376, 0.493, 0.4, 0.556]\nwindow facing blue train: [0.987, 0.354, 0.998, 0.4]\nthe metal train tracks: [0.627, 0.893, 0.934, 0.997]\nA window on a building.: [0.959, 0.529, 0.975, 0.568]\nheadlights on the front of a train: [0.63, 0.574, 0.838, 0.704]\nglass window on the building: [0.908, 0.433, 0.913, 0.461]\nblack bumper on train: [0.649, 0.75, 0.706, 0.835]\nglass window on train: [0.513, 0.438, 0.545, 0.564]\n\n<window: [0.618, 0.433, 0.734, 0.552]> <built into> <train: [0.013, 0.283, 0.883, 0.939]>\n<window: [0.912, 0.51, 0.961, 0.599]> <attached to> <building: [0.861, 0.064, 0.997, 0.679]>\n<window: [0.416, 0.476, 0.438, 0.556]> <on a> <train: [0.036, 0.476, 0.868, 0.933]>\n<light: [0.183, 0.452, 0.209, 0.53]> <posted near> <tracks: [0.834, 0.649, 0.997, 0.959]>\n", "response": "Task: Is there a black bumper on the train in <Region>[0.3, 0.495, 0.533, 0.729]</Region>?\nOutput: Yes, there is a black bumper on the train in the specified region.", "instruction": "Is there a black bumper on the train in <Region>[0.3, 0.495, 0.533, 0.729]</Region>?", "input": "", "output": "Yes, there is a black bumper on the train in the specified region.", "is_classification": false, "dataset": "VG", "img_info": "713523.jpg"}
{"img_id": 150269, "query": "The zebra is under the tree: [0.293, 0.284, 0.434, 0.493]\nfenced area behind the trees: [0.375, 0.141, 0.867, 0.211]\nA zebra eating grass: [0.725, 0.387, 0.896, 0.592]\ntwo large trees shading each other: [0.019, 0.053, 0.252, 0.483]\nThe zebra is stripes: [0.713, 0.378, 0.928, 0.625]\nzebra whose head is down and grazing: [0.721, 0.391, 0.88, 0.574]\nbig willow tree: [0.38, 0.003, 0.992, 0.353]\nA small tree without foliage.: [0.249, 0.198, 0.327, 0.441]\nThere are two trees beside the zebra: [0.009, 0.063, 0.256, 0.489]\nlarge trees casting shadow: [0.002, 0.0, 0.643, 0.558]\n\n<zebra: [0.737, 0.403, 0.882, 0.58]> <eating> <grass: [0.011, 0.104, 0.996, 0.994]>\n<zebra: [0.737, 0.403, 0.882, 0.58]> <grazing> <grass: [0.011, 0.104, 0.996, 0.994]>\n<zebra: [0.316, 0.341, 0.43, 0.463]> <under> <tree: [0.0, 0.003, 0.399, 0.452]>\n<tree: [0.0, 0.003, 0.399, 0.452]> <beside> <zebra: [0.316, 0.341, 0.43, 0.463]>\n<deer: [0.359, 0.252, 0.398, 0.3]> <standing in front of> <tree: [0.382, 0.126, 0.412, 0.275]>\n", "response": "Task: What is the zebra doing in <Region>[0.737, 0.403, 0.882, 0.58]</Region>?\nOutput: The zebra is either eating or grazing grass.", "instruction": "What is the zebra doing in <Region>[0.737, 0.403, 0.882, 0.58]</Region>?", "input": "", "output": "The zebra is either eating or grazing grass.", "is_classification": false, "dataset": "VG", "img_info": "150269.jpg"}
{"img_id": 3765, "query": "light post next to building: [0.123, 0.099, 0.18, 0.555]\nA red brick building: [0.287, 0.008, 0.393, 0.346]\nA tan building front: [0.0, 0.016, 0.17, 0.414]\nreflection of buildings in water: [0.01, 0.591, 0.555, 0.995]\nbuildings are next to the canal: [0.002, 0.003, 0.703, 0.589]\ndark orange building with a lot of windows: [0.293, 0.0, 0.408, 0.352]\nbuilding window has green shutters: [0.0, 0.003, 0.182, 0.529]\nbuilding with a spire: [0.762, 0.242, 0.795, 0.341]\ntree in front of building: [0.486, 0.151, 0.631, 0.44]\nbuilding facade: [0.553, 0.029, 0.666, 0.388]\n\n<tree: [0.494, 0.18, 0.678, 0.419]> <in front of> <building: [0.273, 0.01, 0.385, 0.346]>\n", "response": "Task: What object is in front of the object in <Region>[0.273, 0.01, 0.385, 0.346]</Region>?\nOutput: There is a tree in front of this building.", "instruction": "What object is in front of the object in <Region>[0.273, 0.01, 0.385, 0.346]</Region>?", "input": "", "output": "There is a tree in front of this building.", "is_classification": false, "dataset": "VG", "img_info": "3765.jpg"}
{"img_id": 107931, "query": "person is wearing a jacket: [0.45, 0.654, 0.559, 0.927]\nGrass on side of brick wall: [0.014, 0.556, 0.467, 0.861]\nperson is wearing a brown jacket: [0.448, 0.622, 0.749, 0.995]\nA white building: [0.013, 0.156, 0.38, 0.847]\nlarge low concrete wall against which person is leaning: [0.291, 0.763, 0.481, 0.971]\nA bright red umbrella: [0.394, 0.249, 0.992, 0.953]\nFull green trees are by the buildings: [0.323, 0.076, 0.861, 0.478]\nOpen umbrella covering someone: [0.368, 0.254, 0.995, 0.985]\nA person holds a red umbrella outside near a wall: [0.355, 0.168, 0.935, 0.993]\nA flat-roofed building with a chimney, across from person. : [0.022, 0.186, 0.431, 0.897]\n\n<person: [0.438, 0.588, 0.895, 0.998]> <holds> <umbrella: [0.422, 0.273, 0.999, 0.997]>\n<person: [0.438, 0.588, 0.895, 0.998]> <wears> <jacket: [0.443, 0.614, 0.807, 1.0]>\n<person: [0.438, 0.588, 0.895, 0.998]> <beneath> <umbrella: [0.422, 0.273, 0.999, 0.997]>\n<vegetation: [0.001, 0.544, 0.516, 0.998]> <against> <wall: [0.026, 0.588, 0.529, 0.998]>\n<person: [0.438, 0.588, 0.895, 0.998]> <under> <umbrella: [0.422, 0.273, 0.999, 0.997]>\n<umbrella: [0.422, 0.273, 0.999, 0.997]> <covers> <person: [0.438, 0.588, 0.895, 0.998]>\n<pattern: [0.001, 0.363, 0.386, 0.561]> <beside> <building: [0.001, 0.175, 0.41, 0.927]>\n<building: [0.001, 0.175, 0.41, 0.927]> <to right of> <person: [0.438, 0.588, 0.895, 0.998]>\n<antennas: [0.164, 0.005, 0.268, 0.256]> <on a> <building: [0.001, 0.175, 0.41, 0.927]>\n<person: [0.438, 0.588, 0.895, 0.998]> <leans on> <wall: [0.026, 0.588, 0.529, 0.998]>\n", "response": "Task: What is the person in <Region>[0.438, 0.588, 0.895, 0.998]</Region> holding?\nOutput: The person is holding a red umbrella.", "instruction": "What is the person in <Region>[0.438, 0.588, 0.895, 0.998]</Region> holding?", "input": "", "output": "The person is holding a red umbrella.", "is_classification": false, "dataset": "VG", "img_info": "107931.jpg"}
{"img_id": 2393069, "query": "table set with galsses: [0.043, 0.024, 0.944, 0.994]\nrustic table setting: [0.016, 0.12, 0.957, 0.946]\nwood piece of table chair: [0.745, 0.252, 0.992, 0.546]\ngreen plants behind glass: [0.005, 0.166, 0.742, 0.394]\nglass caraffe on table: [0.199, 0.022, 0.57, 0.692]\nSmall glass goblet on the table: [0.503, 0.496, 0.755, 0.87]\nrustic unfinished wood table: [0.046, 0.444, 0.941, 0.966]\nFlowers behind the glass vase: [0.226, 0.214, 0.742, 0.412]\nwooden dresser by table: [0.411, 0.026, 0.989, 0.51]\nsmall glass wine glass on table: [0.452, 0.478, 0.758, 0.866]\n\n<table: [0.737, 0.492, 0.892, 0.592]> <below> <vase: [0.247, 0.11, 0.583, 0.68]>\n<plants: [0.535, 0.214, 0.737, 0.386]> <by> <vase: [0.247, 0.11, 0.583, 0.68]>\n", "response": "Task: What is located below the object in <Region>[0.247, 0.11, 0.583, 0.68]</Region>?\nOutput: Below the object in this region, there is a table.", "instruction": "What is located below the object in <Region>[0.247, 0.11, 0.583, 0.68]</Region>?", "input": "", "output": "Below the object in this region, there is a table.", "is_classification": false, "dataset": "VG", "img_info": "2393069.jpg"}
{"img_id": 285870, "query": "White sign on the front of the pole.: [0.502, 0.009, 0.547, 0.171]\nWoman standing in a blue dress.: [0.172, 0.102, 0.334, 0.947]\ntwo people in front of a vehicle : [0.367, 0.221, 0.501, 0.351]\na clothed mannequin behind two glass windows: [0.071, 0.048, 0.251, 0.597]\ntwo people riding a motorcycle : [0.671, 0.272, 0.771, 0.385]\npink scooter parked on the street: [0.461, 0.379, 0.642, 0.779]\nmannequin wearing a gold shirt : [0.088, 0.171, 0.184, 0.29]\n a person walking on a street : [0.119, 0.136, 0.427, 0.953]\n a person walking on a street : [0.119, 0.136, 0.427, 0.953]\n a person walking on a street : [0.441, 0.206, 0.485, 0.35]\n\n<pole: [0.367, 0.492, 0.398, 0.934]> <bordering> <motorbikes: [0.238, 0.353, 0.771, 0.909]>\n<people: [0.118, 0.146, 0.407, 0.962]> <WEARING> <dress: [0.18, 0.325, 0.403, 0.993]>\n<hedge: [0.464, 0.186, 0.927, 0.376]> <above> <bricks: [0.762, 0.262, 0.979, 0.447]>\n<mannequin: [0.106, 0.171, 0.208, 0.581]> <behind> <windows: [0.085, 0.082, 0.319, 0.425]>\n<person: [0.432, 0.225, 0.47, 0.348]> <in front of> <vehicle: [0.375, 0.202, 0.485, 0.479]>\n<people: [0.135, 0.136, 0.332, 0.795]> <walking on> <street: [0.644, 0.857, 0.828, 0.981]>\n", "response": "Task: What is bordering the object in <Region>[0.238, 0.353, 0.771, 0.909]</Region>?\nOutput: The object is a pole and it borders the motorbikes.", "instruction": "What is bordering the object in <Region>[0.238, 0.353, 0.771, 0.909]</Region>?", "input": "", "output": "The object is a pole and it borders the motorbikes.", "is_classification": false, "dataset": "VG", "img_info": "285870.jpg"}
{"img_id": 713848, "query": "ground is dark brown: [0.491, 0.166, 0.739, 0.423]\nreflection of boat in water: [0.15, 0.714, 0.844, 0.896]\nboat is on the water: [0.04, 0.327, 0.882, 0.735]\nblue tarp on boat: [0.108, 0.438, 0.38, 0.721]\nA boat on the water.: [0.159, 0.741, 0.859, 0.922]\nThe boat has handles: [0.347, 0.438, 0.728, 0.607]\nblue cover for boat: [0.11, 0.465, 0.391, 0.611]\nback of the boat: [0.647, 0.34, 0.909, 0.739]\nblue weight hanging from boat: [0.598, 0.623, 0.73, 0.724]\nwhite paint on boat: [0.142, 0.566, 0.79, 0.735]\n\n<light: [0.023, 0.101, 0.984, 0.279]> <hitting> <ground: [0.004, 0.005, 0.985, 0.729]>\n<object: [0.617, 0.645, 0.648, 0.705]> <hanging from> <boat: [0.105, 0.42, 0.863, 0.748]>\n", "response": "Task: What is hanging from the object in <Region>[0.105, 0.42, 0.863, 0.748]</Region>?\nOutput: There is a blue weight hanging from the boat.", "instruction": "What is hanging from the object in <Region>[0.105, 0.42, 0.863, 0.748]</Region>?", "input": "", "output": "There is a blue weight hanging from the boat.", "is_classification": false, "dataset": "VG", "img_info": "713848.jpg"}
{"img_id": 1592150, "query": "A street light. : [0.604, 0.014, 0.706, 0.357]\npeople are crossing the street: [0.75, 0.167, 0.906, 0.337]\nA wall on the side of a building: [0.358, 0.061, 0.452, 0.216]\nbike attached to a fence: [0.123, 0.169, 0.898, 0.9]\nPeople crossing the street: [0.66, 0.164, 0.859, 0.352]\nwire attaching bike to fence: [0.404, 0.208, 0.489, 0.435]\nPeople crossing the street: [0.66, 0.164, 0.859, 0.352]\nA wire basket on the bicycle.: [0.055, 0.303, 0.299, 0.482]\nA metal bike basket: [0.051, 0.32, 0.284, 0.486]\nA seat on a bicycle: [0.484, 0.238, 0.621, 0.297]\n\n<basket: [0.05, 0.315, 0.293, 0.473]> <mounted on> <bike: [0.046, 0.174, 0.867, 0.884]>\n<building: [0.373, 0.008, 0.876, 0.31]> <across> <street: [0.014, 0.32, 0.999, 0.773]>\n<bicycle: [0.09, 0.234, 0.915, 0.883]> <parked> <street: [0.021, 0.324, 0.949, 0.743]>\n<people: [0.47, 0.159, 0.942, 0.354]> <crossing> <street: [0.103, 0.336, 0.93, 0.711]>\n<bicycle: [0.049, 0.176, 0.866, 0.884]> <chained> <fence: [0.019, 0.087, 0.969, 0.839]>\n", "response": "Task: Where is the <Region>[0.05, 0.315, 0.293, 0.473]</Region> located?\nOutput: The region is a wire basket mounted on a bicycle.", "instruction": "Where is the <Region>[0.05, 0.315, 0.293, 0.473]</Region> located?", "input": "", "output": "The region is a wire basket mounted on a bicycle.", "is_classification": false, "dataset": "VG", "img_info": "1592150.jpg"}
{"img_id": 4291, "query": "white bar chair sitting on the floor: [0.549, 0.394, 0.676, 0.712]\nWhite desk against the wall: [0.17, 0.485, 0.443, 0.844]\ndesk chair is black: [0.32, 0.506, 0.443, 0.818]\nThe black and white tiled floor: [0.258, 0.632, 0.801, 0.991]\nA black chair under the table: [0.148, 0.618, 0.312, 0.876]\nBlack chair at the desk: [0.326, 0.488, 0.453, 0.841]\na black wooden chair: [0.359, 0.456, 0.527, 0.762]\nA black chair in the kitchen: [0.295, 0.482, 0.486, 0.882]\na wrought iron chair : [0.541, 0.412, 0.676, 0.735]\nsmall lamp on the desk: [0.252, 0.374, 0.314, 0.538]\n\n<chair: [0.322, 0.494, 0.451, 0.821]> <pushed under> <desk: [0.17, 0.485, 0.457, 0.835]>\n<chair: [0.545, 0.4, 0.672, 0.712]> <sitting on> <floor: [0.219, 0.653, 0.785, 0.994]>\n", "response": "Task: Where is the black chair located which is pushed under the desk in <Region>[0.17, 0.485, 0.457, 0.835]</Region>?\nOutput: The black chair is pushed under the desk.", "instruction": "Where is the black chair located which is pushed under the desk in <Region>[0.17, 0.485, 0.457, 0.835]</Region>?", "input": "", "output": "The black chair is pushed under the desk.", "is_classification": false, "dataset": "VG", "img_info": "4291.jpg"}
{"img_id": 2956, "query": "Large building with a steeple: [0.53, 0.268, 0.606, 0.437]\nA wall on the side of a building: [0.018, 0.492, 0.375, 0.838]\na red sign in the window of the white building: [0.547, 0.478, 0.585, 0.528]\n a window on a building : [0.14, 0.352, 0.165, 0.438]\nWindows on the corner of the building : [0.536, 0.443, 0.651, 0.803]\n a window on a building : [0.113, 0.342, 0.136, 0.43]\n a window on a building : [0.105, 0.097, 0.138, 0.237]\n a window on a building : [0.196, 0.188, 0.211, 0.257]\na large white building: [0.396, 0.272, 0.64, 0.743]\n a window on a building : [0.145, 0.155, 0.182, 0.252]\n\n<wall: [0.312, 0.338, 0.364, 0.447]> <on side of> <building: [0.005, 0.002, 0.395, 0.76]>\n", "response": "Task: What object is situated at the <Region>[0.312, 0.338, 0.364, 0.447]</Region> beside the building?\nOutput: There is a wall situated on the side of the building.", "instruction": "What object is situated at the <Region>[0.312, 0.338, 0.364, 0.447]</Region> beside the building?", "input": "", "output": "There is a wall situated on the side of the building.", "is_classification": false, "dataset": "VG", "img_info": "2956.jpg"}
{"img_id": 2813, "query": "a woman on an advertisement: [0.486, 0.434, 0.629, 0.755]\na man wearing glasses: [0.537, 0.448, 0.588, 0.539]\nsign of man in white shirt: [0.464, 0.419, 0.647, 0.79]\npicture of man wearing sunglasses: [0.484, 0.433, 0.644, 0.781]\npicture of man with short hair: [0.48, 0.44, 0.635, 0.772]\nwhite shirt on man: [0.517, 0.521, 0.611, 0.706]\nnecklace on man in sign: [0.547, 0.521, 0.583, 0.652]\nperson is wearing sunglasses : [0.54, 0.466, 0.574, 0.493]\n\n<man: [0.491, 0.448, 0.626, 0.751]> <WEARING> <sunglasses: [0.541, 0.463, 0.59, 0.494]>\n", "response": "Task: What accessory is the man in <Region>[0.491, 0.448, 0.626, 0.751]</Region> wearing?\nOutput: The man in the region is wearing sunglasses.", "instruction": "What accessory is the man in <Region>[0.491, 0.448, 0.626, 0.751]</Region> wearing?", "input": "", "output": "The man in the region is wearing sunglasses.", "is_classification": false, "dataset": "VG", "img_info": "2813.jpg"}
{"img_id": 2393365, "query": "this is a woman: [0.544, 0.45, 0.686, 0.813]\nthe kite has yellow in it: [0.592, 0.019, 0.902, 0.288]\nthis is a kite : [0.64, 0.047, 0.788, 0.164]\nshe is flying a kite: [0.494, 0.037, 0.884, 0.913]\nThe woman is wearing a long dress.: [0.552, 0.614, 0.686, 0.787]\nthe kite is red in color: [0.59, 0.042, 0.798, 0.152]\nThe woman is wearing a long dress.: [0.552, 0.614, 0.686, 0.787]\nthe woman is sitting: [0.82, 0.609, 0.968, 0.815]\nthe kite is medium in size: [0.586, 0.047, 0.816, 0.169]\nwoman is wearing a skirt: [0.516, 0.433, 0.716, 0.937]\n\n<woman: [0.56, 0.452, 0.686, 0.806]> <holding> <kite: [0.594, 0.033, 0.792, 0.159]>\n<woman: [0.56, 0.452, 0.696, 0.806]> <WEARING> <skirt: [0.574, 0.63, 0.68, 0.803]>\n<she: [0.56, 0.454, 0.702, 0.813]> <flies> <kite: [0.594, 0.033, 0.792, 0.159]>\n<woman: [0.56, 0.452, 0.696, 0.806]> <touching> <string: [0.592, 0.133, 0.692, 0.468]>\n", "response": "Task: What is the color of the kite in <Region>[0.59, 0.042, 0.798, 0.152]</Region>?\nOutput: The kite is red in color.", "instruction": "What is the color of the kite in <Region>[0.59, 0.042, 0.798, 0.152]</Region>?", "input": "", "output": "The kite is red in color.", "is_classification": false, "dataset": "VG", "img_info": "2393365.jpg"}
{"img_id": 497995, "query": "the man wearing black shorts: [0.338, 0.513, 0.435, 0.844]\nblack socks on man: [0.339, 0.788, 0.431, 0.815]\nthis is a net: [0.134, 0.466, 0.495, 0.834]\nthe man standing with his legs far apart: [0.084, 0.231, 0.156, 0.386]\nblack shorts on man: [0.356, 0.676, 0.426, 0.733]\nplayer in white headband and white shoes holds racket: [0.701, 0.493, 0.834, 0.801]\nthe net on the tennis court: [0.002, 0.351, 0.996, 0.987]\nthe net is white and black: [0.04, 0.505, 0.37, 0.87]\nthe man wearing a white shirt: [0.333, 0.512, 0.44, 0.848]\nthe shorts are black: [0.316, 0.598, 0.462, 0.791]\n\n<man: [0.323, 0.501, 0.452, 0.851]> <WEARING> <shorts: [0.338, 0.656, 0.417, 0.724]>\n<man: [0.335, 0.512, 0.44, 0.849]> <carrying> <racket: [0.332, 0.557, 0.424, 0.693]>\n<people: [0.005, 0.013, 0.994, 0.282]> <watching> <men: [0.054, 0.321, 0.841, 0.847]>\n<net: [0.0, 0.447, 0.832, 0.764]> <OF> <tennis court: [0.003, 0.35, 0.999, 0.994]>\n", "response": "Task: What is the color of the shorts the man in <Region>[0.335, 0.512, 0.44, 0.849]</Region> is wearing?\nOutput: The shorts the man is wearing are black.", "instruction": "What is the color of the shorts the man in <Region>[0.335, 0.512, 0.44, 0.849]</Region> is wearing?", "input": "", "output": "The shorts the man is wearing are black.", "is_classification": false, "dataset": "VG", "img_info": "497995.jpg"}
{"img_id": 198, "query": "house has balcony: [0.795, 0.397, 0.975, 0.533]\nThe house is a log cabin: [0.085, 0.14, 0.94, 0.75]\nhouse is made of logs: [0.087, 0.173, 0.975, 0.823]\nhouse has balcony: [0.795, 0.397, 0.975, 0.533]\nwhite car parked next to log cabin: [0.085, 0.153, 0.995, 0.997]\nThe wooden balcony: [0.787, 0.39, 0.983, 0.57]\nThe house is a log cabin: [0.085, 0.14, 0.94, 0.75]\nwhite car parked next to house: [0.652, 0.663, 0.993, 0.997]\nhouse has porch: [0.085, 0.487, 0.32, 0.723]\nhouse has porch: [0.085, 0.487, 0.32, 0.723]\n\n<car: [0.652, 0.673, 0.998, 1.0]> <parked beside> <house: [0.09, 0.153, 0.97, 0.813]>\n<balcony: [0.802, 0.4, 0.973, 0.543]> <on side of> <house: [0.09, 0.153, 0.97, 0.813]>\n<leaves: [0.003, 0.88, 0.66, 1.0]> <strewn on> <grass: [0.005, 0.697, 0.545, 0.947]>\n<chimney: [0.465, 0.18, 0.555, 0.323]> <sitting on> <roof: [0.095, 0.18, 0.863, 0.497]>\n<license plate: [0.752, 0.86, 0.82, 0.93]> <on back of> <car: [0.652, 0.673, 0.998, 1.0]>\n<window: [0.733, 0.537, 0.802, 0.657]> <set on> <house: [0.09, 0.153, 0.97, 0.813]>\n<door: [0.723, 0.667, 0.88, 0.793]> <opened on> <car: [0.652, 0.673, 0.998, 1.0]>\n<balcony: [0.802, 0.4, 0.973, 0.543]> <sticking off> <house: [0.09, 0.153, 0.97, 0.813]>\n<door: [0.815, 0.34, 0.865, 0.413]> <to> <balcony: [0.802, 0.4, 0.973, 0.543]>\n<chimney: [0.465, 0.18, 0.555, 0.323]> <in middle of th> <roof: [0.095, 0.18, 0.863, 0.497]>\n<car: [0.652, 0.673, 0.998, 1.0]> <beside> <house: [0.09, 0.153, 0.97, 0.813]>\n<house: [0.09, 0.153, 0.97, 0.813]> <has a> <porch: [0.115, 0.68, 0.307, 0.75]>\n", "response": "Task: What object can be found on the side of the object in <Region>[0.09, 0.153, 0.97, 0.813]</Region>?\nOutput: A balcony, porch, and a white car can be found on the side of the house.", "instruction": "What object can be found on the side of the object in <Region>[0.09, 0.153, 0.97, 0.813]</Region>?", "input": "", "output": "A balcony, porch, and a white car can be found on the side of the house.", "is_classification": false, "dataset": "VG", "img_info": "198.jpg"}
{"img_id": 963, "query": "the woman is next to the man: [0.239, 0.156, 0.831, 0.995]\nthe man wears blue jeans: [0.536, 0.797, 0.723, 0.993]\nwoman wearing purple scarf on head: [0.236, 0.331, 0.578, 0.995]\nman wearing baseball hat: [0.495, 0.336, 0.591, 0.544]\nthe man is wearing a black leather jacket: [0.541, 0.17, 0.819, 0.864]\nwoman wearing purple scarf on head: [0.236, 0.331, 0.578, 0.995]\nthe black leather jacket: [0.486, 0.323, 0.831, 0.918]\nblonde haired woman: [0.242, 0.334, 0.573, 0.995]\nperson standing on sidewalk: [0.004, 0.391, 0.25, 0.993]\ngirl wearing blue coat : [0.249, 0.324, 0.494, 0.993]\n\n<woman: [0.301, 0.266, 0.511, 0.913]> <next ot> <man: [0.516, 0.113, 0.83, 0.902]>\n<woman: [0.461, 0.363, 0.516, 0.537]> <WEARING> <coat: [0.45, 0.414, 0.521, 0.527]>\n<man: [0.485, 0.155, 0.828, 0.997]> <standing on> <sidewalk: [0.175, 0.493, 0.835, 0.988]>\n<man: [0.471, 0.128, 0.844, 0.997]> <wears> <jacket: [0.472, 0.328, 0.838, 0.907]>\n<girl: [0.241, 0.329, 0.573, 0.997]> <holding> <man: [0.495, 0.156, 0.82, 0.992]>\n", "response": "Task: What color is the scarf worn by the woman in <Region>[0.236, 0.331, 0.578, 0.995]</Region>?\nOutput: The scarf worn by the woman is purple in color.", "instruction": "What color is the scarf worn by the woman in <Region>[0.236, 0.331, 0.578, 0.995]</Region>?", "input": "", "output": "The scarf worn by the woman is purple in color.", "is_classification": false, "dataset": "VG", "img_info": "963.jpg"}
{"img_id": 2393807, "query": "computer table is wooden: [0.224, 0.62, 0.29, 0.71]\ncomputer table is wooden: [0.174, 0.563, 0.276, 0.728]\ncomputer table is wooden: [0.282, 0.629, 0.32, 0.665]\ncomputer table is wooden: [0.234, 0.617, 0.34, 0.707]\ncomputer table is wooden: [0.23, 0.593, 0.27, 0.659]\ncomputer table is wooden: [0.246, 0.623, 0.272, 0.668]\ncomputer table is wooden: [0.282, 0.629, 0.32, 0.665]\nkid pointing at a computer: [0.404, 0.033, 0.878, 0.994]\nA laptop on the table.: [0.194, 0.105, 0.554, 0.605]\ncomputer table is wooden: [0.282, 0.629, 0.32, 0.665]\n\n<computer: [0.186, 0.093, 0.584, 0.593]> <behind> <kid: [0.284, 0.009, 0.996, 0.997]>\n<cables: [0.292, 0.74, 0.46, 0.904]> <under> <table: [0.008, 0.35, 0.686, 0.997]>\n<kid: [0.284, 0.009, 0.996, 0.997]> <hides> <face: [0.532, 0.027, 0.96, 0.422]>\n<computer: [0.186, 0.093, 0.584, 0.593]> <sitting on> <table: [0.014, 0.317, 0.688, 0.997]>\n", "response": "Task: What is under the object in <Region>[0.008, 0.35, 0.686, 0.997]</Region>?\nOutput: There are cables under the table.", "instruction": "What is under the object in <Region>[0.008, 0.35, 0.686, 0.997]</Region>?", "input": "", "output": "There are cables under the table.", "is_classification": false, "dataset": "VG", "img_info": "2393807.jpg"}
{"img_id": 29, "query": "one woman is in shorts: [0.001, 0.3, 0.995, 0.99]\nwooden shack structure on beach: [0.004, 0.248, 0.399, 0.582]\nwoman has her hands on her shorts: [0.346, 0.192, 0.544, 0.725]\ntall wooden pole mounted in beach: [0.101, 0.0, 0.215, 0.533]\nhandwritten text music boat: [0.54, 0.423, 0.704, 0.617]\nwhite boat with blue trim: [0.588, 0.457, 0.843, 0.67]\na shadow is behind the woman: [0.056, 0.547, 0.44, 0.683]\na shadow is behind the woman: [0.056, 0.547, 0.44, 0.683]\nfootprints are on the sand: [0.186, 0.69, 0.326, 0.783]\na shadow is behind the woman: [0.056, 0.547, 0.44, 0.683]\n\n<woman: [0.385, 0.27, 0.469, 0.693]> <facing> <ocean: [0.12, 0.297, 0.999, 0.503]>\n<raft: [0.724, 0.385, 0.754, 0.418]> <close to> <beach: [0.0, 0.417, 1.0, 0.998]>\n<tank top: [0.391, 0.332, 0.459, 0.46]> <above> <shorts: [0.4, 0.448, 0.465, 0.548]>\n<woman: [0.834, 0.357, 0.915, 0.648]> <wears> <skirt: [0.843, 0.497, 0.91, 0.59]>\n<words: [0.591, 0.487, 0.631, 0.537]> <written on> <boat: [0.586, 0.455, 0.848, 0.645]>\n<woman: [0.385, 0.27, 0.469, 0.693]> <WEARING> <attire: [0.388, 0.35, 0.461, 0.552]>\n<grass: [0.001, 0.44, 1.0, 0.7]> <on top of> <sand: [0.003, 0.413, 1.0, 0.998]>\n<horizon: [0.641, 0.305, 0.67, 0.313]> <across> <ocean: [0.12, 0.297, 0.999, 0.503]>\n<shadow: [0.297, 0.642, 0.395, 0.69]> <behind> <woman: [0.385, 0.27, 0.469, 0.693]>\n<outside: [0.0, 0.0, 0.998, 0.998]> <taken> <outside: [0.004, 0.022, 0.969, 0.973]>\n", "response": "Task: What is written on the boat located in <Region>[0.586, 0.455, 0.848, 0.645]</Region>?\nOutput: There is handwritten text on the boat.", "instruction": "What is written on the boat located in <Region>[0.586, 0.455, 0.848, 0.645]</Region>?", "input": "", "output": "There is handwritten text on the boat.", "is_classification": false, "dataset": "VG", "img_info": "29.jpg"}
{"img_id": 674, "query": "Four umbrellas shading tables and chairs.: [0.412, 0.72, 0.705, 0.887]\nwindow of a red building: [0.55, 0.402, 0.618, 0.517]\nwindow on the building: [0.195, 0.145, 0.258, 0.242]\nman standing on top of building: [0.314, 0.002, 0.341, 0.06]\nwindow of a red building: [0.684, 0.507, 0.751, 0.647]\nA courtyard.: [0.021, 0.832, 0.989, 0.997]\nA planter with a green bush in it.: [0.301, 0.773, 0.364, 0.898]\nPeople sitting near a building: [0.043, 0.812, 0.142, 0.923]\nBoxes with plants in them: [0.824, 0.87, 0.924, 0.923]\nA yellow building with green shutters.: [0.037, 0.027, 0.301, 0.902]\n\n<courtyard: [0.0, 0.843, 0.999, 0.998]> <in front of> <building: [0.555, 0.002, 1.0, 0.9]>\n<man: [0.919, 0.71, 1.0, 0.998]> <in a> <courtyard: [0.0, 0.843, 0.999, 0.998]>\n<planter: [0.831, 0.877, 0.879, 0.907]> <with a> <plant: [0.831, 0.795, 0.884, 0.877]>\n<umbrellas: [0.412, 0.735, 0.7, 0.78]> <over> <people: [0.449, 0.797, 0.644, 0.885]>\n", "response": "Task: What is in front of the building in <Region>[0.555, 0.002, 1.0, 0.9]</Region>?\nOutput: A courtyard is in front of this building.", "instruction": "What is in front of the building in <Region>[0.555, 0.002, 1.0, 0.9]</Region>?", "input": "", "output": "A courtyard is in front of this building.", "is_classification": false, "dataset": "VG", "img_info": "674.jpg"}
{"img_id": 4766, "query": "door in front of blue house: [0.55, 0.38, 0.605, 0.597]\nthe steps leading to the porch: [0.295, 0.597, 0.405, 0.69]\nthe bush between the steps: [0.195, 0.573, 0.3, 0.673]\nthe window on the side of the house: [0.88, 0.38, 0.915, 0.55]\nthe roof of the porch: [0.265, 0.213, 0.885, 0.377]\nthe jacket is pink: [0.472, 0.563, 0.532, 0.643]\nthe bench on the porch: [0.637, 0.513, 0.723, 0.61]\nthe steps leading to the porch: [0.295, 0.597, 0.405, 0.69]\nthe steps leading to the porch: [0.295, 0.597, 0.405, 0.69]\ndoor in front of blue house: [0.395, 0.403, 0.42, 0.583]\n\n<door: [0.463, 0.403, 0.52, 0.57]> <in front of> <house: [0.033, 0.01, 0.97, 0.753]>\n<boy: [0.58, 0.497, 0.672, 0.757]> <WEARING> <jacket: [0.59, 0.55, 0.662, 0.663]>\n<plants: [0.207, 0.577, 0.312, 0.667]> <are outside of> <porch: [0.24, 0.33, 0.88, 0.7]>\n<plants: [0.207, 0.577, 0.312, 0.667]> <between> <steps: [0.28, 0.54, 0.403, 0.693]>\n<flag: [0.253, 0.353, 0.345, 0.503]> <hanging over> <steps: [0.28, 0.54, 0.403, 0.693]>\n<steps: [0.28, 0.54, 0.403, 0.693]> <are leading up to> <porch: [0.24, 0.33, 0.88, 0.7]>\n", "response": "Task: What is located in front of the <Region>[0.033, 0.01, 0.97, 0.753]</Region> region?\nOutput: The door is located in front of the blue house.", "instruction": "What is located in front of the <Region>[0.033, 0.01, 0.97, 0.753]</Region> region?", "input": "", "output": "The door is located in front of the blue house.", "is_classification": false, "dataset": "VG", "img_info": "4766.jpg"}
{"img_id": 498013, "query": "head of the woman: [0.273, 0.31, 0.329, 0.406]\nWomen in blue dresses: [0.149, 0.183, 0.817, 0.928]\npair of blue slippers on woman : [0.667, 0.83, 0.785, 0.947]\nhead of the woman: [0.273, 0.31, 0.329, 0.406]\narm of a woman: [0.625, 0.474, 0.811, 0.523]\nthe woman in the dress: [0.449, 0.305, 0.757, 0.981]\nhand of the woman: [0.714, 0.357, 0.746, 0.391]\nleg of a woman: [0.383, 0.742, 0.405, 0.93]\narm of a woman: [0.521, 0.4, 0.664, 0.48]\npurple paper umbrella over woman's head: [0.605, 0.258, 0.82, 0.457]\n\n<woman: [0.18, 0.202, 0.812, 0.981]> <holding> <parasols: [0.244, 0.4, 0.758, 0.868]>\n<woman: [0.18, 0.202, 0.812, 0.981]> <WEARING> <dresses: [0.191, 0.335, 0.758, 0.892]>\n<hair: [0.237, 0.297, 0.71, 0.447]> <on top of> <woman: [0.18, 0.202, 0.812, 0.981]>\n<woman: [0.173, 0.19, 0.816, 0.988]> <dancing on> <stage: [0.01, 0.862, 0.996, 0.988]>\n", "response": "Task: What is the woman in <Region>[0.18, 0.202, 0.812, 0.981]</Region> holding?\nOutput: The woman is holding a parasol.", "instruction": "What is the woman in <Region>[0.18, 0.202, 0.812, 0.981]</Region> holding?", "input": "", "output": "The woman is holding a parasol.", "is_classification": false, "dataset": "VG", "img_info": "498013.jpg"}
{"img_id": 285817, "query": "A man wearing a red and white out fit.: [0.247, 0.0, 0.544, 0.987]\na man wearing a shirt: [0.204, 0.022, 0.552, 0.867]\na mans thigh: [0.369, 0.783, 0.595, 0.933]\nsweat band on mans right wrist: [0.497, 0.347, 0.558, 0.458]\ncorner of empty blue chair: [0.697, 0.679, 0.917, 0.936]\nA blue and grey chair up against the wall. : [0.691, 0.64, 0.914, 0.974]\na man wearing a red shirt: [0.201, 0.007, 0.634, 0.994]\nA green tennis ball in the air.: [0.93, 0.549, 0.993, 0.649]\na man holding a tennis racket: [0.192, 0.003, 0.636, 0.996]\na man wearing a red shirt: [0.201, 0.007, 0.634, 0.994]\n\n<man: [0.201, 0.015, 0.601, 0.996]> <swinging> <racket: [0.552, 0.116, 0.641, 0.398]>\n<man: [0.201, 0.015, 0.601, 0.996]> <WEARING> <shirt: [0.252, 0.192, 0.463, 0.703]>\n<chair: [0.692, 0.685, 0.912, 0.99]> <by> <air: [0.0, 0.0, 1.0, 1.0]>\n<band: [0.505, 0.351, 0.554, 0.448]> <on a> <band: [0.505, 0.351, 0.554, 0.448]>\n<man: [0.197, 0.0, 0.638, 1.0]> <hitting a> <ball: [0.938, 0.555, 0.968, 0.672]>\n<air: [0.0, 0.0, 1.0, 1.0]> <for> <air: [0.0, 0.0, 1.0, 1.0]>\n<ball: [0.936, 0.564, 0.97, 0.634]> <flying in> <air: [0.646, 0.035, 0.964, 0.915]>\n<man: [0.197, 0.0, 0.638, 1.0]> <holding> <tennis racket: [0.547, 0.114, 0.639, 0.384]>\n<man: [0.197, 0.0, 0.638, 1.0]> <wearing a> <shirt: [0.243, 0.196, 0.472, 0.653]>\n", "response": "Task: What is the man in <Region>[0.201, 0.015, 0.601, 0.996]</Region> holding and what is he doing with it?\nOutput: The man is holding a tennis racket and is swinging it.", "instruction": "What is the man in <Region>[0.201, 0.015, 0.601, 0.996]</Region> holding and what is he doing with it?", "input": "", "output": "The man is holding a tennis racket and is swinging it.", "is_classification": false, "dataset": "VG", "img_info": "285817.jpg"}
{"img_id": 161, "query": "a palm tree : [0.372, 0.42, 0.487, 0.591]\nBicycles parked by the building.: [0.047, 0.574, 0.255, 0.629]\nDirt around the base of the tree trunk.: [0.19, 0.652, 0.65, 0.84]\nleaves of the tree are green: [0.762, 0.033, 0.992, 0.275]\nA group of people walking in the middle of a street: [0.748, 0.5, 0.863, 0.594]\nA man wearing shorts walking.: [0.795, 0.504, 0.835, 0.589]\ntree is tall and brown: [0.297, 0.019, 0.605, 0.748]\nshadow of the tree: [0.64, 0.632, 0.852, 0.693]\nman in gray shirt walking: [0.793, 0.507, 0.833, 0.568]\nA large brown tree trunk: [0.288, 0.0, 0.552, 0.776]\n\n<building: [0.008, 0.265, 0.635, 0.645]> <by> <street: [0.0, 0.54, 0.987, 0.791]>\n<shadow: [0.62, 0.631, 0.92, 0.696]> <OF> <tree: [0.862, 0.19, 0.96, 0.6]>\n<man: [0.792, 0.504, 0.828, 0.594]> <WEARING> <shorts: [0.787, 0.539, 0.835, 0.574]>\n", "response": "Task: What is the relationship between the object in <Region>[0.008, 0.265, 0.635, 0.645]</Region> and the object in <Region>[0.0, 0.54, 0.987, 0.791]</Region>?\nOutput: The building is located beside the street.", "instruction": "What is the relationship between the object in <Region>[0.008, 0.265, 0.635, 0.645]</Region> and the object in <Region>[0.0, 0.54, 0.987, 0.791]</Region>?", "input": "", "output": "The building is located beside the street.", "is_classification": false, "dataset": "VG", "img_info": "161.jpg"}
{"img_id": 2391614, "query": "individual wearing blue jeans: [0.597, 0.702, 0.89, 0.996]\na plate of food: [0.154, 0.444, 0.607, 0.608]\nblue, red and white sweater: [0.327, 0.26, 0.909, 0.742]\nposter on the wall: [0.009, 0.0, 0.447, 0.134]\na hot pad on the wall: [0.003, 0.208, 0.097, 0.308]\nsmall bottles and spices on racks on wall: [0.082, 0.138, 0.478, 0.304]\nfood with gravy on a plate: [0.167, 0.468, 0.487, 0.544]\na spice rack: [0.006, 0.14, 0.503, 0.316]\nspice racks on wall: [0.0, 0.138, 0.475, 0.312]\na plate of food: [0.154, 0.444, 0.607, 0.608]\n\n<lady: [0.16, 0.078, 0.912, 0.998]> <wearing a> <sweater: [0.355, 0.278, 0.906, 0.734]>\n<lady: [0.16, 0.086, 0.934, 0.57]> <holding> <plate: [0.16, 0.472, 0.487, 0.546]>\n<spices: [0.003, 0.148, 0.053, 0.218]> <on a> <rack: [0.003, 0.148, 0.214, 0.222]>\n<floor: [0.89, 0.71, 0.997, 1.0]> <has a> <rug: [0.887, 0.706, 0.997, 0.812]>\n<red eye: [0.535, 0.18, 0.56, 0.198]> <from> <flash: [0.003, 0.002, 0.991, 0.998]>\n<pans: [0.943, 0.002, 0.997, 0.18]> <mounted on> <wall: [0.865, 0.004, 0.997, 0.73]>\n<lady: [0.16, 0.078, 0.912, 0.998]> <WEARING> <jeans: [0.569, 0.672, 0.887, 0.998]>\n<plate: [0.16, 0.494, 0.487, 0.55]> <has a pile of> <food: [0.182, 0.474, 0.425, 0.532]>\n<rack: [0.261, 0.242, 0.484, 0.308]> <for> <cooking spices: [0.173, 0.158, 0.217, 0.212]>\n<lady: [0.16, 0.078, 0.912, 0.998]> <making> <food: [0.182, 0.474, 0.425, 0.532]>\n", "response": "Task: What object is the lady holding in <Region>[0.16, 0.086, 0.934, 0.57]</Region>?\nOutput: The lady is holding a plate of food in the specified region.", "instruction": "What object is the lady holding in <Region>[0.16, 0.086, 0.934, 0.57]</Region>?", "input": "", "output": "The lady is holding a plate of food in the specified region.", "is_classification": false, "dataset": "VG", "img_info": "2391614.jpg"}
{"img_id": 3222, "query": " a window on a building : [0.789, 0.533, 0.843, 0.697]\nthis is a window display: [0.051, 0.482, 0.385, 0.95]\nA window on a building.: [0.048, 0.04, 0.147, 0.187]\n a window on a building : [0.461, 0.395, 0.532, 0.85]\nA window on a building.: [0.31, 0.04, 0.366, 0.275]\npeople window shopping in a European city: [0.699, 0.61, 0.784, 0.922]\n a window on a building : [0.141, 0.398, 0.399, 0.918]\nA window on a building.: [0.562, 0.133, 0.595, 0.365]\nthree people window shopping: [0.495, 0.627, 0.647, 0.928]\n a window on a building : [0.519, 0.435, 0.601, 0.685]\n\n<window: [0.566, 0.133, 0.603, 0.397]> <on a> <building: [0.003, 0.0, 0.704, 0.995]>\n", "response": "Task: What object is located in the <Region>[0.566, 0.133, 0.603, 0.397]</Region> of the image?\nOutput: There is a window located in this region of the image.", "instruction": "What object is located in the <Region>[0.566, 0.133, 0.603, 0.397]</Region> of the image?", "input": "", "output": "There is a window located in this region of the image.", "is_classification": false, "dataset": "VG", "img_info": "3222.jpg"}
{"img_id": 925, "query": "white number on equipment: [0.486, 0.604, 0.552, 0.66]\nA man wearing a red shirt.: [0.827, 0.369, 0.866, 0.41]\nSmall green tree in front of a truck.: [0.9, 0.681, 0.998, 0.994]\nyellow ladder on equipment: [0.634, 0.529, 0.872, 0.881]\nthe people on the large dump truck: [0.025, 0.087, 0.995, 0.996]\nblack railing on equipment: [0.372, 0.367, 0.714, 0.519]\nTwo headlights of a truck: [0.487, 0.673, 0.525, 0.71]\ngreen tree under equipment: [0.905, 0.677, 0.966, 0.996]\nMan wearing a red shirt: [0.823, 0.348, 0.869, 0.471]\nmen have yellow shirts: [0.741, 0.371, 0.825, 0.446]\n\n<tree: [0.902, 0.669, 0.994, 0.996]> <under> <equipment: [0.084, 0.296, 0.878, 0.935]>\n<people: [0.125, 0.217, 0.178, 0.265]> <in rear of> <truck: [0.0, 0.092, 0.998, 1.002]>\n<man: [0.831, 0.354, 0.87, 0.44]> <wearing a> <shirt: [0.831, 0.365, 0.878, 0.419]>\n", "response": "Task: What color shirts are the men wearing in <Region>[0.741, 0.371, 0.825, 0.446]</Region>?\nOutput: The shirts that the men are wearing are yellow.", "instruction": "What color shirts are the men wearing in <Region>[0.741, 0.371, 0.825, 0.446]</Region>?", "input": "", "output": "The shirts that the men are wearing are yellow.", "is_classification": false, "dataset": "VG", "img_info": "925.jpg"}
{"img_id": 285865, "query": "Black book bag by the chair.: [0.503, 0.611, 0.605, 0.909]\nA gray plastic chair with metal legs: [0.3, 0.435, 0.491, 0.956]\na man wearing socks: [0.604, 0.564, 0.666, 0.687]\na man sitting outside: [0.337, 0.107, 0.539, 0.584]\nthe man is in the chair: [0.31, 0.261, 0.679, 0.659]\na man wearing a hat: [0.315, 0.111, 0.437, 0.246]\na old man sitting: [0.19, 0.026, 0.791, 0.996]\nthe man is in the chair: [0.31, 0.261, 0.679, 0.659]\nan old man sitting on a chair: [0.307, 0.094, 0.75, 0.958]\nan old school looking chair: [0.25, 0.346, 0.617, 0.956]\n\n<man: [0.289, 0.088, 0.754, 0.952]> <WEARING> <hat: [0.319, 0.089, 0.438, 0.183]>\n<bag: [0.511, 0.65, 0.633, 0.893]> <sitting on> <ground: [0.005, 0.493, 0.996, 0.985]>\n<man: [0.289, 0.088, 0.754, 0.952]> <sitting in> <chair: [0.298, 0.382, 0.596, 0.949]>\n", "response": "Task: Where is the man in <Region>[0.289, 0.088, 0.754, 0.952]</Region> sitting?\nOutput: He is sitting in a chair.", "instruction": "Where is the man in <Region>[0.289, 0.088, 0.754, 0.952]</Region> sitting?", "input": "", "output": "He is sitting in a chair.", "is_classification": false, "dataset": "VG", "img_info": "285865.jpg"}
{"img_id": 3316, "query": "A window on a building.: [0.459, 0.015, 0.53, 0.18]\nA window on a building.: [0.797, 0.427, 0.9, 0.485]\nparked tan car : [0.172, 0.593, 0.318, 0.678]\nA window on a building.: [0.211, 0.388, 0.259, 0.455]\nthe cars on the roads: [0.001, 0.587, 0.998, 0.997]\ntire of the car: [0.391, 0.71, 0.436, 0.77]\nwindow on the building: [0.468, 0.212, 0.547, 0.382]\nA two door car : [0.182, 0.628, 0.469, 0.762]\nthe roads in front of the buildings: [0.0, 0.002, 0.998, 0.993]\ncar on the road: [0.525, 0.603, 0.766, 0.757]\n\n<roads: [0.025, 0.775, 0.995, 0.992]> <in front of> <buildings: [0.016, 0.028, 0.976, 0.68]>\n<tire: [0.743, 0.715, 0.787, 0.775]> <OF> <car: [0.535, 0.617, 0.815, 0.768]>\n<tree: [0.266, 0.232, 0.495, 0.64]> <on top of> <sidewalk: [0.217, 0.618, 0.899, 0.752]>\n<window: [0.454, 0.013, 0.547, 0.207]> <attached to> <building: [0.338, 0.017, 0.95, 0.74]>\n", "response": "Task: What object is on top of the <Region>[0.217, 0.618, 0.899, 0.752]</Region>?\nOutput: There is a tree on top of the sidewalk in that region.", "instruction": "What object is on top of the <Region>[0.217, 0.618, 0.899, 0.752]</Region>?", "input": "", "output": "There is a tree on top of the sidewalk in that region.", "is_classification": false, "dataset": "VG", "img_info": "3316.jpg"}
{"img_id": 4556, "query": "A wall on the side of a building: [0.016, 0.558, 0.373, 0.752]\nstone block on wall: [0.861, 0.91, 0.925, 0.962]\nA wall on the side of a building: [0.016, 0.712, 0.373, 0.906]\nstone block on wall: [0.907, 0.9, 0.995, 0.954]\nbrick on the wall: [0.389, 0.716, 0.443, 0.768]\n a stone in a wall : [0.541, 0.9, 0.611, 0.936]\nbrick o nthe wall: [0.832, 0.8, 0.979, 0.858]\nbrick o nthe wall: [0.216, 0.766, 0.259, 0.818]\nthe pipe is going down the wall: [0.331, 0.442, 0.413, 0.726]\n a stone in a wall : [0.923, 0.894, 0.992, 0.966]\n\n<railing: [0.312, 0.184, 0.528, 0.278]> <on top of> <structure: [0.117, 0.174, 0.709, 0.79]>\n<wall: [0.013, 0.662, 0.565, 0.956]> <on side of a> <building: [0.059, 0.142, 0.989, 0.902]>\n", "response": "Task: What is on top of <Region>[0.117, 0.174, 0.709, 0.79]</Region>?\nOutput: There is a railing on top of this structure.", "instruction": "What is on top of <Region>[0.117, 0.174, 0.709, 0.79]</Region>?", "input": "", "output": "There is a railing on top of this structure.", "is_classification": false, "dataset": "VG", "img_info": "4556.jpg"}
{"img_id": 4403, "query": "tree in the background: [0.438, 0.386, 0.469, 0.505]\ntree in the background: [0.333, 0.4, 0.384, 0.507]\ntree in the background: [0.151, 0.453, 0.185, 0.518]\ntree in the background: [0.506, 0.317, 0.546, 0.463]\ntree in the background: [0.76, 0.281, 0.851, 0.476]\nwrecked rumble is on the ground: [0.207, 0.696, 0.365, 0.822]\nsmall white house looks untouched be devastation: [0.482, 0.407, 0.585, 0.526]\ntree in the background: [0.438, 0.386, 0.469, 0.505]\ntrees falling and uprooted: [0.22, 0.413, 0.376, 0.576]\nwrecked rumble is on the ground: [0.684, 0.507, 0.927, 0.845]\n\n<ruble: [0.39, 0.801, 0.494, 0.929]> <lying on> <ground: [0.0, 0.6, 0.994, 0.992]>\n<stairs: [0.661, 0.757, 0.853, 0.99]> <attached to> <house: [0.688, 0.405, 0.999, 0.927]>\n<tree: [0.765, 0.13, 0.881, 0.514]> <behind> <house: [0.688, 0.405, 0.999, 0.927]>\n<window: [0.278, 0.744, 0.312, 0.784]> <on side of> <house: [0.203, 0.685, 0.378, 0.818]>\n<tree: [0.15, 0.447, 0.175, 0.533]> <located in> <field: [0.003, 0.52, 0.479, 0.887]>\n<tree: [0.001, 0.438, 0.03, 0.568]> <sitting in> <field: [0.003, 0.52, 0.479, 0.887]>\n", "response": "Task: What is the relationship between the house in <Region>[0.482, 0.407, 0.585, 0.526]</Region> and the stairs in <Region>[0.661, 0.757, 0.853, 0.99]</Region>?\nOutput: The stairs are attached to the small white house.", "instruction": "What is the relationship between the house in <Region>[0.482, 0.407, 0.585, 0.526]</Region> and the stairs in <Region>[0.661, 0.757, 0.853, 0.99]</Region>?", "input": "", "output": "The stairs are attached to the small white house.", "is_classification": false, "dataset": "VG", "img_info": "4403.jpg"}
{"img_id": 639, "query": "A woman walking on a sidewalk: [0.743, 0.508, 0.792, 0.801]\nA black backpack on a person: [0.596, 0.598, 0.718, 0.842]\nperson standing on sidewalk: [0.307, 0.497, 0.349, 0.617]\nperson standing on sidewalk: [0.106, 0.499, 0.216, 0.936]\nAn orange striped shirt on a person: [0.845, 0.559, 0.915, 0.668]\nhead of a person: [0.575, 0.448, 0.652, 0.576]\nperson standing on sidewalk: [0.003, 0.418, 0.116, 0.996]\nperson standing on sidewalk: [0.003, 0.418, 0.116, 0.996]\nperson standing on sidewalk: [0.003, 0.418, 0.116, 0.996]\nperson standing on sidewalk: [0.341, 0.48, 0.378, 0.677]\n\n<doorway: [0.839, 0.214, 0.932, 0.437]> <on a> <building: [0.634, 0.024, 0.999, 0.493]>\n<woman: [0.828, 0.488, 0.925, 0.865]> <walking on> <sidewalk: [0.087, 0.533, 0.968, 0.996]>\n<man: [0.12, 0.471, 0.357, 1.0]> <wearing a> <backpack: [0.608, 0.61, 0.703, 0.839]>\n<man: [0.66, 0.42, 0.777, 0.91]> <WEARING> <sneakers: [0.7, 0.865, 0.739, 0.927]>\n<watch: [0.689, 0.422, 0.705, 0.433]> <worn by> <man: [0.66, 0.42, 0.777, 0.91]>\n<man: [0.12, 0.471, 0.357, 1.0]> <standing on> <sidewalk: [0.087, 0.533, 0.968, 0.996]>\n<head: [0.751, 0.499, 0.776, 0.561]> <of a> <person: [0.741, 0.525, 0.809, 0.822]>\n", "response": "Task: What is the object on the person in <Region>[0.596, 0.598, 0.718, 0.842]</Region> wearing, and what is the object's type?\nOutput: The object on the person in the given region is a black backpack.", "instruction": "What is the object on the person in <Region>[0.596, 0.598, 0.718, 0.842]</Region> wearing, and what is the object's type?", "input": "", "output": "The object on the person in the given region is a black backpack.", "is_classification": false, "dataset": "VG", "img_info": "639.jpg"}
{"img_id": 947, "query": "a tall grey building with many windows: [0.002, 0.491, 0.2, 0.829]\nthe lion fountain behind the woman: [0.438, 0.578, 0.704, 0.984]\nA man dressed in brown sitting : [0.318, 0.819, 0.442, 0.965]\nthe green bushes beside the woman: [0.689, 0.547, 0.998, 0.998]\nhair of the woman: [0.223, 0.674, 0.3, 0.699]\nA dark haired woman in a colorful top : [0.12, 0.664, 0.365, 0.95]\nthe woman is squinting: [0.116, 0.661, 0.369, 0.998]\na woman is walking: [0.101, 0.652, 0.365, 0.998]\nthe man is wearing a white shirt.: [0.438, 0.775, 0.506, 0.844]\nA man wearing a blue shirt : [0.421, 0.746, 0.517, 0.866]\n\n<man: [0.29, 0.823, 0.463, 0.963]> <sitting on> <bench: [0.066, 0.895, 0.408, 0.989]>\n", "response": "Task: What object is the man sitting on at the <Region>[0.066, 0.895, 0.408, 0.989]</Region>?\nOutput: The man is sitting on a bench.", "instruction": "What object is the man sitting on at the <Region>[0.066, 0.895, 0.408, 0.989]</Region>?", "input": "", "output": "The man is sitting on a bench.", "is_classification": false, "dataset": "VG", "img_info": "947.jpg"}
{"img_id": 4450, "query": "boy in white shirt and blue shorts on bike: [0.42, 0.319, 0.56, 0.86]\nA wall on the side of a building: [0.358, 0.272, 0.452, 0.449]\nthe boy is wearing shorts: [0.237, 0.335, 0.44, 0.905]\nA girl pushing a bicycle. : [0.635, 0.309, 0.852, 0.919]\nA wall on the side of a building: [0.358, 0.272, 0.452, 0.449]\ngirl pushing an adult sized bicycle : [0.62, 0.363, 0.822, 0.902]\nground of debri in city slum: [0.009, 0.316, 0.994, 0.974]\nboy in white shirt and blue shorts on bike: [0.42, 0.319, 0.56, 0.86]\nA girl wearing an overall jean dress.: [0.723, 0.342, 0.811, 0.884]\nThe boy riding the bike.: [0.42, 0.323, 0.563, 0.774]\n\n<girl: [0.62, 0.36, 0.823, 0.9]> <walking on> <ground: [0.012, 0.36, 0.988, 0.988]>\n<girl: [0.62, 0.36, 0.823, 0.9]> <pushing> <bike: [0.595, 0.36, 0.795, 0.884]>\n<boy: [0.423, 0.316, 0.557, 0.877]> <riding> <bike: [0.423, 0.316, 0.557, 0.877]>\n<boy: [0.229, 0.337, 0.405, 0.895]> <WEARING> <shorts: [0.263, 0.584, 0.398, 0.812]>\n<wall: [0.514, 0.072, 0.82, 0.507]> <beside> <people: [0.458, 0.072, 0.766, 0.451]>\n<man: [0.334, 0.198, 0.423, 0.405]> <wears> <shirt: [0.334, 0.198, 0.423, 0.405]>\n", "response": "Task: What is the girl in <Region>[0.62, 0.36, 0.823, 0.9]</Region> pushing?\nOutput: The girl is pushing a bicycle.", "instruction": "What is the girl in <Region>[0.62, 0.36, 0.823, 0.9]</Region> pushing?", "input": "", "output": "The girl is pushing a bicycle.", "is_classification": false, "dataset": "VG", "img_info": "4450.jpg"}
{"img_id": 1592393, "query": "blue flag hanging on a pole: [0.647, 0.197, 0.687, 0.33]\nblue flag hanging on a pole: [0.558, 0.297, 0.583, 0.373]\nblue flag hanging on a pole: [0.55, 0.331, 0.57, 0.39]\nblue banner hanging down: [0.637, 0.187, 0.69, 0.326]\n\n<banner: [0.627, 0.14, 0.706, 0.427]> <hanging on> <pole: [0.689, 0.192, 0.705, 0.455]>\n", "response": "Task: What is hanging on the <Region>[0.689, 0.192, 0.705, 0.455]</Region>?\nOutput: A blue banner is hanging on the pole located at the given region.", "instruction": "What is hanging on the <Region>[0.689, 0.192, 0.705, 0.455]</Region>?", "input": "", "output": "A blue banner is hanging on the pole located at the given region.", "is_classification": false, "dataset": "VG", "img_info": "1592393.jpg"}
{"img_id": 713205, "query": "red hat on man: [0.524, 0.324, 0.545, 0.346]\nthe backpack is black: [0.159, 0.394, 0.283, 0.536]\nthe people are riding a motorcycle: [0.108, 0.19, 0.438, 0.688]\nred helmet on person's head: [0.278, 0.185, 0.372, 0.312]\nthere is a man and woman on the motorcycle: [0.122, 0.216, 0.496, 0.908]\nThe woman has on a pink head wrap: [0.178, 0.233, 0.38, 0.784]\na man wearing a white shirt on a motorcycle: [0.491, 0.319, 0.566, 0.527]\nThe woman has on a black backpack: [0.181, 0.221, 0.369, 0.77]\na man wearing a red helmet: [0.27, 0.176, 0.456, 0.759]\na woman dressed in pink riding a motorcycle: [0.175, 0.221, 0.416, 0.795]\n\n<person: [0.278, 0.157, 0.46, 0.462]> <riding on> <motorcycle: [0.198, 0.534, 0.487, 0.927]>\n<person: [0.187, 0.225, 0.411, 0.774]> <has a> <backpack: [0.139, 0.351, 0.393, 0.661]>\n<head: [0.279, 0.189, 0.365, 0.285]> <OF> <person: [0.283, 0.189, 0.446, 0.775]>\n<man: [0.461, 0.287, 0.604, 0.532]> <WEARING> <red hat: [0.511, 0.322, 0.555, 0.347]>\n", "response": "Task: What color is the backpack that the person in <Region>[0.187, 0.225, 0.411, 0.774]</Region> has?\nOutput: The backpack is black.", "instruction": "What color is the backpack that the person in <Region>[0.187, 0.225, 0.411, 0.774]</Region> has?", "input": "", "output": "The backpack is black.", "is_classification": false, "dataset": "VG", "img_info": "713205.jpg"}
{"img_id": 2441, "query": "hand holding a camera: [0.253, 0.659, 0.335, 0.786]\nhand holding a lens of a camera: [0.821, 0.499, 0.998, 0.7]\nman wearing sunglasses: [0.142, 0.377, 0.229, 0.574]\nTwo people holding up a flag: [0.251, 0.139, 0.659, 0.606]\nA lens on a camera.: [0.838, 0.471, 0.995, 0.7]\nhand holding a camera: [0.253, 0.659, 0.335, 0.786]\nred, yellow, and green flag: [0.438, 0.174, 0.589, 0.381]\nletter r in a star: [0.834, 0.298, 0.901, 0.415]\nhand holding a lens of a camera: [0.821, 0.499, 0.998, 0.7]\nman holding up a flag: [0.426, 0.159, 0.667, 0.867]\n\n<star: [0.492, 0.268, 0.52, 0.325]> <in middle of> <flag: [0.425, 0.165, 0.598, 0.379]>\n<sunglasses: [0.136, 0.398, 0.228, 0.46]> <are on> <head: [0.135, 0.386, 0.236, 0.559]>\n<hand: [0.865, 0.527, 0.968, 0.762]> <holding q> <camera: [0.792, 0.473, 0.999, 0.722]>\n<hand: [0.284, 0.707, 0.33, 0.78]> <holding> <camera: [0.263, 0.675, 0.335, 0.765]>\n", "response": "Task: What is the object being held in <Region>[0.821, 0.499, 0.998, 0.7]</Region>?\nOutput: The object being held is a camera lens.", "instruction": "What is the object being held in <Region>[0.821, 0.499, 0.998, 0.7]</Region>?", "input": "", "output": "The object being held is a camera lens.", "is_classification": false, "dataset": "VG", "img_info": "2441.jpg"}
{"img_id": 713765, "query": "A wall on the side of a building: [0.358, 0.342, 0.452, 0.497]\nA window on a building.: [0.36, 0.449, 0.392, 0.52]\nwhite lines on road: [0.674, 0.745, 0.879, 0.885]\nA window on a building.: [0.314, 0.569, 0.405, 0.625]\nlarge red brick building: [0.004, 0.345, 0.447, 0.738]\nA window on a building.: [0.244, 0.439, 0.279, 0.516]\nthe window of the building: [0.903, 0.539, 0.919, 0.599]\nA window on a building.: [0.076, 0.418, 0.121, 0.499]\nA window on a building.: [0.314, 0.569, 0.405, 0.625]\nlettering is on the building: [0.186, 0.526, 0.399, 0.568]\n\n<window: [0.319, 0.451, 0.36, 0.544]> <on a> <building: [0.009, 0.341, 0.439, 0.708]>\n<lights: [0.538, 0.596, 0.6, 0.648]> <for> <crossing: [0.591, 0.701, 0.971, 0.753]>\n<window: [0.205, 0.436, 0.239, 0.513]> <adorning> <building: [0.009, 0.341, 0.439, 0.708]>\n<building: [0.011, 0.311, 0.494, 0.788]> <made of> <bricks: [0.074, 0.388, 0.252, 0.613]>\n<lines: [0.834, 0.871, 0.999, 0.923]> <painted on> <road: [0.492, 0.719, 0.999, 0.997]>\n", "response": "Task: What object is at <Region>[0.186, 0.526, 0.399, 0.568]</Region> and what is on it?\nOutput: There is lettering on the building.", "instruction": "What object is at <Region>[0.186, 0.526, 0.399, 0.568]</Region> and what is on it?", "input": "", "output": "There is lettering on the building.", "is_classification": false, "dataset": "VG", "img_info": "713765.jpg"}
{"img_id": 612, "query": "window of a car: [0.251, 0.628, 0.294, 0.673]\nGreen pull cart on street.: [0.738, 0.533, 0.998, 0.77]\nThe headlights of the taxi are on.: [0.3, 0.665, 0.396, 0.705]\nmetal pole with traffic lights attached : [0.482, 0.43, 0.546, 0.627]\nan advertisement on a lamp pole: [0.033, 0.065, 0.159, 0.375]\na black car driving down the street: [0.424, 0.595, 0.736, 0.818]\na red light signal on pole: [0.472, 0.438, 0.546, 0.545]\na red light signal on pole: [0.472, 0.438, 0.546, 0.545]\nyellow taxi cab driving on the road: [0.235, 0.61, 0.391, 0.73]\nwindow of a car: [0.472, 0.623, 0.529, 0.67]\n\n<buidling: [0.024, 0.27, 0.102, 0.52]> <behind> <pole: [0.03, 0.0, 0.069, 0.637]>\n<pole: [0.03, 0.0, 0.069, 0.637]> <in front of> <person: [0.004, 0.555, 0.146, 0.997]>\n<taxi: [0.236, 0.613, 0.386, 0.725]> <following> <car: [0.427, 0.625, 0.711, 0.782]>\n", "response": "Task: What is the object located behind the <Region>[0.03, 0.0, 0.069, 0.637]</Region>? What object is in front of the pole in this region?\nOutput: The object behind the pole is a building. In front of the pole in this region is a person.", "instruction": "What is the object located behind the <Region>[0.03, 0.0, 0.069, 0.637]</Region>? What object is in front of the pole in this region?", "input": "", "output": "The object behind the pole is a building. In front of the pole in this region is a person.", "is_classification": false, "dataset": "VG", "img_info": "612.jpg"}
{"img_id": 1159781, "query": "grey saddle bags on a bicycle: [0.267, 0.709, 0.535, 0.996]\nwhite plastic shopping bag is bulging: [0.785, 0.508, 0.867, 0.654]\nman has green bag: [0.098, 0.558, 0.24, 0.799]\ngreen bag over man's shoulders: [0.057, 0.549, 0.211, 0.765]\nwhite plastic bag on top of fruit: [0.769, 0.483, 0.899, 0.67]\nman with pocketed shoulder bag on back: [0.007, 0.132, 0.199, 0.978]\n\n<bag: [0.061, 0.57, 0.205, 0.745]> <over> <shoulders: [0.0, 0.273, 0.19, 0.459]>\n", "response": "Task: How is the object in <Region>[0.061, 0.57, 0.205, 0.745]</Region> being carried?\nOutput: The green bag is over the man's shoulders.", "instruction": "How is the object in <Region>[0.061, 0.57, 0.205, 0.745]</Region> being carried?", "input": "", "output": "The green bag is over the man's shoulders.", "is_classification": false, "dataset": "VG", "img_info": "1159781.jpg"}
{"img_id": 713795, "query": "a person sitting down: [0.745, 0.58, 0.854, 0.768]\nyellow shirt on spectator: [0.89, 0.611, 0.998, 0.972]\na person sitting down: [0.008, 0.541, 0.164, 0.994]\nthe white top the woman is wearing: [0.138, 0.637, 0.308, 0.938]\na person sitting down: [0.902, 0.568, 0.993, 0.736]\na bottle behind a woman: [0.297, 0.835, 0.35, 0.996]\na person performing on the stage: [0.339, 0.283, 0.389, 0.375]\nperson has white top: [0.469, 0.248, 0.527, 0.425]\nblack shirt on spectator: [0.674, 0.634, 0.833, 0.975]\nwhite shirt on spectator: [0.144, 0.594, 0.333, 0.94]\n\n<person: [0.477, 0.26, 0.536, 0.453]> <performing on> <stage: [0.0, 0.364, 0.997, 0.491]>\n<boy: [0.869, 0.476, 0.997, 0.994]> <WEARING> <shirt: [0.869, 0.615, 0.993, 0.981]>\n<woman: [0.131, 0.504, 0.311, 0.994]> <holding> <umbrella: [0.081, 0.332, 0.475, 0.558]>\n", "response": "Task: What is the person in <Region>[0.477, 0.26, 0.536, 0.453]</Region> doing?\nOutput: The person in the given region is performing on stage.", "instruction": "What is the person in <Region>[0.477, 0.26, 0.536, 0.453]</Region> doing?", "input": "", "output": "The person in the given region is performing on stage.", "is_classification": false, "dataset": "VG", "img_info": "713795.jpg"}
{"img_id": 1299, "query": "trees can be seen outside : [0.008, 0.077, 0.494, 0.362]\nlamp on a table: [0.824, 0.223, 0.938, 0.428]\nlamp on a table: [0.029, 0.287, 0.123, 0.697]\ncandle holder on top of the tv armoire: [0.643, 0.079, 0.758, 0.159]\nRed boquet of flowers in a clear vase on the table. : [0.297, 0.405, 0.393, 0.572]\nlamp beside the windows: [0.514, 0.231, 0.582, 0.544]\ncoffee table in the living room : [0.252, 0.51, 0.467, 0.718]\nchair near a desk: [0.797, 0.423, 0.9, 0.636]\nlamp beside the windows: [0.514, 0.231, 0.582, 0.544]\na center table over a rug: [0.203, 0.403, 0.59, 0.972]\n\n<table: [0.256, 0.515, 0.467, 0.744]> <in center of> <rug: [0.172, 0.544, 0.783, 0.997]>\n<trees: [0.002, 0.067, 0.48, 0.323]> <seen> <outside: [0.002, 0.046, 0.523, 0.521]>\n<trees: [0.002, 0.067, 0.48, 0.323]> <outside of> <balcony: [0.0, 0.041, 0.531, 0.533]>\n<lamp: [0.523, 0.244, 0.586, 0.574]> <over> <chair: [0.473, 0.354, 0.602, 0.569]>\n<lamp: [0.523, 0.244, 0.586, 0.574]> <beside> <windows: [0.15, 0.062, 0.523, 0.528]>\n<candle holder: [0.652, 0.085, 0.76, 0.164]> <on top of> <armoire: [0.584, 0.149, 0.822, 0.659]>\n<dresser: [0.584, 0.149, 0.822, 0.659]> <against> <wall: [0.566, 0.003, 1.0, 0.697]>\n", "response": "Task: What is the object that is against the wall in <Region>[0.566, 0.003, 1.0, 0.697]</Region>?\nOutput: The object that is against the wall is a dresser.", "instruction": "What is the object that is against the wall in <Region>[0.566, 0.003, 1.0, 0.697]</Region>?", "input": "", "output": "The object that is against the wall is a dresser.", "is_classification": false, "dataset": "VG", "img_info": "1299.jpg"}
{"img_id": 1159676, "query": "Crowds in the field.: [0.736, 0.078, 0.972, 0.161]\nthe man is wearing a blue shirt.: [0.43, 0.259, 0.757, 0.486]\nthe woman is wearinf blue jeans.: [0.698, 0.086, 0.76, 0.342]\nhe is checking the kite : [0.437, 0.165, 0.801, 0.934]\nWoman wearing blue jeans.: [0.687, 0.173, 0.756, 0.336]\nthe woman is wearing a gray tank top.: [0.69, 0.079, 0.774, 0.346]\na man working on a kite: [0.223, 0.208, 0.831, 0.832]\na man with a blue shirt: [0.476, 0.251, 0.688, 0.434]\npeople casting shadows over the lawn: [0.654, 0.242, 0.819, 0.323]\nGreen grass in the field.: [0.1, 0.743, 0.302, 0.927]\n\n<boy: [0.526, 0.09, 0.561, 0.186]> <carries> <bag: [0.544, 0.147, 0.563, 0.176]>\n<couple: [0.385, 0.076, 0.44, 0.199]> <walking across> <field: [0.003, 0.1, 0.998, 0.97]>\n<people: [0.597, 0.079, 0.762, 0.345]> <casting> <people: [0.688, 0.254, 0.827, 0.339]>\n<people: [0.688, 0.254, 0.827, 0.339]> <over> <field: [0.003, 0.1, 0.998, 0.97]>\n<litter: [0.306, 0.259, 0.336, 0.294]> <thrown on> <field: [0.003, 0.1, 0.998, 0.97]>\n<child: [0.084, 0.113, 0.109, 0.168]> <WEARING> <shirt: [0.09, 0.135, 0.099, 0.156]>\n<man: [0.469, 0.225, 0.606, 0.438]> <wearing a> <t-shirt: [0.465, 0.225, 0.737, 0.462]>\n<man: [0.428, 0.258, 0.757, 0.688]> <working on> <kite: [0.23, 0.358, 0.822, 0.823]>\n<belt: [0.638, 0.285, 0.725, 0.423]> <attached to> <jeans: [0.621, 0.315, 0.753, 0.708]>\n", "response": "Task: What is the man in <Region>[0.428, 0.258, 0.757, 0.688]</Region> doing?\nOutput: He is working on the kite.", "instruction": "What is the man in <Region>[0.428, 0.258, 0.757, 0.688]</Region> doing?", "input": "", "output": "He is working on the kite.", "is_classification": false, "dataset": "VG", "img_info": "1159676.jpg"}
{"img_id": 4657, "query": "The window in the room.: [0.631, 0.003, 0.996, 0.591]\nthe curtain hanging over the window: [0.638, 0.035, 0.778, 0.608]\nthe window behind the curtains: [0.68, 0.147, 0.936, 0.564]\ngrey panels on a window: [0.62, 0.005, 0.985, 0.54]\nThe drapes are covering the window: [0.625, 0.025, 0.951, 0.714]\n\n<drapes: [0.625, 0.03, 0.982, 0.578]> <are covering> <window: [0.653, 0.074, 0.813, 0.548]>\n", "response": "Task: What is the object that is located behind the object in <Region>[0.638, 0.035, 0.778, 0.608]</Region>?\nOutput: The object behind the curtains is a window.", "instruction": "What is the object that is located behind the object in <Region>[0.638, 0.035, 0.778, 0.608]</Region>?", "input": "", "output": "The object behind the curtains is a window.", "is_classification": false, "dataset": "VG", "img_info": "4657.jpg"}
{"img_id": 713232, "query": "A person is standing up: [0.049, 0.021, 0.164, 0.374]\nA person in a blue jacket with her back turned away from the bears: [0.387, 0.079, 0.486, 0.383]\npads on bear paw: [0.544, 0.261, 0.619, 0.389]\nperson watching two bears play: [0.255, 0.17, 0.296, 0.357]\ntwo reclined polar bears: [0.046, 0.175, 0.995, 0.836]\nman is wearing black hat: [0.339, 0.085, 0.386, 0.142]\nA group of people looking at the polar bears: [0.03, 0.062, 0.887, 0.254]\nSnow on green leaves.: [0.927, 0.021, 0.989, 0.104]\nthe person has back turned: [0.397, 0.032, 0.521, 0.322]\nsnow on tree limbs: [0.376, 0.006, 0.817, 0.197]\n\n<bear: [0.04, 0.267, 0.532, 0.768]> <have a> <shadow: [0.421, 0.702, 0.744, 0.836]>\n<polar bear: [0.053, 0.311, 0.549, 0.734]> <playing with> <polar bear: [0.504, 0.156, 0.994, 0.808]>\n<woman: [0.578, 0.073, 0.654, 0.231]> <wearing a> <cap: [0.604, 0.076, 0.636, 0.106]>\n<person: [0.389, 0.05, 0.492, 0.327]> <WEARING> <jacket: [0.399, 0.063, 0.495, 0.32]>\n<snow: [0.9, 0.162, 0.967, 0.182]> <on green> <leaves: [0.888, 0.304, 0.969, 0.317]>\n<railing: [0.183, 0.138, 0.597, 0.345]> <behind> <bears: [0.166, 0.223, 0.878, 0.742]>\n<man: [0.383, 0.079, 0.489, 0.333]> <turned away from> <bears: [0.025, 0.261, 0.696, 0.767]>\n<bear: [0.04, 0.267, 0.532, 0.767]> <looking at> <bear: [0.384, 0.169, 0.996, 0.827]>\n", "response": "Task: What is the relationship between the object in <Region>[0.387, 0.079, 0.486, 0.383]</Region> and the object in <Region>[0.025, 0.261, 0.696, 0.767]</Region>?\nOutput: The person in the blue jacket with her back turned away is looking at the two polar bears playing.", "instruction": "What is the relationship between the object in <Region>[0.387, 0.079, 0.486, 0.383]</Region> and the object in <Region>[0.025, 0.261, 0.696, 0.767]</Region>?", "input": "", "output": "The person in the blue jacket with her back turned away is looking at the two polar bears playing.", "is_classification": false, "dataset": "VG", "img_info": "713232.jpg"}
{"img_id": 1593154, "query": "man wearing a blue tie : [0.375, 0.292, 0.413, 0.523]\nsunglasses on her face: [0.836, 0.184, 0.921, 0.262]\nblack neck tie worn by a boy: [0.164, 0.355, 0.26, 0.708]\nboy has black glasses: [0.338, 0.154, 0.438, 0.295]\nblack uneven glasses on his face: [0.312, 0.164, 0.404, 0.231]\nboy wearing theatrical makeup and crooked glasses: [0.314, 0.102, 0.414, 0.276]\ngreen umbrella behind boys: [0.206, 0.02, 0.479, 0.112]\na blue neck tie: [0.37, 0.29, 0.421, 0.523]\na boy with a white shirt covered with red stains on: [0.064, 0.154, 0.276, 0.997]\na boy with a white shirt covered with red stains on: [0.064, 0.154, 0.276, 0.997]\n\n<boy: [0.07, 0.19, 0.282, 0.992]> <dressed as> <boy: [0.07, 0.19, 0.282, 0.992]>\n<paint: [0.282, 0.133, 0.468, 0.363]> <on boys> <face: [0.282, 0.133, 0.468, 0.363]>\n<table: [0.696, 0.529, 0.913, 0.888]> <behind> <women: [0.399, 0.245, 0.913, 0.888]>\n<lady: [0.407, 0.277, 0.692, 0.892]> <WEARING> <hoodie: [0.407, 0.277, 0.692, 0.892]>\n<signs: [0.825, 0.008, 0.941, 0.063]> <on a> <pole: [0.825, 0.064, 0.941, 0.135]>\n<tie: [0.147, 0.352, 0.27, 0.664]> <worn by> <boy: [0.062, 0.172, 0.27, 0.663]>\n<shirt: [0.07, 0.189, 0.287, 0.863]> <covered with> <paint: [0.281, 0.133, 0.468, 0.363]>\n<boy: [0.07, 0.189, 0.287, 0.863]> <with a> <shirt: [0.07, 0.189, 0.287, 0.863]>\n", "response": "Task: What object is behind the object in <Region>[0.399, 0.245, 0.913, 0.888]</Region>?\nOutput: Behind the object, there is a table.", "instruction": "What object is behind the object in <Region>[0.399, 0.245, 0.913, 0.888]</Region>?", "input": "", "output": "Behind the object, there is a table.", "is_classification": false, "dataset": "VG", "img_info": "1593154.jpg"}
{"img_id": 498059, "query": "plane in the sky: [0.189, 0.148, 0.389, 0.281]\nGreen grass next to the runway in the airport : [0.258, 0.842, 0.709, 0.956]\ncommercial airline plane taking off from airport: [0.133, 0.149, 0.422, 0.254]\nnose of a plane: [0.192, 0.16, 0.221, 0.217]\nairplane is in the air: [0.172, 0.141, 0.397, 0.283]\nthe plane is taking off : [0.171, 0.133, 0.396, 0.321]\nairplane is in the air: [0.172, 0.141, 0.397, 0.283]\nWater next to the large runway at the airport: [0.068, 0.76, 0.536, 0.93]\nthe plane is taking off : [0.171, 0.133, 0.396, 0.321]\ncommercial airline plane taking off from airport: [0.133, 0.149, 0.422, 0.254]\n\n<wing: [0.318, 0.18, 0.403, 0.271]> <sticking off side of> <plane: [0.173, 0.123, 0.399, 0.299]>\n<nose: [0.177, 0.164, 0.228, 0.216]> <of a> <plane: [0.156, 0.101, 0.378, 0.306]>\n<tail: [0.299, 0.141, 0.358, 0.234]> <OF> <plane: [0.162, 0.132, 0.398, 0.354]>\n<airplane: [0.187, 0.172, 0.38, 0.254]> <taking off from> <airfield: [0.0, 0.883, 0.998, 0.997]>\n<item: [0.063, 0.933, 0.117, 0.991]> <on side of a> <runway: [0.046, 0.879, 0.523, 0.991]>\n", "response": "Task: What object is sticking off the side of the plane in <Region>[0.173, 0.123, 0.399, 0.299]</Region>?\nOutput: The object sticking off the side of the plane is a wing.", "instruction": "What object is sticking off the side of the plane in <Region>[0.173, 0.123, 0.399, 0.299]</Region>?", "input": "", "output": "The object sticking off the side of the plane is a wing.", "is_classification": false, "dataset": "VG", "img_info": "498059.jpg"}
{"img_id": 1881, "query": "black windows part of building: [0.32, 0.278, 0.355, 0.313]\na parked silver car: [0.355, 0.437, 0.412, 0.503]\nbeverage can on ground: [0.619, 0.762, 0.66, 0.793]\ncars driving alongside of the road: [0.194, 0.455, 0.207, 0.492]\ncar parked on side of street: [0.24, 0.418, 0.281, 0.478]\na parallel parked car: [0.2, 0.44, 0.26, 0.508]\nwindow on the building: [0.324, 0.245, 0.369, 0.275]\nutility pole with power line: [0.035, 0.003, 0.169, 0.997]\npole mounted to building infrastructure: [0.46, 0.362, 0.497, 0.513]\ntire on motor vehicle: [0.481, 0.502, 0.537, 0.597]\n\n<motor vehicle: [0.441, 0.403, 0.79, 0.585]> <backed into> <space: [0.436, 0.367, 0.909, 0.938]>\n<can: [0.61, 0.753, 0.664, 0.793]> <on top of> <ground: [0.603, 0.78, 0.705, 0.882]>\n<front grill: [0.436, 0.482, 0.472, 0.525]> <OF> <motor vehicle: [0.444, 0.397, 0.8, 0.607]>\n<pole: [0.576, 0.328, 0.599, 0.59]> <mounted to> <building: [0.395, 0.017, 0.961, 0.915]>\n<car: [0.199, 0.445, 0.265, 0.517]> <parked on side of> <street: [0.045, 0.445, 0.255, 0.915]>\n", "response": "Task: What object is located at <Region>[0.571, 0.406, 0.604, 0.449]</Region> on the ground vehicle?\nOutput: The front grill of the motor vehicle is located in the specified region.", "instruction": "What object is located at <Region>[0.571, 0.406, 0.604, 0.449]</Region> on the ground vehicle?", "input": "", "output": "The front grill of the motor vehicle is located in the specified region.", "is_classification": false, "dataset": "VG", "img_info": "1881.jpg"}
{"img_id": 498302, "query": "the water is calm: [0.628, 0.846, 0.894, 0.993]\nbuilding near the ocean: [0.92, 0.465, 0.951, 0.497]\nbuilding is color white: [0.784, 0.475, 0.813, 0.539]\nman on a surfboard: [0.63, 0.426, 0.729, 0.629]\nbuilding near the ocean: [0.003, 0.49, 0.032, 0.526]\na white person in the water: [0.442, 0.661, 0.484, 0.709]\nboat on the water: [0.637, 0.527, 0.722, 0.609]\nthe water is blue: [0.708, 0.572, 0.899, 0.967]\nman in the water: [0.426, 0.636, 0.5, 0.732]\nlarge white cabin cruiser on the blue water: [0.213, 0.346, 0.575, 0.554]\n\n<man: [0.534, 0.532, 0.558, 0.584]> <holding> <sail: [0.547, 0.449, 0.625, 0.587]>\n<building: [0.699, 0.489, 0.757, 0.527]> <behind> <water: [0.007, 0.526, 0.993, 0.991]>\n", "response": "Task: What object is behind the object in <Region>[0.699, 0.489, 0.757, 0.527]</Region>?\nOutput: The building is behind the water.", "instruction": "What object is behind the object in <Region>[0.699, 0.489, 0.757, 0.527]</Region>?", "input": "", "output": "The building is behind the water.", "is_classification": false, "dataset": "VG", "img_info": "498302.jpg"}
{"img_id": 1159371, "query": "a woman on skies in the air: [0.205, 0.144, 0.693, 0.824]\nman wearing a white shirt : [0.622, 0.939, 0.683, 0.99]\nwoman wearing a wetsuit : [0.395, 0.207, 0.588, 0.561]\nwoman wearing a blue shirt : [0.843, 0.934, 0.9, 0.995]\nWoman in water skis: [0.309, 0.135, 0.633, 0.833]\nman wearing a black helmet : [0.818, 0.384, 0.876, 0.47]\na man on skies: [0.543, 0.379, 0.958, 0.832]\na man on skies in the air: [0.498, 0.388, 0.879, 0.98]\nwoman wearing tank top: [0.846, 0.891, 0.908, 0.996]\nyoung woman doing trick on water ski: [0.258, 0.134, 0.72, 0.575]\n\n<woman: [0.333, 0.15, 0.683, 0.712]> <WEARING> <helmets: [0.578, 0.072, 0.894, 0.516]>\n<man: [0.612, 0.379, 0.912, 0.88]> <holding> <rope: [0.0, 0.451, 0.749, 0.66]>\n", "response": "Task: What is the relationship between the object in <Region>[0.612, 0.379, 0.912, 0.88]</Region> and the object in <Region>[0.0, 0.451, 0.749, 0.66]</Region>?\nOutput: The man is holding the rope.", "instruction": "What is the relationship between the object in <Region>[0.612, 0.379, 0.912, 0.88]</Region> and the object in <Region>[0.0, 0.451, 0.749, 0.66]</Region>?", "input": "", "output": "The man is holding the rope.", "is_classification": false, "dataset": "VG", "img_info": "1159371.jpg"}
{"img_id": 713411, "query": "parked motorcycle is silver: [0.588, 0.671, 0.771, 0.829]\nsign is attached to the building: [0.577, 0.115, 0.621, 0.411]\nglass window on building: [0.312, 0.305, 0.327, 0.359]\nlady is walking beside the street: [0.647, 0.634, 0.722, 0.898]\nsign is attached to the building: [0.577, 0.115, 0.621, 0.411]\ngreen palm on side of road: [0.82, 0.518, 0.972, 0.997]\nman is riding a motorcycle: [0.407, 0.642, 0.476, 0.857]\nsign is on the side of the building : [0.721, 0.008, 0.82, 0.458]\nsign is attached to building: [0.132, 0.202, 0.179, 0.335]\nwoman wearing black tanktop: [0.646, 0.629, 0.721, 0.905]\n\n<man: [0.409, 0.638, 0.47, 0.823]> <WEARING> <shirt: [0.412, 0.661, 0.468, 0.76]>\n<woman: [0.659, 0.638, 0.715, 0.908]> <walking on side of> <road: [0.074, 0.598, 0.919, 0.99]>\n<motorcycle: [0.589, 0.664, 0.76, 0.806]> <parked on side of> <road: [0.0, 0.589, 0.889, 0.961]>\n<cables: [0.081, 0.009, 0.569, 0.398]> <hanging between> <buildings: [0.003, 0.001, 0.999, 0.905]>\n<car: [0.447, 0.609, 0.51, 0.689]> <in middle of> <road: [0.469, 0.697, 0.568, 0.962]>\n<man: [0.409, 0.638, 0.472, 0.845]> <riding> <motorcycle: [0.423, 0.746, 0.47, 0.826]>\n<lady: [0.645, 0.642, 0.716, 0.898]> <walking beside> <street: [0.478, 0.714, 0.606, 0.979]>\n<sign: [0.13, 0.199, 0.172, 0.329]> <attached> <building: [0.025, 0.018, 0.148, 0.716]>\n<motorcycle: [0.59, 0.663, 0.768, 0.811]> <in front of> <building: [0.69, 0.023, 0.824, 0.658]>\n<sign: [0.577, 0.116, 0.613, 0.411]> <attached to> <building: [0.569, 0.076, 0.734, 0.809]>\n<sign: [0.724, 0.021, 0.812, 0.454]> <on side of> <building: [0.653, 0.001, 0.997, 0.887]>\n", "response": "Task: What color tank top is the woman <Region>[0.646, 0.629, 0.721, 0.905]</Region> wearing?\nOutput: The woman is wearing a black tank top.", "instruction": "What color tank top is the woman <Region>[0.646, 0.629, 0.721, 0.905]</Region> wearing?", "input": "", "output": "The woman is wearing a black tank top.", "is_classification": false, "dataset": "VG", "img_info": "713411.jpg"}
{"img_id": 1591964, "query": "person watching seminar presentation: [0.717, 0.339, 0.877, 0.513]\nman wearing a vest: [0.349, 0.471, 0.746, 0.655]\nthe cheek of a man: [0.659, 0.466, 0.736, 0.519]\nperson sitting watching seminar: [0.372, 0.351, 0.856, 0.711]\nman wearing a brown and orange hat: [0.377, 0.352, 0.86, 0.715]\nthe head of a man: [0.514, 0.365, 0.74, 0.511]\nman wearing glasses: [0.26, 0.414, 0.311, 0.445]\nman's cap is orange: [0.551, 0.346, 0.736, 0.459]\nman wearing a green polo shirt: [0.273, 0.322, 0.508, 0.52]\nman's laptop is black and silver: [0.201, 0.636, 0.564, 0.866]\n\n<man: [0.382, 0.354, 0.852, 0.714]> <wearing a> <hat: [0.526, 0.346, 0.755, 0.476]>\n<person: [0.758, 0.665, 0.99, 0.992]> <sitting in> <theatre: [0.009, 0.014, 0.966, 0.997]>\n", "response": "Task: What color is the cap worn by the man in <Region>[0.526, 0.346, 0.755, 0.476]</Region>?\nOutput: The man is wearing an orange cap.", "instruction": "What color is the cap worn by the man in <Region>[0.526, 0.346, 0.755, 0.476]</Region>?", "input": "", "output": "The man is wearing an orange cap.", "is_classification": false, "dataset": "VG", "img_info": "1591964.jpg"}
{"img_id": 3468, "query": "window on a building: [0.14, 0.05, 0.151, 0.123]\nwindow on a building: [0.221, 0.49, 0.241, 0.522]\nwindow on white building facing street: [0.324, 0.122, 0.351, 0.223]\nwindow on white building facing street: [0.136, 0.053, 0.154, 0.122]\nwindow on a building: [0.325, 0.13, 0.35, 0.223]\nwindow on white building facing street: [0.27, 0.305, 0.291, 0.333]\npink building in the background: [0.91, 0.483, 0.989, 0.662]\nA window on a vehicle.: [0.49, 0.548, 0.594, 0.593]\ngreen bush at side of building: [0.911, 0.577, 0.973, 0.657]\nwindow on white building facing street: [0.278, 0.162, 0.3, 0.248]\n\n<bushes: [0.901, 0.577, 0.97, 0.657]> <beside> <sidewalk: [0.818, 0.605, 0.994, 0.725]>\n<railing: [0.21, 0.488, 0.61, 0.575]> <in front of> <building: [0.121, 0.043, 0.818, 0.66]>\n<building: [0.099, 0.023, 0.511, 0.612]> <facing> <street: [0.013, 0.605, 0.346, 0.99]>\n<window: [0.328, 0.137, 0.349, 0.223]> <on white building facing> <street: [0.025, 0.703, 0.885, 0.848]>\n<window: [0.285, 0.133, 0.343, 0.137]> <on a> <building: [0.14, 0.313, 0.425, 0.438]>\n", "response": "Task: What object is located beside the <Region>[0.121, 0.043, 0.818, 0.66]</Region>?\nOutput: There is a railing situated in front of the building.", "instruction": "What object is located beside the <Region>[0.121, 0.043, 0.818, 0.66]</Region>?", "input": "", "output": "There is a railing situated in front of the building.", "is_classification": false, "dataset": "VG", "img_info": "3468.jpg"}
{"img_id": 1621, "query": "White keyboard on desk : [0.201, 0.618, 0.472, 0.747]\na keyboard : [0.249, 0.632, 0.431, 0.725]\ncomputer monitor with black screen: [0.301, 0.375, 0.504, 0.645]\namerican flag behind computer monitor : [0.73, 0.33, 0.833, 0.612]\nA desk covered in computers and clutter: [0.048, 0.333, 0.999, 0.987]\namerican flag behind computer monitor : [0.73, 0.33, 0.833, 0.612]\nthe keyboard is white : [0.231, 0.64, 0.417, 0.735]\nTwo white computer monitors: [0.291, 0.307, 0.706, 0.675]\nblue desk lamp next to speaker : [0.096, 0.505, 0.211, 0.688]\nWhite keyboard on desk : [0.201, 0.618, 0.472, 0.747]\n\n<panels: [0.146, 0.037, 0.292, 0.448]> <are on> <wall: [0.328, 0.012, 0.599, 0.377]>\n<phone: [0.605, 0.735, 0.741, 0.807]> <sits on> <desk: [0.104, 0.52, 0.734, 0.96]>\n<door: [0.581, 0.04, 0.821, 0.425]> <behind> <monitor: [0.273, 0.307, 0.501, 0.643]>\n<keyboard: [0.237, 0.615, 0.485, 0.732]> <in front of> <monitor: [0.273, 0.307, 0.501, 0.643]>\n", "response": "Task: What is in front of the object in <Region>[0.273, 0.307, 0.501, 0.643]</Region>?\nOutput: In front of the object, there is a white keyboard.", "instruction": "What is in front of the object in <Region>[0.273, 0.307, 0.501, 0.643]</Region>?", "input": "", "output": "In front of the object, there is a white keyboard.", "is_classification": false, "dataset": "VG", "img_info": "1621.jpg"}
{"img_id": 1592894, "query": "the cheek of a woman: [0.335, 0.061, 0.377, 0.111]\nthe neck of a woman: [0.353, 0.142, 0.445, 0.227]\nA black necklace around woman's neck: [0.347, 0.158, 0.455, 0.335]\nthe mouth of a woman: [0.355, 0.082, 0.416, 0.124]\nthe neck of a woman: [0.353, 0.142, 0.445, 0.227]\nthe glasses of a woman: [0.334, 0.02, 0.43, 0.082]\nthe head of a woman: [0.327, 0.01, 0.446, 0.221]\nwoman wearing glasses: [0.312, 0.0, 0.458, 0.198]\nthe teeth of a woman: [0.377, 0.094, 0.394, 0.116]\nA necklace around a neck: [0.347, 0.15, 0.455, 0.332]\n\n<head: [0.325, 0.01, 0.439, 0.215]> <OF> <woman: [0.285, 0.01, 0.585, 0.467]>\n<necklace: [0.364, 0.177, 0.443, 0.319]> <around> <neck: [0.353, 0.15, 0.432, 0.224]>\n", "response": "Task: What object is located around the object in <Region>[0.353, 0.15, 0.432, 0.224]</Region>, and what kind of object is it?\nOutput: There is a necklace around the neck of the woman. It is a black necklace.", "instruction": "What object is located around the object in <Region>[0.353, 0.15, 0.432, 0.224]</Region>, and what kind of object is it?", "input": "", "output": "There is a necklace around the neck of the woman. It is a black necklace.", "is_classification": false, "dataset": "VG", "img_info": "1592894.jpg"}
{"img_id": 285632, "query": "white price tag in a basket of carrots: [0.241, 0.701, 0.391, 0.802]\ncarrot next to carrot at market: [0.146, 0.781, 0.218, 0.824]\ntomatoes in a blue bin: [0.497, 0.579, 0.702, 0.654]\na sign on the carrots: [0.239, 0.686, 0.412, 0.79]\na bucket of carrots: [0.204, 0.691, 0.507, 0.984]\na large orange carrot : [0.251, 0.902, 0.308, 0.997]\nbin full of brussel sprouts: [0.443, 0.616, 0.743, 0.882]\nbaby carrots in a blue plastic bin: [0.153, 0.699, 0.58, 0.993]\ncarrot next to carrot at market: [0.33, 0.872, 0.385, 0.943]\na large orange carrot: [0.261, 0.879, 0.346, 0.956]\n\n<woman: [0.371, 0.099, 0.574, 0.542]> <WEARING> <vest: [0.39, 0.22, 0.53, 0.539]>\n<carrots: [0.435, 0.513, 0.614, 0.638]> <have> <tops: [0.362, 0.47, 0.477, 0.561]>\n<bin: [0.04, 0.526, 0.756, 0.971]> <full> <sprouts: [0.482, 0.664, 0.646, 0.76]>\n<carrot: [0.246, 0.898, 0.316, 0.995]> <beside> <carrot: [0.253, 0.872, 0.353, 0.947]>\n<sign: [0.243, 0.695, 0.4, 0.831]> <for> <vegetable: [0.247, 0.785, 0.328, 0.842]>\n<head: [0.101, 0.029, 0.162, 0.21]> <behind> <pineapple: [0.04, 0.012, 0.134, 0.221]>\n<carrots: [0.247, 0.695, 0.472, 0.935]> <IN A> <bin: [0.218, 0.668, 0.562, 0.951]>\n<pineapple: [0.02, 0.021, 0.177, 0.216]> <IN FRONT OF THE> <man: [0.018, 0.065, 0.37, 0.592]>\n<bananas: [0.1, 0.014, 0.37, 0.094]> <HANGING FROM THE> <ceiling: [0.041, 0.012, 0.97, 0.026]>\n<hand: [0.787, 0.727, 0.906, 0.874]> <POINTING TO THE> <vegetables: [0.116, 0.557, 0.75, 0.952]>\n<bin: [0.141, 0.712, 0.595, 0.997]> <OF> <carrots: [0.212, 0.71, 0.548, 0.966]>\n<sign: [0.243, 0.695, 0.4, 0.831]> <ON THE> <carrots: [0.187, 0.693, 0.546, 0.947]>\n<tomatoes: [0.507, 0.591, 0.712, 0.676]> <in a> <bin: [0.481, 0.608, 0.744, 0.853]>\n<sign: [0.243, 0.695, 0.399, 0.831]> <displaying price of> <carrots: [0.187, 0.693, 0.546, 0.947]>\n", "response": "Task: What is the price tag in the vegetable <Region>[0.204, 0.691, 0.507, 0.984]</Region> bucket indicating?\nOutput: The price tag is displaying the price of the carrots in the bucket.", "instruction": "What is the price tag in the vegetable <Region>[0.204, 0.691, 0.507, 0.984]</Region> bucket indicating?", "input": "", "output": "The price tag is displaying the price of the carrots in the bucket.", "is_classification": false, "dataset": "VG", "img_info": "285632.jpg"}
{"img_id": 3382, "query": "Black tire of a white vehicle: [0.364, 0.773, 0.427, 0.872]\nSilver car parked by a field.: [0.56, 0.587, 0.83, 0.765]\ntire on the car: [0.54, 0.747, 0.605, 0.808]\ncar on the road: [0.254, 0.615, 0.589, 0.865]\ncar on the road: [0.574, 0.588, 0.835, 0.793]\ntire on the car: [0.54, 0.747, 0.605, 0.808]\ntire on the car: [0.794, 0.685, 0.828, 0.747]\nLicense plate of a vehicle: [0.216, 0.775, 0.253, 0.818]\ncar on the road: [0.574, 0.588, 0.835, 0.793]\nlight on the car: [0.304, 0.733, 0.345, 0.787]\n\n<car: [0.193, 0.643, 0.605, 0.865]> <by> <field: [0.214, 0.722, 0.943, 0.975]>\n<tire: [0.361, 0.77, 0.422, 0.863]> <on a> <car: [0.193, 0.643, 0.605, 0.865]>\n<car: [0.517, 0.54, 0.831, 0.772]> <by a> <field: [0.665, 0.663, 0.934, 0.968]>\n<mirror: [0.524, 0.693, 0.545, 0.717]> <mounted on> <car: [0.196, 0.635, 0.609, 0.865]>\n<tail light: [0.282, 0.733, 0.34, 0.777]> <of a> <car: [0.193, 0.643, 0.605, 0.865]>\n<tire: [0.361, 0.77, 0.422, 0.863]> <OF> <vehicle: [0.2, 0.59, 0.623, 0.923]>\n", "response": "Task: What is the location of the field relative to the car in <Region>[0.517, 0.54, 0.831, 0.772]</Region>?\nOutput: The car in this region is parked by the field.", "instruction": "What is the location of the field relative to the car in <Region>[0.517, 0.54, 0.831, 0.772]</Region>?", "input": "", "output": "The car in this region is parked by the field.", "is_classification": false, "dataset": "VG", "img_info": "3382.jpg"}
{"img_id": 1592775, "query": "a person in a room: [0.645, 0.393, 0.753, 0.53]\nwhite mantle above fireplace : [0.71, 0.115, 0.997, 0.242]\nboy standing beside woman: [0.652, 0.385, 0.772, 0.55]\nempty chair is white: [0.608, 0.694, 0.808, 0.859]\na person in a room: [0.82, 0.542, 0.97, 0.715]\na person in a room: [0.07, 0.334, 0.262, 0.42]\nboy standing beside woman: [0.652, 0.385, 0.772, 0.55]\nempty brown chair : [0.168, 0.772, 0.408, 0.939]\nman sitting on bean bag : [0.28, 0.485, 0.518, 0.623]\na person in a room: [0.288, 0.489, 0.478, 0.623]\n\n<person: [0.487, 0.25, 0.662, 0.542]> <standing behind> <rug: [0.43, 0.345, 0.798, 0.489]>\n<boy: [0.657, 0.384, 0.767, 0.545]> <standing beside> <person: [0.487, 0.25, 0.662, 0.542]>\n<chair: [0.605, 0.676, 0.815, 0.864]> <by> <man: [0.697, 0.53, 0.978, 0.754]>\n<man: [0.287, 0.472, 0.53, 0.647]> <sitting on> <bean bag: [0.085, 0.455, 0.468, 0.715]>\n<man: [0.752, 0.554, 0.962, 0.73]> <sitting in> <sweater: [0.785, 0.594, 0.957, 0.711]>\n", "response": "Task: Who or what is standing behind the object in <Region>[0.43, 0.345, 0.798, 0.489]</Region>?\nOutput: The person is standing behind the rug.", "instruction": "Who or what is standing behind the object in <Region>[0.43, 0.345, 0.798, 0.489]</Region>?", "input": "", "output": "The person is standing behind the rug.", "is_classification": false, "dataset": "VG", "img_info": "1592775.jpg"}
{"img_id": 216, "query": "hanging ceiling light: [0.002, 0.111, 0.17, 0.362]\nchain hanging the light from ceiling: [0.01, 0.007, 0.041, 0.127]\nthe light is hanging: [0.002, 0.002, 0.16, 0.327]\nthe sofa is light colored: [0.119, 0.487, 0.527, 0.788]\n\n<light: [0.0, 0.075, 0.217, 0.351]> <hanging from> <ceiling: [0.0, 0.005, 0.994, 0.174]>\n", "response": "Task: From where is the <Region>[0.0, 0.075, 0.217, 0.351]</Region> hanging?\nOutput: The region is hanging from the ceiling.", "instruction": "From where is the <Region>[0.0, 0.075, 0.217, 0.351]</Region> hanging?", "input": "", "output": "The region is hanging from the ceiling.", "is_classification": false, "dataset": "VG", "img_info": "216.jpg"}
{"img_id": 608, "query": "man is wearing white pants : [0.075, 0.675, 0.152, 0.848]\nAn American flag hanging over a street: [0.01, 0.023, 0.141, 0.19]\na black car in the street : [0.235, 0.552, 0.331, 0.647]\na window on the building : [0.409, 0.192, 0.431, 0.223]\nA yellow cab driving down a city street: [0.486, 0.553, 0.816, 0.782]\na flag : [0.052, 0.045, 0.142, 0.192]\nA man wearing a grey ballcap. : [0.065, 0.467, 0.16, 0.868]\nthe street is black : [0.831, 0.802, 0.938, 0.91]\nThe street. : [0.155, 0.458, 0.998, 0.993]\ntaxi on the street: [0.471, 0.502, 0.849, 0.798]\n\n<man: [0.066, 0.495, 0.16, 0.863]> <WEARING> <pants: [0.072, 0.67, 0.144, 0.852]>\n<man: [0.066, 0.495, 0.16, 0.863]> <wearing a> <hat: [0.098, 0.492, 0.126, 0.532]>\n<flag: [0.05, 0.023, 0.133, 0.185]> <above> <street: [0.181, 0.532, 0.999, 0.998]>\n<person: [0.39, 0.543, 0.414, 0.593]> <crossing> <street: [0.181, 0.532, 0.999, 0.998]>\n<building: [0.265, 0.0, 0.565, 0.543]> <has a> <window: [0.411, 0.29, 0.421, 0.313]>\n", "response": "Task: Is the man in <Region>[0.066, 0.495, 0.16, 0.863]</Region> wearing a hat in the image?\nOutput: Yes, he is wearing a grey baseball cap.", "instruction": "Is the man in <Region>[0.066, 0.495, 0.16, 0.863]</Region> wearing a hat in the image?", "input": "", "output": "Yes, he is wearing a grey baseball cap.", "is_classification": false, "dataset": "VG", "img_info": "608.jpg"}
{"img_id": 61600, "query": "the man is wearing snow ski gear: [0.079, 0.019, 0.873, 0.961]\nskier wearing reflective goggles: [0.448, 0.187, 0.467, 0.222]\ngoggles are on face: [0.438, 0.172, 0.468, 0.226]\nthe man has a backpack on: [0.354, 0.234, 0.59, 0.68]\nPair of ski boots on a man's feet: [0.369, 0.645, 0.476, 0.763]\nhead of man skiing with orange goggles: [0.444, 0.154, 0.486, 0.272]\nSki goggles on a person's head.: [0.439, 0.174, 0.487, 0.234]\nman with backpack and poles skiing: [0.234, 0.154, 0.542, 0.826]\nman has red goggles: [0.437, 0.191, 0.466, 0.224]\nman is wearing skiing shoes: [0.249, 0.647, 0.515, 0.807]\n\n<man: [0.241, 0.139, 0.61, 0.859]> <wears> <goggles: [0.445, 0.191, 0.468, 0.226]>\n", "response": "Task: What object is the man in <Region>[0.241, 0.139, 0.61, 0.859]</Region> wearing?\nOutput: The man is wearing goggles.", "instruction": "What object is the man in <Region>[0.241, 0.139, 0.61, 0.859]</Region> wearing?", "input": "", "output": "The man is wearing goggles.", "is_classification": false, "dataset": "VG", "img_info": "61600.jpg"}
{"img_id": 285913, "query": "man on white surfboard in number ten shirt: [0.272, 0.138, 0.771, 0.544]\nA clear blue sky: [0.005, 0.148, 0.996, 0.771]\na man with wavy hair: [0.34, 0.142, 0.772, 0.504]\nman in orange shirt on white surfboard: [0.272, 0.141, 0.767, 0.563]\nman on white surfboard in number ten shirt: [0.272, 0.138, 0.771, 0.544]\na water skiing rope: [0.747, 0.009, 0.976, 0.287]\nman on white surfboard in air over ocean: [0.147, 0.04, 0.923, 0.99]\na clear blue ocean: [0.0, 0.764, 0.998, 0.994]\nman on white surfboard : [0.26, 0.133, 0.778, 0.566]\na man wearing black shorts: [0.348, 0.139, 0.762, 0.51]\n\n<man: [0.342, 0.136, 0.771, 0.516]> <WEARING> <shorts: [0.425, 0.283, 0.517, 0.381]>\n<hair: [0.602, 0.136, 0.701, 0.261]> <belonging to> <man: [0.351, 0.13, 0.771, 0.509]>\n<man: [0.352, 0.106, 0.806, 0.553]> <INTO A> <board: [0.273, 0.356, 0.587, 0.55]>\n<man: [0.342, 0.136, 0.771, 0.516]> <holding> <handle: [0.733, 0.204, 0.802, 0.287]>\n<ocean: [0.0, 0.77, 0.997, 0.999]> <SPLASHED UP FROM> <board: [0.299, 0.422, 0.346, 0.503]>\n<man: [0.342, 0.136, 0.771, 0.516]> <STANDING ON> <board: [0.313, 0.425, 0.35, 0.553]>\n<sky: [0.297, 0.04, 0.462, 0.282]> <above> <water: [0.434, 0.887, 0.565, 0.944]>\n<man: [0.342, 0.136, 0.771, 0.516]> <FLYING ABOVE> <water: [0.51, 0.78, 0.673, 0.959]>\n<man: [0.342, 0.136, 0.771, 0.516]> <holding onto> <handle: [0.739, 0.223, 0.77, 0.284]>\n<handle: [0.749, 0.213, 0.765, 0.299]> <connected to> <wires: [0.758, 0.029, 0.919, 0.274]>\n<man: [0.342, 0.136, 0.771, 0.516]> <in air on> <board: [0.254, 0.302, 0.582, 0.559]>\n", "response": "Task: What is the relationship between the object in <Region>[0.342, 0.136, 0.771, 0.516]</Region> and the object in <Region>[0.749, 0.213, 0.765, 0.299]</Region>?\nOutput: The handle is being held by the man in the given region.", "instruction": "What is the relationship between the object in <Region>[0.342, 0.136, 0.771, 0.516]</Region> and the object in <Region>[0.749, 0.213, 0.765, 0.299]</Region>?", "input": "", "output": "The handle is being held by the man in the given region.", "is_classification": false, "dataset": "VG", "img_info": "285913.jpg"}
{"img_id": 285860, "query": "Computer monitor displays a frog.: [0.087, 0.009, 0.425, 0.37]\nWhite corded landline phone.: [0.377, 0.507, 0.511, 0.698]\nComputer monitor displays a frog.: [0.087, 0.009, 0.425, 0.37]\nBlack laptop is open: [0.495, 0.336, 0.981, 0.988]\na dark circular mouse pad: [0.308, 0.751, 0.507, 0.889]\nBlack laptop sitting on top of desk.: [0.489, 0.346, 0.906, 0.987]\na dark circular mouse pad: [0.308, 0.751, 0.507, 0.889]\na calendar on the wall: [0.611, 0.013, 0.801, 0.323]\nCalender on back wall.: [0.596, 0.003, 0.811, 0.322]\na laptop on a desk: [0.498, 0.344, 0.971, 0.97]\n\n<a: [0.481, 0.333, 0.879, 0.708]> <laptop on a> <desk: [0.169, 0.919, 0.992, 1.0]>\n<a: [0.569, 0.139, 0.845, 0.318]> <calendar on> <wall: [0.814, 0.264, 0.948, 0.307]>\n<a: [0.002, 0.188, 0.316, 0.574]> <paper hanging on> <wall: [0.062, 0.598, 0.305, 0.827]>\n<cord: [0.379, 0.638, 0.485, 0.729]> <white phone> <cord: [0.403, 0.638, 0.442, 0.717]>\n<a: [0.809, 0.134, 0.86, 0.185]> <post it note on> <wall: [0.854, 0.27, 0.899, 0.301]>\n<an: [0.272, 0.536, 0.341, 0.684]> <ipod on> <desk: [0.0, 0.582, 0.509, 1.0]>\n<monitor: [0.497, 0.337, 0.871, 0.741]> <of a black> <laptop: [0.562, 0.483, 0.729, 0.622]>\n<oddsandends: [0.006, 0.608, 0.519, 0.879]> <cover> <desk: [0.042, 0.531, 0.882, 0.918]>\n<monitor: [0.08, 0.068, 0.427, 0.387]> <displays> <frog: [0.127, 0.121, 0.252, 0.324]>\n<a: [0.013, 0.217, 0.314, 0.491]> <hangs on> <wall: [0.002, 0.004, 0.998, 0.617]>\n<mouse pad: [0.31, 0.742, 0.517, 0.904]> <sits on> <desk: [0.006, 0.556, 0.985, 0.996]>\n<note: [0.464, 0.258, 0.529, 0.318]> <scribbled on> <wall: [0.109, 0.004, 0.985, 0.618]>\n<keys: [0.063, 0.708, 0.146, 0.771]> <on a> <keyboard: [0.0, 0.66, 0.334, 0.895]>\n", "response": "Task: What is hanging on the <Region>[0.002, 0.004, 0.998, 0.617]</Region> wall?\nOutput: There is a calendar and a note scribbled on the wall.", "instruction": "What is hanging on the <Region>[0.002, 0.004, 0.998, 0.617]</Region> wall?", "input": "", "output": "There is a calendar and a note scribbled on the wall.", "is_classification": false, "dataset": "VG", "img_info": "285860.jpg"}
{"img_id": 2391599, "query": "the bed is king size : [0.23, 0.817, 0.944, 0.991]\nA dark bedroom : [0.234, 0.24, 0.974, 0.961]\nStriped pillow laying on bed: [0.406, 0.505, 0.494, 0.622]\nthe laptop on the bed: [0.284, 0.586, 0.448, 0.751]\nPicture of woman on wall: [0.518, 0.228, 0.554, 0.336]\nEnd section of bed: [0.056, 0.781, 0.9, 0.991]\na white bed sheet.: [0.164, 0.673, 0.628, 0.829]\nWoman laying on bed: [0.456, 0.532, 0.604, 0.775]\nthe pillow on the bed: [0.388, 0.514, 0.496, 0.652]\nthe bed is wrinkled : [0.516, 0.778, 0.78, 0.949]\n\n<woman: [0.416, 0.508, 0.658, 0.826]> <on top of> <bed: [0.046, 0.541, 0.934, 1.0]>\n", "response": "Task: Who or what is on top of the <Region>[0.046, 0.541, 0.934, 1.0]</Region>?\nOutput: A woman is on top of the bed.", "instruction": "Who or what is on top of the <Region>[0.046, 0.541, 0.934, 1.0]</Region>?", "input": "", "output": "A woman is on top of the bed.", "is_classification": false, "dataset": "VG", "img_info": "2391599.jpg"}
{"img_id": 107980, "query": "several adult sheep grazing: [0.009, 0.463, 0.867, 0.489]\nTwo sheep in a meadow.: [0.257, 0.513, 0.618, 0.688]\nA sheep grazing alone.: [0.098, 0.467, 0.171, 0.509]\nclump of trees in middle distance: [0.007, 0.137, 0.578, 0.482]\ngroup of trees in the background: [0.004, 0.162, 0.53, 0.468]\nHillside with trees.: [0.579, 0.393, 0.978, 0.477]\nTwo sheep on a grassy knoll: [0.64, 0.33, 0.993, 0.598]\nTwo trees are in the corner.: [0.915, 0.399, 0.999, 0.489]\ntrees and shrubs in far distance: [0.585, 0.379, 0.99, 0.454]\nTwo sheep are white: [0.236, 0.508, 0.637, 0.695]\n\n<trees: [0.007, 0.144, 0.999, 0.481]> <behind> <sheep: [0.007, 0.467, 0.958, 0.697]>\n", "response": "Task: What is the relationship between the objects in <Region>[0.007, 0.144, 0.999, 0.481]</Region> and the objects in <Region>[0.007, 0.467, 0.958, 0.697]</Region>?\nOutput: The trees are behind the sheep in the image.", "instruction": "What is the relationship between the objects in <Region>[0.007, 0.144, 0.999, 0.481]</Region> and the objects in <Region>[0.007, 0.467, 0.958, 0.697]</Region>?", "input": "", "output": "The trees are behind the sheep in the image.", "is_classification": false, "dataset": "VG", "img_info": "107980.jpg"}
{"img_id": 4094, "query": " a tile in a floor : [0.344, 0.733, 0.425, 0.798]\nthe tv is black and silver: [0.0, 0.312, 0.22, 0.59]\n a tile in a floor : [0.381, 0.81, 0.481, 0.883]\n a tile in a floor : [0.369, 0.779, 0.444, 0.838]\nThe dresser is made of wood: [0.38, 0.448, 0.68, 0.817]\nmirror on the wall: [0.4, 0.196, 0.592, 0.485]\nlarge dresser mirror with wood frame: [0.422, 0.252, 0.581, 0.512]\ntwo ugly flower pattern bed pillows: [0.766, 0.565, 0.998, 0.752]\n a tile in a floor : [0.403, 0.873, 0.511, 0.942]\nmirror on the wall: [0.4, 0.196, 0.592, 0.485]\n\n<mirror: [0.406, 0.248, 0.603, 0.517]> <above> <dresser: [0.391, 0.504, 0.67, 0.752]>\n<dresser: [0.391, 0.504, 0.67, 0.752]> <under> <mirror: [0.406, 0.248, 0.603, 0.517]>\n<floor: [0.191, 0.704, 0.602, 0.996]> <underneath> <comforter: [0.478, 0.629, 1.0, 1.0]>\n<pillows: [0.789, 0.56, 0.995, 0.731]> <on top of> <comforter: [0.478, 0.629, 1.0, 1.0]>\n<tv: [0.006, 0.306, 0.233, 0.575]> <across from> <comforter: [0.478, 0.629, 1.0, 1.0]>\n<mirror: [0.406, 0.248, 0.603, 0.517]> <above wooden> <dresser: [0.391, 0.504, 0.67, 0.752]>\n", "response": "Task: What object is above the object in <Region>[0.391, 0.504, 0.67, 0.752]</Region>? What is the material of this object?\nOutput: The object above the dresser is a mirror, and it has a wooden frame.", "instruction": "What object is above the object in <Region>[0.391, 0.504, 0.67, 0.752]</Region>? What is the material of this object?", "input": "", "output": "The object above the dresser is a mirror, and it has a wooden frame.", "is_classification": false, "dataset": "VG", "img_info": "4094.jpg"}
{"img_id": 2393050, "query": "an older woman wearing black: [0.679, 0.138, 0.762, 0.384]\na woman wearing a black and white striped dress: [0.244, 0.184, 0.572, 0.718]\nwoman wearing black dress: [0.679, 0.16, 0.772, 0.378]\na woman with blonde hair.: [0.338, 0.184, 0.5, 0.358]\nA cement section of a building.: [0.0, 0.456, 0.277, 0.898]\nwoman wearing black dress: [0.679, 0.16, 0.772, 0.378]\na woman dressed in black.: [0.641, 0.146, 0.782, 0.39]\na woman in a zebra stripe dress.: [0.331, 0.198, 0.508, 0.808]\na young woman pulling a backpack: [0.303, 0.164, 0.621, 0.974]\na hand clutching a purse strap: [0.733, 0.204, 0.772, 0.228]\n\n<woman: [0.251, 0.194, 0.513, 0.804]> <carries> <luggage: [0.374, 0.546, 0.628, 0.954]>\n<doorway: [0.751, 0.086, 0.777, 0.194]> <to> <building: [0.618, 0.006, 0.862, 0.366]>\n<woman: [0.251, 0.194, 0.513, 0.804]> <WEARING> <dress: [0.338, 0.31, 0.51, 0.556]>\n<hand: [0.731, 0.206, 0.751, 0.224]> <clutches> <strap: [0.736, 0.19, 0.756, 0.232]>\n", "response": "Task: What is the person in <Region>[0.251, 0.194, 0.513, 0.804]</Region> wearing?\nOutput: The person is wearing a dress.", "instruction": "What is the person in <Region>[0.251, 0.194, 0.513, 0.804]</Region> wearing?", "input": "", "output": "The person is wearing a dress.", "is_classification": false, "dataset": "VG", "img_info": "2393050.jpg"}
{"img_id": 3254, "query": "A wall on the side of a building: [0.016, 0.49, 0.372, 0.837]\nwindow on a building: [0.469, 0.662, 0.496, 0.725]\nThe tan building: [0.046, 0.44, 0.889, 0.8]\nwindow on a building: [0.339, 0.378, 0.351, 0.42]\nwindow on a building: [0.453, 0.372, 0.46, 0.408]\nwindow on a building: [0.27, 0.642, 0.301, 0.722]\nThe pointy building: [0.223, 0.252, 0.525, 0.48]\nA pointy building: [0.236, 0.227, 0.521, 0.468]\nA wall on the side of a building: [0.016, 0.49, 0.372, 0.837]\nwindow on a building: [0.177, 0.662, 0.201, 0.717]\n\n<wall: [0.361, 0.373, 0.634, 0.56]> <on side of> <building: [0.006, 0.298, 0.844, 0.872]>\n", "response": "Task: What object is located at the <Region>[0.361, 0.373, 0.634, 0.56]</Region> on the plane?\nOutput: There is a wall on the side of the building at the given location.", "instruction": "What object is located at the <Region>[0.361, 0.373, 0.634, 0.56]</Region> on the plane?", "input": "", "output": "There is a wall on the side of the building at the given location.", "is_classification": false, "dataset": "VG", "img_info": "3254.jpg"}
{"img_id": 1592808, "query": "man pointing to wine bottle: [0.342, 0.377, 0.648, 0.723]\nbottle of wine on the table in the winery: [0.344, 0.584, 0.391, 0.696]\nthe woman has grey hair: [0.704, 0.401, 0.943, 0.589]\nbrown wine bottles: [0.319, 0.573, 0.383, 0.665]\nA pink sleeve. : [0.001, 0.558, 0.073, 0.87]\nperson wearing a blue floral shawl: [0.691, 0.433, 0.953, 0.997]\nwine glasses on a table in the distilery: [0.388, 0.608, 0.57, 0.714]\nthe man is looking down: [0.336, 0.358, 0.641, 0.625]\nthe woman wears blue: [0.69, 0.512, 0.964, 0.974]\nthe bottles are dark: [0.322, 0.569, 0.414, 0.705]\n\n<legs: [0.311, 0.84, 0.609, 1.0]> <OF> <table: [0.211, 0.645, 0.74, 0.945]>\n<hair: [0.764, 0.417, 0.893, 0.543]> <over> <shaw: [0.686, 0.546, 0.962, 0.967]>\n<hand: [0.004, 0.417, 0.125, 0.556]> <above> <sleeve: [0.003, 0.552, 0.081, 0.903]>\n<man: [0.35, 0.395, 0.628, 0.719]> <pointing to wine> <bottle: [0.339, 0.594, 0.385, 0.692]>\n<woman: [0.699, 0.436, 0.982, 0.998]> <wearing a> <caftan: [0.785, 0.552, 0.878, 0.626]>\n", "response": "Task: What color does the woman in <Region>[0.699, 0.436, 0.982, 0.998]</Region> wear?\nOutput: The woman is wearing blue.", "instruction": "What color does the woman in <Region>[0.699, 0.436, 0.982, 0.998]</Region> wear?", "input": "", "output": "The woman is wearing blue.", "is_classification": false, "dataset": "VG", "img_info": "1592808.jpg"}
{"img_id": 713494, "query": "batter holding a black bat: [0.417, 0.381, 0.48, 0.716]\ncatcher squatting behind the batter: [0.484, 0.516, 0.592, 0.721]\nBatter at bat in a ball field: [0.418, 0.379, 0.461, 0.698]\nBatter is wearing a red helmet: [0.376, 0.296, 0.518, 0.76]\nbatters box for the batter: [0.328, 0.647, 0.78, 0.7]\ncatcher squatting behind the batter: [0.484, 0.516, 0.592, 0.721]\na person wearing a red helmet: [0.426, 0.379, 0.468, 0.432]\nbatters box for the batter: [0.328, 0.647, 0.78, 0.7]\nUmpire standing behind catcher and batter: [0.401, 0.332, 0.597, 0.754]\nbatter wearing red helmet: [0.426, 0.389, 0.466, 0.691]\n\n<helmet: [0.424, 0.382, 0.467, 0.428]> <of> <batter: [0.411, 0.372, 0.47, 0.495]>\n<batter: [0.422, 0.391, 0.468, 0.512]> <holding> <bat: [0.421, 0.309, 0.474, 0.414]>\n", "response": "Task: What color is the helmet of the <Region>[0.411, 0.372, 0.47, 0.495]</Region> in the image?\nOutput: The helmet is red.", "instruction": "What color is the helmet of the <Region>[0.411, 0.372, 0.47, 0.495]</Region> in the image?", "input": "", "output": "The helmet is red.", "is_classification": false, "dataset": "VG", "img_info": "713494.jpg"}
{"img_id": 4215, "query": "Man standing in restaurant: [0.505, 0.238, 0.703, 0.937]\nwoman wearing black V-neck shirt: [0.354, 0.276, 0.512, 0.956]\nSwivel chair at a table: [0.744, 0.619, 0.924, 0.895]\nBlack shoe on a woman: [0.384, 0.869, 0.436, 0.967]\ngray floor tile in faast food restaurant: [0.655, 0.843, 0.751, 0.951]\nMenu in a restaurant: [0.369, 0.002, 0.772, 0.086]\nwoman standing with her arms crossed: [0.353, 0.269, 0.51, 0.958]\ngray floor tile in faast food restaurant: [0.659, 0.766, 0.727, 0.846]\nthe woman has her arms crossed: [0.36, 0.292, 0.51, 0.867]\nTable in a restaurant: [0.8, 0.495, 0.991, 0.787]\n\n<woman: [0.354, 0.273, 0.516, 0.967]> <WEARING> <shirt: [0.356, 0.388, 0.518, 0.631]>\n<chair: [0.692, 0.397, 0.781, 0.519]> <at a> <table: [0.705, 0.32, 0.968, 0.904]>\n<trash bins: [0.007, 0.301, 0.375, 0.804]> <in a> <restaurant: [0.0, 0.009, 0.941, 0.991]>\n", "response": "Task: What object is on the woman in <Region>[0.384, 0.869, 0.436, 0.967]</Region>'s foot?\nOutput: A black shoe is on the woman's foot.", "instruction": "What object is on the woman in <Region>[0.384, 0.869, 0.436, 0.967]</Region>'s foot?", "input": "", "output": "A black shoe is on the woman's foot.", "is_classification": false, "dataset": "VG", "img_info": "4215.jpg"}
{"img_id": 285938, "query": "A chair with no one in front of it.: [0.706, 0.007, 0.821, 0.193]\nchair in the box on the court: [0.21, 0.094, 0.297, 0.251]\nLetter E on the blue wall: [0.128, 0.147, 0.185, 0.246]\nchair by the wall: [0.208, 0.102, 0.309, 0.267]\nwords on blue wall: [0.004, -0.001, 0.968, 0.326]\nchair in blue box: [0.713, 0.001, 0.869, 0.185]\nbook on chair seat: [0.22, 0.107, 0.302, 0.259]\n\n<chair: [0.208, 0.102, 0.312, 0.268]> <by> <wall: [0.004, 0.007, 0.969, 0.319]>\n", "response": "Task: What is the relationship between the object in <Region>[0.208, 0.102, 0.312, 0.268]</Region> and the object in <Region>[0.004, 0.007, 0.969, 0.319]</Region>?\nOutput: The chair is located by the wall with some words written on it.", "instruction": "What is the relationship between the object in <Region>[0.208, 0.102, 0.312, 0.268]</Region> and the object in <Region>[0.004, 0.007, 0.969, 0.319]</Region>?", "input": "", "output": "The chair is located by the wall with some words written on it.", "is_classification": false, "dataset": "VG", "img_info": "285938.jpg"}
{"img_id": 2873, "query": "the woman has hair: [0.378, 0.522, 0.451, 0.902]\nthe woman is walking: [0.325, 0.44, 0.466, 0.923]\nwoman in a beige dress: [0.37, 0.515, 0.456, 0.917]\na woman wearing a white outfit: [0.374, 0.498, 0.46, 0.927]\nA woman with long black hair: [0.69, 0.545, 0.78, 0.835]\nA sidewalk drain: [0.785, 0.758, 0.845, 0.813]\nthe woman wearing a shirt: [0.381, 0.525, 0.451, 0.9]\na woman wearing a white outfit: [0.374, 0.498, 0.46, 0.927]\na woman looking in her purse: [0.374, 0.505, 0.461, 0.923]\nThe woman is wearing a dress.: [0.391, 0.593, 0.453, 0.827]\n\n<people: [0.604, 0.537, 0.772, 0.807]> <walking on> <sidewalk: [0.328, 0.712, 0.816, 0.99]>\n<woman: [0.375, 0.523, 0.454, 0.9]> <WEARING> <dress: [0.38, 0.587, 0.436, 0.843]>\n<man: [0.509, 0.557, 0.569, 0.695]> <sitting on> <bike: [0.519, 0.642, 0.571, 0.702]>\n<boxes: [0.115, 0.665, 0.22, 0.96]> <in front of a> <store: [0.009, 0.01, 0.67, 0.978]>\n<woman: [0.605, 0.558, 0.688, 0.828]> <with a> <coat: [0.598, 0.625, 0.67, 0.745]>\n<man: [0.5, 0.518, 0.58, 0.717]> <holding> <bike: [0.496, 0.622, 0.579, 0.723]>\n<tree: [0.645, 0.005, 0.998, 0.62]> <in a> <plaza: [0.005, 0.01, 0.994, 0.988]>\n", "response": "Task: What is the woman doing in <Region>[0.374, 0.505, 0.461, 0.923]</Region>?\nOutput: The woman is looking in her purse.", "instruction": "What is the woman doing in <Region>[0.374, 0.505, 0.461, 0.923]</Region>?", "input": "", "output": "The woman is looking in her purse.", "is_classification": false, "dataset": "VG", "img_info": "2873.jpg"}
{"img_id": 2392020, "query": "computer is turn on: [0.022, 0.628, 0.374, 0.872]\nblack and white bedroom window: [0.37, 0.006, 0.618, 0.266]\na man laying on a bed: [0.19, 0.442, 0.942, 0.986]\nblack and white man laying on bed: [0.366, 0.466, 0.64, 0.746]\nthe laptop is open: [0.038, 0.606, 0.376, 0.834]\nblack and white man laying on bed: [0.366, 0.466, 0.64, 0.746]\nlogotype of laptop : [0.122, 0.72, 0.184, 0.776]\nperson holds his head with left hand: [0.114, 0.434, 0.458, 0.708]\nheadboard of a bed is brown: [0.078, 0.37, 0.916, 0.484]\nblack and white bed headboard: [0.522, 0.398, 0.712, 0.492]\n\n<shelf: [0.05, 0.252, 0.96, 0.344]> <above> <bed: [0.072, 0.38, 0.942, 0.99]>\n<headboard: [0.074, 0.386, 0.908, 0.466]> <OF> <bed: [0.072, 0.38, 0.942, 0.99]>\n<charger: [0.016, 0.726, 0.096, 0.772]> <for> <laptop: [0.044, 0.628, 0.384, 0.858]>\n<person: [0.19, 0.434, 0.612, 0.994]> <laying in> <bed: [0.072, 0.38, 0.942, 0.99]>\n<person: [0.19, 0.434, 0.518, 0.674]> <holds> <head: [0.218, 0.44, 0.358, 0.62]>\n<person: [0.19, 0.434, 0.612, 0.994]> <on h> <side: [0.378, 0.518, 0.588, 0.672]>\n<person: [0.19, 0.434, 0.612, 0.994]> <looks at> <computer: [0.044, 0.628, 0.384, 0.858]>\n<wires: [0.068, 0.506, 0.196, 0.608]> <connect to> <laptop: [0.044, 0.628, 0.384, 0.858]>\n", "response": "Task: What object is located above the <Region>[0.072, 0.38, 0.942, 0.99]</Region> and what object is above this object?\nOutput: A shelf is located above the bed and above the shelf is not mentioned in the description.", "instruction": "What object is located above the <Region>[0.072, 0.38, 0.942, 0.99]</Region> and what object is above this object?", "input": "", "output": "A shelf is located above the bed and above the shelf is not mentioned in the description.", "is_classification": false, "dataset": "VG", "img_info": "2392020.jpg"}
{"img_id": 3217, "query": "gray car on the street: [0.755, 0.0, 0.83, 0.028]\nthe person is walking: [0.911, 0.0, 0.965, 0.12]\ncar on the road: [0.835, 0.0, 0.93, 0.053]\nrope connecting the boat to the wall : [0.371, 0.027, 0.586, 0.248]\nNarrow dock made of wooden slats : [0.355, 0.392, 0.823, 0.988]\nMold and moss growing on the side of the wall : [0.401, 0.137, 0.998, 0.692]\na person walking on the street: [0.902, 0.0, 0.966, 0.127]\ncar on the road: [0.764, 0.005, 0.815, 0.035]\nthe moss on the wall: [0.105, 0.0, 0.996, 0.712]\nboard on the dock: [0.634, 0.752, 0.649, 0.76]\n\n<wall: [0.111, 0.002, 0.993, 0.707]> <overlooking> <sea: [0.003, 0.005, 0.996, 0.987]>\n<person: [0.902, 0.002, 0.969, 0.125]> <walking on> <road: [0.341, 0.002, 0.994, 0.162]>\n<car: [0.762, 0.0, 0.831, 0.025]> <speeding on> <road: [0.531, 0.002, 0.993, 0.098]>\n<slat: [0.598, 0.728, 0.686, 0.777]> <supporting> <dock: [0.378, 0.432, 0.915, 0.995]>\n", "response": "Task: What is growing on the <Region>[0.111, 0.002, 0.993, 0.707]</Region>? \nOutput: There is mold and moss growing on the side of the wall.", "instruction": "What is growing on the <Region>[0.111, 0.002, 0.993, 0.707]</Region>?", "input": "", "output": "There is mold and moss growing on the side of the wall.", "is_classification": false, "dataset": "VG", "img_info": "3217.jpg"}
{"img_id": 1932, "query": "The chain linked fence separating the building from the snow filled field.: [0.14, 0.472, 0.431, 0.575]\nThe small pile of snow against the building on the right.: [0.84, 0.575, 0.996, 0.685]\nwindow on side of building : [0.448, 0.217, 0.469, 0.253]\nbrick pillar in front of building : [0.37, 0.077, 0.466, 0.563]\nthe tall office building in the background: [0.116, 0.0, 0.581, 0.407]\nbig building next to other building: [0.126, 0.007, 0.507, 0.427]\ntwo brown pillars of building: [0.325, 0.067, 0.547, 0.582]\ngrey building on other side of sidewalk: [0.521, 0.158, 0.864, 0.438]\n\n<wall: [0.081, 0.012, 0.544, 0.568]> <on side of> <building: [0.237, 0.007, 0.399, 0.412]>\n", "response": "Task: What object is on the side of the <Region>[0.237, 0.007, 0.399, 0.412]</Region>?\nOutput: A wall is on the side of the building.", "instruction": "What object is on the side of the <Region>[0.237, 0.007, 0.399, 0.412]</Region>?", "input": "", "output": "A wall is on the side of the building.", "is_classification": false, "dataset": "VG", "img_info": "1932.jpg"}
{"img_id": 3988, "query": "table attached to the gas grill: [0.164, 0.571, 0.244, 0.621]\nglass table in the sunroom: [0.003, 0.727, 0.178, 0.998]\nlarge bush growing over the fence: [0.23, 0.221, 0.606, 0.515]\nwhite pole among the bushes: [0.58, 0.142, 0.595, 0.287]\nGrass beside fence and porch.: [0.278, 0.338, 0.984, 0.848]\nwhite metal table in the room: [0.0, 0.748, 0.178, 0.996]\ngray metal chain link fence in the yard: [0.0, 0.346, 0.998, 0.56]\nA white table chair.: [0.053, 0.637, 0.233, 0.823]\nbushes grew over and through the fence: [0.317, 0.346, 0.778, 0.531]\ntable attached to the gas grill: [0.164, 0.571, 0.244, 0.621]\n\n<side: [0.281, 0.046, 0.983, 0.942]> <of> <building: [0.284, 0.035, 0.981, 0.946]>\n<barbeque grill: [0.0, 0.5, 0.248, 0.927]> <by> <table: [0.0, 0.748, 0.183, 0.994]>\n<plant: [0.347, 0.204, 0.598, 0.517]> <growing on> <fence: [0.014, 0.335, 1.0, 0.583]>\n<table: [0.17, 0.575, 0.242, 0.623]> <attached to> <grill: [0.019, 0.506, 0.198, 0.923]>\n<bushes: [0.003, 0.127, 1.0, 0.858]> <overhanging> <fence: [0.014, 0.335, 1.0, 0.583]>\n<bush: [0.233, 0.231, 0.822, 0.54]> <growing through> <fence: [0.014, 0.335, 0.973, 0.565]>\n<door: [0.128, 0.215, 0.284, 0.781]> <to> <patio: [0.008, 0.002, 0.989, 0.99]>\n", "response": "Task: What is growing over the fence in <Region>[0.014, 0.335, 1.0, 0.583]</Region>?\nOutput: There are bushes growing over the fence.", "instruction": "What is growing over the fence in <Region>[0.014, 0.335, 1.0, 0.583]</Region>?", "input": "", "output": "There are bushes growing over the fence.", "is_classification": false, "dataset": "VG", "img_info": "3988.jpg"}
{"img_id": 2392068, "query": "A bookshelf.: [0.0, 0.0, 0.15, 0.623]\nThe window is covered by blinds. : [0.57, 0.0, 0.83, 0.552]\nbooks on shelf: [0.05, 0.238, 0.15, 0.452]\na white pillow on a bed: [0.51, 0.427, 0.78, 0.641]\nThe woman is in bed.: [0.24, 0.004, 0.74, 0.875]\nThe woman's eyes are closed.: [0.42, 0.0, 0.57, 0.285]\na white bookshelf next to a bed: [0.0, 0.007, 0.218, 0.712]\na white bookshelf next to a bed: [0.0, 0.007, 0.218, 0.712]\ncord for mini blinds: [0.798, 0.0, 0.84, 0.203]\na woman sitting up in bed: [0.36, 0.025, 0.636, 0.843]\n\n<window: [0.23, 0.004, 0.916, 0.644]> <covered by> <blinds: [0.26, 0.004, 0.862, 0.562]>\n<woman: [0.366, 0.0, 0.614, 0.819]> <WEARING> <shirt: [0.442, 0.242, 0.586, 0.626]>\n<blinds: [0.26, 0.004, 0.862, 0.562]> <are over> <window: [0.23, 0.004, 0.916, 0.644]>\n<cord: [0.804, 0.004, 0.832, 0.199]> <for> <blinds: [0.26, 0.004, 0.862, 0.562]>\n<books: [0.0, 0.441, 0.162, 0.633]> <are on> <bookshelf: [0.0, 0.431, 0.164, 0.633]>\n<pillow: [0.572, 0.47, 0.768, 0.648]> <behind> <woman: [0.366, 0.0, 0.614, 0.819]>\n<woman: [0.366, 0.0, 0.614, 0.819]> <on top of> <bed: [0.002, 0.431, 0.84, 0.996]>\n<bookcase: [0.0, 0.0, 0.232, 0.637]> <filled with> <books: [0.0, 0.441, 0.162, 0.633]>\n<cord: [0.804, 0.004, 0.832, 0.199]> <hanging on> <blinds: [0.26, 0.004, 0.862, 0.562]>\n", "response": "Task: What is behind the woman in <Region>[0.366, 0.0, 0.614, 0.819]</Region>?\nOutput: There is a white pillow behind the woman.", "instruction": "What is behind the woman in <Region>[0.366, 0.0, 0.614, 0.819]</Region>?", "input": "", "output": "There is a white pillow behind the woman.", "is_classification": false, "dataset": "VG", "img_info": "2392068.jpg"}
{"img_id": 498286, "query": "the cubicles are in the building: [0.332, 0.454, 0.576, 0.538]\nwindow on the building: [0.208, 0.538, 0.23, 0.577]\nwindow on a building: [0.204, 0.254, 0.298, 0.339]\ndiamond on the street: [0.596, 0.711, 0.696, 0.848]\nlit traffic light on a pole: [0.476, 0.362, 0.792, 0.796]\nwindow on a building: [0.104, 0.251, 0.204, 0.344]\nThe speeding car with lighted headlamps.: [0.391, 0.673, 0.534, 0.777]\nVan stopped at a street light: [0.394, 0.674, 0.536, 0.78]\nVan stopped at a street light: [0.394, 0.674, 0.536, 0.78]\nA stoplight for vehicles : [0.484, 0.382, 0.505, 0.419]\n\n<light: [0.028, 0.642, 0.052, 0.663]> <mounted on> <building: [0.003, 0.151, 0.746, 0.725]>\n<diamond: [0.615, 0.758, 0.671, 0.796]> <painted on> <road: [0.003, 0.68, 0.999, 0.996]>\n<sky: [0.003, 0.004, 0.757, 0.37]> <above> <buildings: [0.003, 0.151, 0.744, 0.715]>\n<window: [0.248, 0.257, 0.271, 0.342]> <adorning> <building: [0.003, 0.151, 0.746, 0.725]>\n<sky: [0.003, 0.004, 0.757, 0.37]> <behind> <light: [0.574, 0.062, 0.657, 0.169]>\n", "response": "Task: What is painted on the street in <Region>[0.615, 0.758, 0.671, 0.796]</Region>?\nOutput: A diamond is painted on the street.", "instruction": "What is painted on the street in <Region>[0.615, 0.758, 0.671, 0.796]</Region>?", "input": "", "output": "A diamond is painted on the street.", "is_classification": false, "dataset": "VG", "img_info": "498286.jpg"}
{"img_id": 2393542, "query": "small tunnels under the bridge: [0.29, 0.547, 0.472, 0.648]\nhouses next to the trains: [0.578, 0.28, 0.898, 0.48]\nhouses near train tracks: [0.822, 0.323, 0.93, 0.469]\nhouse by the train tracks: [0.618, 0.325, 0.994, 0.528]\nswampy grass around river: [0.254, 0.656, 0.84, 0.995]\na river next to a train track: [0.006, 0.485, 0.432, 0.899]\nbrown muddy river water: [0.012, 0.496, 0.212, 0.979]\nthe river water is brown: [0.494, 0.872, 0.556, 0.96]\na muddy river: [0.0, 0.755, 0.55, 0.923]\nrushing brown water by trees: [0.02, 0.515, 0.212, 0.661]\n\n<carriages: [0.268, 0.512, 0.574, 0.547]> <attached to> <train: [0.85, 0.477, 0.966, 0.56]>\n<water: [0.034, 0.659, 0.332, 0.936]> <inside of> <river: [0.726, 0.885, 0.914, 0.987]>\n<grass: [0.56, 0.76, 0.648, 0.813]> <around> <river: [0.726, 0.885, 0.914, 0.987]>\n<rocks: [0.68, 0.875, 0.816, 0.947]> <by> <river: [0.726, 0.885, 0.914, 0.987]>\n<bridge: [0.434, 0.557, 0.846, 0.621]> <under> <train: [0.85, 0.477, 0.966, 0.56]>\n<train station: [0.634, 0.365, 0.974, 0.469]> <behind> <train: [0.85, 0.477, 0.966, 0.56]>\n<poles: [0.44, 0.397, 0.49, 0.52]> <holding up> <wires: [0.568, 0.408, 0.654, 0.451]>\n<train: [0.85, 0.477, 0.966, 0.56]> <running along> <bridge: [0.434, 0.557, 0.846, 0.621]>\n<bridge: [0.434, 0.557, 0.846, 0.621]> <made of> <brick: [0.664, 0.589, 0.738, 0.675]>\n<train: [0.85, 0.477, 0.966, 0.56]> <on top of> <bridge: [0.434, 0.557, 0.846, 0.621]>\n", "response": "Task: What is beneath the <Region>[0.434, 0.557, 0.846, 0.621]</Region> on the plane?\nOutput: There is a train running under the bridge.", "instruction": "What is beneath the <Region>[0.434, 0.557, 0.846, 0.621]</Region> on the plane?", "input": "", "output": "There is a train running under the bridge.", "is_classification": false, "dataset": "VG", "img_info": "2393542.jpg"}
{"img_id": 2798, "query": "plant on front the body of water: [0.826, 0.685, 0.978, 0.912]\nA clear blue sky : [0.005, 0.0, 0.99, 0.738]\nA large body of water with some ripples in it : [0.004, 0.775, 0.996, 0.988]\nripples formed in the water: [0.229, 0.77, 0.465, 0.92]\nscattered waves in water : [0.007, 0.785, 0.882, 0.963]\nripples formed in the water: [0.786, 0.778, 0.854, 0.847]\nA blue sky with few light clouds: [0.007, 0.0, 0.993, 0.747]\nthe sky is clear and blue: [0.184, 0.133, 0.556, 0.603]\nA large body of water: [0.003, 0.763, 0.969, 0.995]\nCloud in the sky. : [0.12, 0.025, 0.323, 0.222]\n\n<bushes: [0.282, 0.695, 0.989, 0.988]> <beside> <water: [0.006, 0.773, 0.956, 0.98]>\n<building: [0.723, 0.722, 0.765, 0.743]> <below> <sky: [0.006, 0.0, 0.996, 0.735]>\n", "response": "Task: What is beside <Region>[0.006, 0.773, 0.956, 0.98]</Region>?\nOutput: There are bushes beside the body of water.", "instruction": "What is beside <Region>[0.006, 0.773, 0.956, 0.98]</Region>?", "input": "", "output": "There are bushes beside the body of water.", "is_classification": false, "dataset": "VG", "img_info": "2798.jpg"}
{"img_id": 1592855, "query": "trees lining the street: [0.509, 0.335, 0.995, 0.738]\nfour way street light : [0.436, 0.23, 0.515, 0.358]\nLine of cars parked at curb: [0.765, 0.665, 0.96, 0.742]\nGreen and white street signs.: [0.499, 0.54, 0.543, 0.568]\nstreet signs on a corner: [0.51, 0.536, 0.539, 0.747]\nA street light : [0.93, 0.341, 0.996, 0.404]\na street sign: [0.068, 0.565, 0.091, 0.715]\nUtility pole on street: [0.062, 0.195, 0.169, 0.74]\ncars parked on the street: [0.766, 0.659, 0.971, 0.73]\ngreen street signs: [0.502, 0.529, 0.543, 0.57]\n\n<car: [0.906, 0.672, 0.945, 0.715]> <parked along> <street: [0.003, 0.689, 0.998, 0.996]>\n", "response": "Task: What can be seen in the image in <Region>[0.906, 0.672, 0.945, 0.715]</Region>?\nOutput: A parked car can be seen in this region.", "instruction": "What can be seen in the image in <Region>[0.906, 0.672, 0.945, 0.715]</Region>?", "input": "", "output": "A parked car can be seen in this region.", "is_classification": false, "dataset": "VG", "img_info": "1592855.jpg"}
{"img_id": 1592166, "query": "many cars on the street: [0.061, 0.279, 0.661, 0.935]\nVery big white bus with green on bottom: [0.004, 0.025, 0.208, 0.137]\nthis bus is white and green: [0.001, 0.016, 0.265, 0.15]\nthese are cars in traffic : [0.06, 0.062, 0.844, 0.98]\nBlue traffic sign: [0.106, 0.148, 0.181, 0.285]\ncars stuck in traffic jam: [0.394, 0.474, 0.493, 0.573]\nwhite car on the street: [0.191, 0.493, 0.279, 0.613]\ncars stuck in traffic jam: [0.388, 0.219, 0.541, 0.389]\nwhite lines on the ground: [0.607, 0.585, 0.726, 0.751]\nbus on the street: [0.339, 0.122, 0.504, 0.335]\n\n<traffic: [0.018, 0.017, 0.793, 0.932]> <on side> <road: [0.012, 0.004, 0.993, 0.992]>\n<bus: [0.615, 0.014, 0.681, 0.086]> <under> <bridge: [0.374, 0.001, 0.45, 0.098]>\n<person: [0.226, 0.397, 0.249, 0.452]> <walking on> <sidewalk: [0.164, 0.155, 0.376, 0.482]>\n<bottom: [0.118, 0.096, 0.207, 0.122]> <belonging to> <bus: [0.006, 0.012, 0.209, 0.13]>\n<man: [0.597, 0.302, 0.62, 0.362]> <diverting> <traffic: [0.018, 0.017, 0.793, 0.932]>\n<guy: [0.329, 0.191, 0.347, 0.242]> <WEARING> <shirt: [0.329, 0.198, 0.347, 0.224]>\n<car: [0.207, 0.862, 0.283, 0.93]> <driving on> <road: [0.0, 0.0, 0.998, 0.997]>\n<line: [0.633, 0.721, 0.648, 0.747]> <painted on> <road: [0.0, 0.0, 0.998, 0.997]>\n", "response": "Task: What color is the big bus on the <Region>[0.004, 0.025, 0.208, 0.137]</Region>?\nOutput: The bus is white and green on the bottom.", "instruction": "What color is the big bus on the <Region>[0.004, 0.025, 0.208, 0.137]</Region>?", "input": "", "output": "The bus is white and green on the bottom.", "is_classification": false, "dataset": "VG", "img_info": "1592166.jpg"}
{"img_id": 3162, "query": "Windows of a building: [0.691, 0.293, 0.881, 0.522]\nHead of a woman: [0.44, 0.698, 0.468, 0.74]\nwoman wearing brown capris: [0.417, 0.763, 0.491, 0.853]\na white sidewalk sandwich sign: [0.703, 0.75, 0.756, 0.857]\nFoot of a woman: [0.449, 0.852, 0.482, 0.88]\ncolorful merchandise in shop window: [0.335, 0.658, 0.391, 0.787]\na woman wearing brown pants: [0.427, 0.787, 0.477, 0.845]\ngreen papers posted to windows: [0.698, 0.34, 0.875, 0.41]\na woman walking on a sidewalk: [0.406, 0.702, 0.49, 0.878]\na glass metal picture window: [0.674, 0.297, 0.896, 0.537]\n\n<window: [0.816, 0.073, 0.874, 0.252]> <of a> <building: [0.656, 0.002, 0.892, 0.883]>\n<woman: [0.4, 0.715, 0.472, 0.885]> <walking on> <sidewalk: [0.001, 0.825, 0.998, 0.925]>\n<paper: [0.843, 0.363, 0.879, 0.407]> <hanging in> <window: [0.84, 0.338, 0.881, 0.463]>\n", "response": "Task: What object is hanging in the object in <Region>[0.816, 0.073, 0.874, 0.252]</Region>?\nOutput: In the window of the building, there is a paper hanging.", "instruction": "What object is hanging in the object in <Region>[0.816, 0.073, 0.874, 0.252]</Region>?", "input": "", "output": "In the window of the building, there is a paper hanging.", "is_classification": false, "dataset": "VG", "img_info": "3162.jpg"}
{"img_id": 4548, "query": "a blue cushioned office chair: [0.337, 0.6, 0.586, 0.99]\nthe tv is black and on the wall: [0.6, 0.048, 0.731, 0.252]\nGame on the table: [0.203, 0.713, 0.31, 0.8]\npicture on a wall: [0.39, 0.139, 0.511, 0.297]\nTable next to chairs: [0.094, 0.71, 0.414, 0.965]\nthe room filled with empty chairs: [0.0, 0.0, 0.998, 0.997]\nbrown table on wall: [0.097, 0.729, 0.383, 0.994]\nBlack television on wall: [0.613, 0.081, 0.743, 0.219]\nSmall table for kids : [0.099, 0.723, 0.39, 0.994]\nthe toys on the table: [0.102, 0.719, 0.385, 0.99]\n\n<table: [0.107, 0.758, 0.385, 0.997]> <by> <chairs: [0.223, 0.59, 0.593, 0.997]>\n<television: [0.63, 0.09, 0.709, 0.197]> <hanging on> <wall: [0.0, 0.003, 0.736, 0.439]>\n<book: [0.462, 0.429, 0.533, 0.465]> <laying on> <table: [0.107, 0.758, 0.385, 0.997]>\n<chart: [0.523, 0.155, 0.579, 0.294]> <hangs on> <wall: [0.0, 0.003, 0.736, 0.439]>\n<chart: [0.523, 0.155, 0.579, 0.294]> <seen on> <wall: [0.0, 0.003, 0.736, 0.439]>\n<wall: [0.0, 0.003, 0.736, 0.439]> <has a> <television: [0.63, 0.09, 0.709, 0.197]>\n<chairs: [0.223, 0.59, 0.593, 0.997]> <are in th> <room: [0.002, 0.003, 1.0, 0.997]>\n<legs: [0.673, 0.652, 0.777, 0.845]> <OF> <chair: [0.562, 0.506, 0.775, 0.855]>\n<chairs: [0.223, 0.59, 0.593, 0.997]> <in th> <room: [0.002, 0.003, 1.0, 0.997]>\n", "response": "Task: What can be seen on the wall within <Region>[0.0, 0.003, 0.736, 0.439]</Region>?\nOutput: There is a black television hanging on the wall. Additionally, a chart is also seen hanging on the same wall.", "instruction": "What can be seen on the wall within <Region>[0.0, 0.003, 0.736, 0.439]</Region>?", "input": "", "output": "There is a black television hanging on the wall. Additionally, a chart is also seen hanging on the same wall.", "is_classification": false, "dataset": "VG", "img_info": "4548.jpg"}
{"img_id": 2392097, "query": "Man is holding large rope leading horse.: [0.676, 0.272, 0.89, 0.507]\na tree behind the fence: [0.614, 0.006, 0.996, 0.448]\nHorse has black mane.: [0.302, 0.204, 0.502, 0.391]\na man wearing a white shirt: [0.742, 0.19, 0.942, 0.601]\nthe house has a window: [0.002, 0.02, 0.19, 0.238]\na man with a horse: [0.036, 0.079, 0.936, 0.986]\nThe ropes the man is using to lead the horse.: [0.602, 0.297, 0.866, 0.439]\nThe ropes the man is using to lead the horse.: [0.602, 0.297, 0.866, 0.439]\nThe black pants the man is wearing.: [0.78, 0.397, 0.88, 0.581]\nThe back legs of the horse.: [0.116, 0.544, 0.216, 0.986]\n\n<shadow: [0.648, 0.533, 0.91, 0.946]> <OF> <rope: [0.6, 0.306, 0.83, 0.47]>\n<man: [0.778, 0.198, 0.934, 0.586]> <and> <horse: [0.074, 0.11, 0.642, 0.935]>\n<fence: [0.67, 0.215, 0.996, 0.377]> <behind> <man: [0.778, 0.198, 0.934, 0.586]>\n<line: [0.288, 0.008, 0.396, 0.119]> <between> <house: [0.438, 0.008, 0.666, 0.272]>\n", "response": "Task: What is the man holding to lead the horse in <Region>[0.676, 0.272, 0.89, 0.507]</Region>?\nOutput: The man is holding a large rope to lead the horse in the given region.", "instruction": "What is the man holding to lead the horse in <Region>[0.676, 0.272, 0.89, 0.507]</Region>?", "input": "", "output": "The man is holding a large rope to lead the horse in the given region.", "is_classification": false, "dataset": "VG", "img_info": "2392097.jpg"}
{"img_id": 1592180, "query": "building has a window: [0.011, 0.385, 0.026, 0.421]\nbuilding has a window: [0.002, 0.193, 0.021, 0.23]\ntwo guys wearing blazer jackets: [0.083, 0.168, 0.988, 0.997]\nthe fingers of a man: [0.714, 0.818, 0.848, 0.947]\nThe man is wearing a watch: [0.751, 0.624, 0.809, 0.676]\nthe mustache of a man: [0.269, 0.379, 0.328, 0.409]\nman is wearing a multicolored tie: [0.526, 0.663, 0.675, 0.98]\nThe guy on the right has a tie that is multi colored: [0.57, 0.66, 0.676, 0.996]\nbuilding has a window: [0.058, 0.249, 0.073, 0.294]\nman is wearing a blue tie with a stripe: [0.246, 0.535, 0.337, 0.809]\n\n<man: [0.448, 0.193, 0.978, 0.996]> <WEARING> <tie: [0.571, 0.658, 0.674, 0.996]>\n<button: [0.285, 0.77, 0.322, 0.829]> <sewn on> <jacket: [0.097, 0.461, 0.836, 0.996]>\n<window: [0.058, 0.251, 0.073, 0.294]> <adorning> <building: [0.025, 0.208, 0.097, 0.427]>\n", "response": "Task: What is the relationship between the object in <Region>[0.097, 0.461, 0.836, 0.996]</Region> and the object in <Region>[0.285, 0.77, 0.322, 0.829]</Region>?\nOutput: The button is sewn on the jacket.", "instruction": "What is the relationship between the object in <Region>[0.097, 0.461, 0.836, 0.996]</Region> and the object in <Region>[0.285, 0.77, 0.322, 0.829]</Region>?", "input": "", "output": "The button is sewn on the jacket.", "is_classification": false, "dataset": "VG", "img_info": "1592180.jpg"}
{"img_id": 1160160, "query": "knife has black handle: [0.435, 0.729, 0.602, 0.829]\nman chopping up apples: [0.097, 0.015, 0.462, 0.956]\nman's shirt is white: [0.101, 0.204, 0.419, 0.972]\nBandana on a man's head.: [0.237, 0.0, 0.423, 0.216]\nbandana on a man's head: [0.243, 0.0, 0.423, 0.137]\nthe man is chopping fruits : [0.056, 0.01, 0.616, 0.982]\nthe man's mouth is open: [0.34, 0.231, 0.368, 0.266]\nbandanna on man's head: [0.233, 0.0, 0.436, 0.137]\nthe man's mouth is open: [0.34, 0.231, 0.368, 0.266]\nthis is a knife : [0.421, 0.712, 0.619, 0.825]\n\n<man: [0.111, 0.001, 0.582, 0.988]> <using a> <knife: [0.52, 0.721, 0.598, 0.815]>\n<window: [0.047, 0.0, 0.708, 0.524]> <in front of> <man: [0.111, 0.001, 0.582, 0.988]>\n", "response": "Task: What object is the man in <Region>[0.111, 0.001, 0.582, 0.988]</Region> using?\nOutput: The man is using a knife.", "instruction": "What object is the man in <Region>[0.111, 0.001, 0.582, 0.988]</Region> using?", "input": "", "output": "The man is using a knife.", "is_classification": false, "dataset": "VG", "img_info": "1160160.jpg"}
{"img_id": 2393042, "query": "the dirt of the pitcher's mound: [0.0, 0.752, 0.997, 0.994]\na black and white shoe on a man: [0.538, 0.824, 0.691, 0.89]\nDirt on the ball field: [0.189, 0.81, 0.429, 0.996]\nshoe on baseball player: [0.547, 0.82, 0.682, 0.892]\nThe player's arm and hand without the glove.: [0.505, 0.302, 0.691, 0.424]\ninfield grass next to pitcher: [0.763, 0.458, 0.955, 0.746]\nBaseball glove: [0.607, 0.524, 0.79, 0.608]\na black cap on a man: [0.577, 0.334, 0.757, 0.394]\na black and white shoe on a man: [0.538, 0.824, 0.691, 0.89]\nbaseball in the air: [0.736, 0.228, 0.838, 0.284]\n\n<arm: [0.489, 0.318, 0.709, 0.428]> <throwing> <ball: [0.754, 0.224, 0.823, 0.266]>\n<man: [0.021, 0.286, 0.718, 0.896]> <WEARING> <cleats: [0.012, 0.716, 0.084, 0.802]>\n<man: [0.021, 0.286, 0.718, 0.896]> <standing in> <dirt: [0.006, 0.786, 0.994, 1.0]>\n<man: [0.021, 0.286, 0.718, 0.896]> <pitching> <ball: [0.754, 0.224, 0.823, 0.266]>\n<infield dirt: [0.006, 0.158, 0.997, 0.454]> <behind> <pitcher: [0.021, 0.286, 0.718, 0.896]>\n", "response": "Task: What is behind the object in <Region>[0.021, 0.286, 0.718, 0.896]</Region>?\nOutput: Behind the object, there is infield dirt next to the pitcher.", "instruction": "What is behind the object in <Region>[0.021, 0.286, 0.718, 0.896]</Region>?", "input": "", "output": "Behind the object, there is infield dirt next to the pitcher.", "is_classification": false, "dataset": "VG", "img_info": "2393042.jpg"}
{"img_id": 1634, "query": "person standing on the sidewalk: [0.264, 0.523, 0.336, 0.737]\nman walking on sidewalk: [0.27, 0.508, 0.344, 0.738]\nperson wearing a black jacket with white stripe: [0.305, 0.525, 0.336, 0.725]\ntrees on the sidewalk : [0.469, 0.173, 0.996, 0.455]\ngrey SUV on the right sidewalk: [0.438, 0.545, 0.665, 0.808]\npeople walking on the sidewalk: [0.266, 0.448, 0.416, 0.732]\npeople walking on the sidewalk: [0.266, 0.448, 0.416, 0.732]\nlong line of cards parked on sidewalks: [0.416, 0.42, 0.996, 0.835]\nlong line of cards parked on sidewalks: [0.416, 0.42, 0.996, 0.835]\ncobbled design on the sidewalk: [0.009, 0.785, 0.45, 0.993]\n\n<people: [0.268, 0.535, 0.335, 0.735]> <WEARING> <jacket: [0.268, 0.533, 0.341, 0.635]>\n<people: [0.351, 0.508, 0.385, 0.637]> <walking on> <sidewalk: [0.0, 0.497, 0.446, 0.993]>\n<cars: [0.419, 0.437, 0.999, 0.815]> <parked> <sidewalks: [0.242, 0.565, 0.436, 0.938]>\n", "response": "Task: What are the people doing in <Region>[0.351, 0.508, 0.385, 0.637]</Region>?\nOutput: They are walking on the sidewalk.", "instruction": "What are the people doing in <Region>[0.351, 0.508, 0.385, 0.637]</Region>?", "input": "", "output": "They are walking on the sidewalk.", "is_classification": false, "dataset": "VG", "img_info": "1634.jpg"}
{"img_id": 1592670, "query": "a black colored shirt: [0.333, 0.432, 0.447, 0.56]\na person wearing a blue helmet and black shirt: [0.303, 0.361, 0.461, 0.768]\nyoung boy on skateboard: [0.302, 0.359, 0.461, 0.776]\nblue helmet on boy's head: [0.348, 0.354, 0.401, 0.424]\nskateboard boy is riding on: [0.329, 0.68, 0.404, 0.75]\nshoes on boy's feet: [0.372, 0.693, 0.435, 0.772]\na boy is running: [0.293, 0.345, 0.521, 0.87]\nthe shirt is dark blue: [0.327, 0.424, 0.448, 0.574]\n\n<boy: [0.313, 0.378, 0.463, 0.594]> <WEARING> <shirt: [0.339, 0.43, 0.447, 0.569]>\n", "response": "Task: What is the color of the shirt that the boy is wearing in <Region>[0.313, 0.378, 0.463, 0.594]</Region>?\nOutput: The boy is wearing a dark blue shirt.", "instruction": "What is the color of the shirt that the boy is wearing in <Region>[0.313, 0.378, 0.463, 0.594]</Region>?", "input": "", "output": "The boy is wearing a dark blue shirt.", "is_classification": false, "dataset": "VG", "img_info": "1592670.jpg"}
{"img_id": 474, "query": "orange electrical jacks on wall: [0.105, 0.59, 0.141, 0.662]\na wooden chair near a long rectangular table inside a small room: [0.196, 0.517, 0.312, 0.67]\nbrown table is empty: [0.04, 0.445, 0.774, 0.837]\nbrown table in room: [0.068, 0.442, 0.781, 0.845]\na white wall: [0.434, 0.267, 0.576, 0.383]\na white wall: [0.502, 0.107, 0.665, 0.293]\nRadiator on the wall: [0.374, 0.508, 0.854, 0.775]\nwhite wall in room: [0.507, 0.202, 0.801, 0.388]\nthree outlets on the wall: [0.066, 0.59, 0.219, 0.688]\nwhite heater on wall: [0.651, 0.525, 0.848, 0.787]\n\n<wall: [0.276, 0.123, 0.995, 0.787]> <behind> <table: [0.061, 0.52, 0.7, 0.993]>\n", "response": "Task: What object is behind the <Region>[0.061, 0.52, 0.7, 0.993]</Region> in the image?\nOutput: The object behind the region is the wall.", "instruction": "What object is behind the <Region>[0.061, 0.52, 0.7, 0.993]</Region> in the image?", "input": "", "output": "The object behind the region is the wall.", "is_classification": false, "dataset": "VG", "img_info": "474.jpg"}
